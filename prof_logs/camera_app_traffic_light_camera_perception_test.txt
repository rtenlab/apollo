==22622== NVPROF is profiling process 22622, command: ./camera_app_traffic_light_camera_perception_test
[NVBLAS] NVBLAS_CONFIG_FILE environment variable is set to '/usr/local/cuda/'
[NVBLAS] Config parsed
[NVBLAS] CPU Blas library need to be provided
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0416 17:32:41.089570 22622 object_pool_types.cc:33] []Initialize base object pool (malloc).
Running main() from gmock_main.cc
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from TrafficLightCameraPerceptionTest
[ RUN      ] TrafficLightCameraPerceptionTest.normal
I0416 17:32:41.105080 22622 traffic_light_camera_perception.cc:40] []proto_path /apollo/modules/perception/testdata/camera/app/conf/perception/camera/traffic_light/trafficlight.pt
I0416 17:32:41.105262 22622 detection.cc:38] []proto_path /apollo/modules/perception/production/data/perception/camera/models/traffic_light_detection/detection.pt
I0416 17:32:41.105350 22622 detection.cc:46] []TL detection param: min_crop_size: 270
crop_method: 0
mean_b: 102.9801
mean_g: 115.9465
mean_r: 122.7717
is_bgr: true
crop_scale: 2.5
input_blob_name: "img"
im_param_blob_name: "im_info"
output_blob_name: "bboxes"
model_name: "./"
model_type: "CaffeNet"
proto_file: "deploy.prototxt"
weight_file: "baidu_iter_140000.caffemodel"
max_batch_size: 4
I0416 17:32:41.105355 22622 detection.cc:50] []model_root /apollo/modules/perception/production/data/perception/camera/models/traffic_light_detection/./
I0416 17:32:41.105357 22622 detection.cc:54] []proto_file /apollo/modules/perception/production/data/perception/camera/models/traffic_light_detection/./deploy.prototxt
I0416 17:32:41.105360 22622 detection.cc:58] []weight_file /apollo/modules/perception/production/data/perception/camera/models/traffic_light_detection/./baidu_iter_140000.caffemodel
I0416 17:32:41.105363 22622 detection.cc:76] []net input blobs: 
img
im_info
I0416 17:32:41.105365 22622 detection.cc:82] []net output blobs: 
bboxes
I0416 17:32:41.105367 22622 detection.cc:90] []model_type: CaffeNet
I0416 17:32:41.105370 22622 detection.cc:96] []rt_net_ create succeed
I0416 17:32:41.105372 22622 detection.cc:98] []set gpu id 0
I0416 17:32:41.489603 22622 common.cpp:178] Device id:                     0
I0416 17:32:41.489656 22622 common.cpp:179] Major revision number:         6
I0416 17:32:41.489660 22622 common.cpp:180] Minor revision number:         1
I0416 17:32:41.489661 22622 common.cpp:181] Name:                          GeForce GTX 1070 Ti
I0416 17:32:41.489663 22622 common.cpp:182] Total global memory:           8510701568
I0416 17:32:41.489673 22622 common.cpp:183] Total shared memory per block: 49152
I0416 17:32:41.489675 22622 common.cpp:184] Total registers per block:     65536
I0416 17:32:41.489677 22622 common.cpp:185] Warp size:                     32
I0416 17:32:41.489679 22622 common.cpp:186] Maximum memory pitch:          2147483647
I0416 17:32:41.489681 22622 common.cpp:187] Maximum threads per block:     1024
I0416 17:32:41.489683 22622 common.cpp:188] Maximum dimension of block:    1024, 1024, 64
I0416 17:32:41.489686 22622 common.cpp:191] Maximum dimension of grid:     2147483647, 65535, 65535
I0416 17:32:41.489688 22622 common.cpp:194] Clock rate:                    1683000
I0416 17:32:41.489691 22622 common.cpp:195] Total constant memory:         65536
I0416 17:32:41.489692 22622 common.cpp:196] Texture alignment:             512
I0416 17:32:41.489694 22622 common.cpp:197] Concurrent copy and execution: Yes
I0416 17:32:41.489696 22622 common.cpp:199] Number of multiprocessors:     19
I0416 17:32:41.489698 22622 common.cpp:200] Kernel execution timeout:      Yes
I0416 17:32:41.493829 22622 net.cpp:53] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "img"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 256
      dim: 256
      dim: 3
    }
    shape {
      dim: 1
      dim: 6
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "permute"
  type: "Permute"
  bottom: "img"
  top: "data"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2b"
  top: "res2a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2b"
  top: "res2b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2b"
  top: "res2c"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2b"
  top: "res3a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2b"
  top: "res3b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2b"
  top: "res3c"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2b"
  top: "res3d"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2b"
  top: "res4a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2b"
  top: "res4b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c"
  type: "Eltwise"
  bottom: "res4b"
  bottom: "res4c_branch2b"
  top: "res4c"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4c_relu"
  type: "ReLU"
  bottom: "res4c"
  top: "res4c"
}
layer {
  name: "res4d_branch2a"
  type: "Convolution"
  bottom: "res4c"
  top: "res4d_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4d_branch2a"
  type: "BatchNorm"
  bottom: "res4d_branch2a"
  top: "res4d_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4d_branch2a"
  type: "Scale"
  bottom: "res4d_branch2a"
  top: "res4d_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4d_branch2a_relu"
  type: "ReLU"
  bottom: "res4d_branch2a"
  top: "res4d_branch2a"
}
layer {
  name: "res4d_branch2b"
  type: "Convolution"
  bottom: "res4d_branch2a"
  top: "res4d_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4d_branch2b"
  type: "BatchNorm"
  bottom: "res4d_branch2b"
  top: "res4d_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4d_branch2b"
  type: "Scale"
  bottom: "res4d_branch2b"
  top: "res4d_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4d"
  type: "Eltwise"
  bottom: "res4c"
  bottom: "res4d_branch2b"
  top: "res4d"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4d_relu"
  type: "ReLU"
  bottom: "res4d"
  top: "res4d"
}
layer {
  name: "res4e_branch2a"
  type: "Convolution"
  bottom: "res4d"
  top: "res4e_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4e_branch2a"
  type: "BatchNorm"
  bottom: "res4e_branch2a"
  top: "res4e_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4e_branch2a"
  type: "Scale"
  bottom: "res4e_branch2a"
  top: "res4e_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4e_branch2a_relu"
  type: "ReLU"
  bottom: "res4e_branch2a"
  top: "res4e_branch2a"
}
layer {
  name: "res4e_branch2b"
  type: "Convolution"
  bottom: "res4e_branch2a"
  top: "res4e_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4e_branch2b"
  type: "BatchNorm"
  bottom: "res4e_branch2b"
  top: "res4e_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4e_branch2b"
  type: "Scale"
  bottom: "res4e_branch2b"
  top: "res4e_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4e"
  type: "Eltwise"
  bottom: "res4d"
  bottom: "res4e_branch2b"
  top: "res4e"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4e_relu"
  type: "ReLU"
  bottom: "res4e"
  top: "res4e"
}
layer {
  name: "res4f_branch2a"
  type: "Convolution"
  bottom: "res4e"
  top: "res4f_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4f_branch2a"
  type: "BatchNorm"
  bottom: "res4f_branch2a"
  top: "res4f_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4f_branch2a"
  type: "Scale"
  bottom: "res4f_branch2a"
  top: "res4f_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4f_branch2a_relu"
  type: "ReLU"
  bottom: "res4f_branch2a"
  top: "res4f_branch2a"
}
layer {
  name: "res4f_branch2b"
  type: "Convolution"
  bottom: "res4f_branch2a"
  top: "res4f_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4f_branch2b"
  type: "BatchNorm"
  bottom: "res4f_branch2b"
  top: "res4f_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4f_branch2b"
  type: "Scale"
  bottom: "res4f_branch2b"
  top: "res4f_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4f"
  type: "Eltwise"
  bottom: "res4e"
  bottom: "res4f_branch2b"
  top: "res4f"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4f_relu"
  type: "ReLU"
  bottom: "res4f"
  top: "res4f"
}
layer {
  name: "res5a_branch1"
  type: "Convolution"
  bottom: "res4f"
  top: "res5a_branch1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5a_branch1"
  type: "BatchNorm"
  bottom: "res5a_branch1"
  top: "res5a_branch1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5a_branch1"
  type: "Scale"
  bottom: "res5a_branch1"
  top: "res5a_branch1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "res4f"
  top: "res5a_branch2a"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5a_branch2a"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5a_branch2a"
  type: "Scale"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5a_branch2a_relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 2
  }
}
layer {
  name: "bn5a_branch2b"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5a_branch2b"
  type: "Scale"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5a"
  type: "Eltwise"
  bottom: "res5a_branch1"
  bottom: "res5a_branch2b"
  top: "res5a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5a_relu"
  type: "ReLU"
  bottom: "res5a"
  top: "res5a"
}
layer {
  name: "res5b_branch2a"
  type: "Convolution"
  bottom: "res5a"
  top: "res5b_branch2a"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 2
  }
}
layer {
  name: "bn5b_branch2a"
  type: "BatchNorm"
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5b_branch2a"
  type: "Scale"
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5b_branch2a_relu"
  type: "ReLU"
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
}
layer {
  name: "res5b_branch2b"
  type: "Convolution"
  bottom: "res5b_branch2a"
  top: "res5b_branch2b"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 2
  }
}
layer {
  name: "bn5b_branch2b"
  type: "BatchNorm"
  bottom: "res5b_branch2b"
  top: "res5b_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5b_branch2b"
  type: "Scale"
  bottom: "res5b_branch2b"
  top: "res5b_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5b"
  type: "Eltwise"
  bottom: "res5a"
  bottom: "res5b_branch2b"
  top: "res5b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5b_relu"
  type: "ReLU"
  bottom: "res5b"
  top: "res5b"
}
layer {
  name: "res5c_branch2a"
  type: "Convolution"
  bottom: "res5b"
  top: "res5c_branch2a"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 2
  }
}
layer {
  name: "bn5c_branch2a"
  type: "BatchNorm"
  bottom: "res5c_branch2a"
  top: "res5c_branch2a"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5c_branch2a"
  type: "Scale"
  bottom: "res5c_branch2a"
  top: "res5c_branch2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5c_branch2a_relu"
  type: "ReLU"
  bottom: "res5c_branch2a"
  top: "res5c_branch2a"
}
layer {
  name: "res5c_branch2b"
  type: "Convolution"
  bottom: "res5c_branch2a"
  top: "res5c_branch2b"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 2
  }
}
layer {
  name: "bn5c_branch2b"
  type: "BatchNorm"
  bottom: "res5c_branch2b"
  top: "res5c_branch2b"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5c_branch2b"
  type: "Scale"
  bottom: "res5c_branch2b"
  top: "res5c_branch2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5c"
  type: "Eltwise"
  bottom: "res5b"
  bottom: "res5c_branch2b"
  top: "res5c"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5c_relu"
  type: "ReLU"
  bottom: "res5c"
  top: "res5c"
}
layer {
  name: "rpn_deconv"
  type: "Deconvolution"
  bottom: "res4f"
  top: "rpn/output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "rpn_relu"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      std: 0.01
    }
    bias_filler {
      type: "constan
I0416 17:32:41.494437 22622 layer_factory.hpp:77] Creating layer input
I0416 17:32:41.494463 22622 net.cpp:86] Creating Layer input
I0416 17:32:41.494475 22622 net.cpp:382] input -> img
I0416 17:32:41.494549 22622 net.cpp:382] input -> im_info
I0416 17:32:41.671295 22622 net.cpp:124] Setting up input
I0416 17:32:41.671399 22622 net.cpp:131] Top shape: 1 256 256 3 (196608)
I0416 17:32:41.671403 22622 net.cpp:131] Top shape: 1 6 1 1 (6)
I0416 17:32:41.671406 22622 net.cpp:139] Memory required for data: 786456
I0416 17:32:41.671432 22622 layer_factory.hpp:77] Creating layer im_info_input_1_split
I0416 17:32:41.671444 22622 net.cpp:86] Creating Layer im_info_input_1_split
I0416 17:32:41.671456 22622 net.cpp:408] im_info_input_1_split <- im_info
I0416 17:32:41.671489 22622 net.cpp:382] im_info_input_1_split -> im_info_input_1_split_0
I0416 17:32:41.671497 22622 net.cpp:382] im_info_input_1_split -> im_info_input_1_split_1
I0416 17:32:41.671522 22622 net.cpp:124] Setting up im_info_input_1_split
I0416 17:32:41.671526 22622 net.cpp:131] Top shape: 1 6 1 1 (6)
I0416 17:32:41.671530 22622 net.cpp:131] Top shape: 1 6 1 1 (6)
I0416 17:32:41.671531 22622 net.cpp:139] Memory required for data: 786504
I0416 17:32:41.671533 22622 layer_factory.hpp:77] Creating layer permute
I0416 17:32:41.671546 22622 net.cpp:86] Creating Layer permute
I0416 17:32:41.671550 22622 net.cpp:408] permute <- img
I0416 17:32:41.671552 22622 net.cpp:382] permute -> data
I0416 17:32:41.671640 22622 net.cpp:124] Setting up permute
I0416 17:32:41.671645 22622 net.cpp:131] Top shape: 1 3 256 256 (196608)
I0416 17:32:41.671648 22622 net.cpp:139] Memory required for data: 1572936
I0416 17:32:41.671649 22622 layer_factory.hpp:77] Creating layer conv1
I0416 17:32:41.671692 22622 net.cpp:86] Creating Layer conv1
I0416 17:32:41.671695 22622 net.cpp:408] conv1 <- data
I0416 17:32:41.671699 22622 net.cpp:382] conv1 -> conv1
==22622== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
I0416 17:32:42.561493 22622 net.cpp:124] Setting up conv1
I0416 17:32:42.561528 22622 net.cpp:131] Top shape: 1 16 128 128 (262144)
I0416 17:32:42.561532 22622 net.cpp:139] Memory required for data: 2621512
I0416 17:32:42.561558 22622 layer_factory.hpp:77] Creating layer bn_conv1
I0416 17:32:42.561573 22622 net.cpp:86] Creating Layer bn_conv1
I0416 17:32:42.561578 22622 net.cpp:408] bn_conv1 <- conv1
I0416 17:32:42.561583 22622 net.cpp:369] bn_conv1 -> conv1 (in-place)
I0416 17:32:42.561718 22622 net.cpp:124] Setting up bn_conv1
I0416 17:32:42.561722 22622 net.cpp:131] Top shape: 1 16 128 128 (262144)
I0416 17:32:42.561725 22622 net.cpp:139] Memory required for data: 3670088
I0416 17:32:42.561731 22622 layer_factory.hpp:77] Creating layer scale_conv1
I0416 17:32:42.561743 22622 net.cpp:86] Creating Layer scale_conv1
I0416 17:32:42.561746 22622 net.cpp:408] scale_conv1 <- conv1
I0416 17:32:42.561750 22622 net.cpp:369] scale_conv1 -> conv1 (in-place)
I0416 17:32:42.561810 22622 layer_factory.hpp:77] Creating layer scale_conv1
I0416 17:32:42.561906 22622 net.cpp:124] Setting up scale_conv1
I0416 17:32:42.561910 22622 net.cpp:131] Top shape: 1 16 128 128 (262144)
I0416 17:32:42.561913 22622 net.cpp:139] Memory required for data: 4718664
I0416 17:32:42.561918 22622 layer_factory.hpp:77] Creating layer conv1_relu
I0416 17:32:42.561923 22622 net.cpp:86] Creating Layer conv1_relu
I0416 17:32:42.561924 22622 net.cpp:408] conv1_relu <- conv1
I0416 17:32:42.561928 22622 net.cpp:369] conv1_relu -> conv1 (in-place)
I0416 17:32:42.562316 22622 net.cpp:124] Setting up conv1_relu
I0416 17:32:42.562325 22622 net.cpp:131] Top shape: 1 16 128 128 (262144)
I0416 17:32:42.562327 22622 net.cpp:139] Memory required for data: 5767240
I0416 17:32:42.562330 22622 layer_factory.hpp:77] Creating layer pool1
I0416 17:32:42.562345 22622 net.cpp:86] Creating Layer pool1
I0416 17:32:42.562348 22622 net.cpp:408] pool1 <- conv1
I0416 17:32:42.562351 22622 net.cpp:382] pool1 -> pool1
I0416 17:32:42.562397 22622 net.cpp:124] Setting up pool1
I0416 17:32:42.562400 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.562402 22622 net.cpp:139] Memory required for data: 6029384
I0416 17:32:42.562404 22622 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0416 17:32:42.562409 22622 net.cpp:86] Creating Layer pool1_pool1_0_split
I0416 17:32:42.562412 22622 net.cpp:408] pool1_pool1_0_split <- pool1
I0416 17:32:42.562414 22622 net.cpp:382] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0416 17:32:42.562418 22622 net.cpp:382] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0416 17:32:42.562438 22622 net.cpp:124] Setting up pool1_pool1_0_split
I0416 17:32:42.562443 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.562445 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.562448 22622 net.cpp:139] Memory required for data: 6553672
I0416 17:32:42.562449 22622 layer_factory.hpp:77] Creating layer res2a_branch1
I0416 17:32:42.562456 22622 net.cpp:86] Creating Layer res2a_branch1
I0416 17:32:42.562459 22622 net.cpp:408] res2a_branch1 <- pool1_pool1_0_split_0
I0416 17:32:42.562463 22622 net.cpp:382] res2a_branch1 -> res2a_branch1
I0416 17:32:42.563602 22622 net.cpp:124] Setting up res2a_branch1
I0416 17:32:42.563611 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.563614 22622 net.cpp:139] Memory required for data: 6815816
I0416 17:32:42.563617 22622 layer_factory.hpp:77] Creating layer bn2a_branch1
I0416 17:32:42.563622 22622 net.cpp:86] Creating Layer bn2a_branch1
I0416 17:32:42.563624 22622 net.cpp:408] bn2a_branch1 <- res2a_branch1
I0416 17:32:42.563628 22622 net.cpp:369] bn2a_branch1 -> res2a_branch1 (in-place)
I0416 17:32:42.563730 22622 net.cpp:124] Setting up bn2a_branch1
I0416 17:32:42.563735 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.563736 22622 net.cpp:139] Memory required for data: 7077960
I0416 17:32:42.563742 22622 layer_factory.hpp:77] Creating layer scale2a_branch1
I0416 17:32:42.563747 22622 net.cpp:86] Creating Layer scale2a_branch1
I0416 17:32:42.563750 22622 net.cpp:408] scale2a_branch1 <- res2a_branch1
I0416 17:32:42.563752 22622 net.cpp:369] scale2a_branch1 -> res2a_branch1 (in-place)
I0416 17:32:42.563772 22622 layer_factory.hpp:77] Creating layer scale2a_branch1
I0416 17:32:42.563830 22622 net.cpp:124] Setting up scale2a_branch1
I0416 17:32:42.563834 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.563836 22622 net.cpp:139] Memory required for data: 7340104
I0416 17:32:42.563840 22622 layer_factory.hpp:77] Creating layer res2a_branch2a
I0416 17:32:42.563845 22622 net.cpp:86] Creating Layer res2a_branch2a
I0416 17:32:42.563848 22622 net.cpp:408] res2a_branch2a <- pool1_pool1_0_split_1
I0416 17:32:42.563851 22622 net.cpp:382] res2a_branch2a -> res2a_branch2a
I0416 17:32:42.565816 22622 net.cpp:124] Setting up res2a_branch2a
I0416 17:32:42.565826 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.565829 22622 net.cpp:139] Memory required for data: 7602248
I0416 17:32:42.565834 22622 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0416 17:32:42.565841 22622 net.cpp:86] Creating Layer bn2a_branch2a
I0416 17:32:42.565845 22622 net.cpp:408] bn2a_branch2a <- res2a_branch2a
I0416 17:32:42.565848 22622 net.cpp:369] bn2a_branch2a -> res2a_branch2a (in-place)
I0416 17:32:42.565954 22622 net.cpp:124] Setting up bn2a_branch2a
I0416 17:32:42.565958 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.565961 22622 net.cpp:139] Memory required for data: 7864392
I0416 17:32:42.565965 22622 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0416 17:32:42.565969 22622 net.cpp:86] Creating Layer scale2a_branch2a
I0416 17:32:42.565971 22622 net.cpp:408] scale2a_branch2a <- res2a_branch2a
I0416 17:32:42.565975 22622 net.cpp:369] scale2a_branch2a -> res2a_branch2a (in-place)
I0416 17:32:42.565995 22622 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0416 17:32:42.566054 22622 net.cpp:124] Setting up scale2a_branch2a
I0416 17:32:42.566059 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.566061 22622 net.cpp:139] Memory required for data: 8126536
I0416 17:32:42.566066 22622 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0416 17:32:42.566071 22622 net.cpp:86] Creating Layer res2a_branch2a_relu
I0416 17:32:42.566072 22622 net.cpp:408] res2a_branch2a_relu <- res2a_branch2a
I0416 17:32:42.566076 22622 net.cpp:369] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0416 17:32:42.566429 22622 net.cpp:124] Setting up res2a_branch2a_relu
I0416 17:32:42.566437 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.566439 22622 net.cpp:139] Memory required for data: 8388680
I0416 17:32:42.566442 22622 layer_factory.hpp:77] Creating layer res2a_branch2b
I0416 17:32:42.566449 22622 net.cpp:86] Creating Layer res2a_branch2b
I0416 17:32:42.566452 22622 net.cpp:408] res2a_branch2b <- res2a_branch2a
I0416 17:32:42.566455 22622 net.cpp:382] res2a_branch2b -> res2a_branch2b
I0416 17:32:42.567529 22622 net.cpp:124] Setting up res2a_branch2b
I0416 17:32:42.567538 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.567540 22622 net.cpp:139] Memory required for data: 8650824
I0416 17:32:42.567543 22622 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0416 17:32:42.567548 22622 net.cpp:86] Creating Layer bn2a_branch2b
I0416 17:32:42.567551 22622 net.cpp:408] bn2a_branch2b <- res2a_branch2b
I0416 17:32:42.567554 22622 net.cpp:369] bn2a_branch2b -> res2a_branch2b (in-place)
I0416 17:32:42.567658 22622 net.cpp:124] Setting up bn2a_branch2b
I0416 17:32:42.567662 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.567664 22622 net.cpp:139] Memory required for data: 8912968
I0416 17:32:42.567668 22622 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0416 17:32:42.567672 22622 net.cpp:86] Creating Layer scale2a_branch2b
I0416 17:32:42.567675 22622 net.cpp:408] scale2a_branch2b <- res2a_branch2b
I0416 17:32:42.567679 22622 net.cpp:369] scale2a_branch2b -> res2a_branch2b (in-place)
I0416 17:32:42.567698 22622 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0416 17:32:42.567757 22622 net.cpp:124] Setting up scale2a_branch2b
I0416 17:32:42.567761 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.567764 22622 net.cpp:139] Memory required for data: 9175112
I0416 17:32:42.567767 22622 layer_factory.hpp:77] Creating layer res2a
I0416 17:32:42.567782 22622 net.cpp:86] Creating Layer res2a
I0416 17:32:42.567785 22622 net.cpp:408] res2a <- res2a_branch1
I0416 17:32:42.567787 22622 net.cpp:408] res2a <- res2a_branch2b
I0416 17:32:42.567790 22622 net.cpp:382] res2a -> res2a
I0416 17:32:42.567816 22622 net.cpp:124] Setting up res2a
I0416 17:32:42.567818 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.567821 22622 net.cpp:139] Memory required for data: 9437256
I0416 17:32:42.567823 22622 layer_factory.hpp:77] Creating layer res2a_relu
I0416 17:32:42.567827 22622 net.cpp:86] Creating Layer res2a_relu
I0416 17:32:42.567831 22622 net.cpp:408] res2a_relu <- res2a
I0416 17:32:42.567832 22622 net.cpp:369] res2a_relu -> res2a (in-place)
I0416 17:32:42.568193 22622 net.cpp:124] Setting up res2a_relu
I0416 17:32:42.568205 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.568208 22622 net.cpp:139] Memory required for data: 9699400
I0416 17:32:42.568210 22622 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0416 17:32:42.568214 22622 net.cpp:86] Creating Layer res2a_res2a_relu_0_split
I0416 17:32:42.568217 22622 net.cpp:408] res2a_res2a_relu_0_split <- res2a
I0416 17:32:42.568220 22622 net.cpp:382] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0416 17:32:42.568225 22622 net.cpp:382] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0416 17:32:42.568246 22622 net.cpp:124] Setting up res2a_res2a_relu_0_split
I0416 17:32:42.568249 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.568253 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.568254 22622 net.cpp:139] Memory required for data: 10223688
I0416 17:32:42.568256 22622 layer_factory.hpp:77] Creating layer res2b_branch2a
I0416 17:32:42.568262 22622 net.cpp:86] Creating Layer res2b_branch2a
I0416 17:32:42.568265 22622 net.cpp:408] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0416 17:32:42.568269 22622 net.cpp:382] res2b_branch2a -> res2b_branch2a
I0416 17:32:42.569344 22622 net.cpp:124] Setting up res2b_branch2a
I0416 17:32:42.569353 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.569355 22622 net.cpp:139] Memory required for data: 10485832
I0416 17:32:42.569358 22622 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0416 17:32:42.569362 22622 net.cpp:86] Creating Layer bn2b_branch2a
I0416 17:32:42.569365 22622 net.cpp:408] bn2b_branch2a <- res2b_branch2a
I0416 17:32:42.569370 22622 net.cpp:369] bn2b_branch2a -> res2b_branch2a (in-place)
I0416 17:32:42.569473 22622 net.cpp:124] Setting up bn2b_branch2a
I0416 17:32:42.569476 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.569478 22622 net.cpp:139] Memory required for data: 10747976
I0416 17:32:42.569483 22622 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0416 17:32:42.569486 22622 net.cpp:86] Creating Layer scale2b_branch2a
I0416 17:32:42.569489 22622 net.cpp:408] scale2b_branch2a <- res2b_branch2a
I0416 17:32:42.569491 22622 net.cpp:369] scale2b_branch2a -> res2b_branch2a (in-place)
I0416 17:32:42.569511 22622 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0416 17:32:42.569572 22622 net.cpp:124] Setting up scale2b_branch2a
I0416 17:32:42.569576 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.569579 22622 net.cpp:139] Memory required for data: 11010120
I0416 17:32:42.569582 22622 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0416 17:32:42.569586 22622 net.cpp:86] Creating Layer res2b_branch2a_relu
I0416 17:32:42.569588 22622 net.cpp:408] res2b_branch2a_relu <- res2b_branch2a
I0416 17:32:42.569592 22622 net.cpp:369] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0416 17:32:42.569936 22622 net.cpp:124] Setting up res2b_branch2a_relu
I0416 17:32:42.569944 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.569947 22622 net.cpp:139] Memory required for data: 11272264
I0416 17:32:42.569949 22622 layer_factory.hpp:77] Creating layer res2b_branch2b
I0416 17:32:42.569954 22622 net.cpp:86] Creating Layer res2b_branch2b
I0416 17:32:42.569957 22622 net.cpp:408] res2b_branch2b <- res2b_branch2a
I0416 17:32:42.569962 22622 net.cpp:382] res2b_branch2b -> res2b_branch2b
I0416 17:32:42.571764 22622 net.cpp:124] Setting up res2b_branch2b
I0416 17:32:42.571775 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.571779 22622 net.cpp:139] Memory required for data: 11534408
I0416 17:32:42.571781 22622 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0416 17:32:42.571786 22622 net.cpp:86] Creating Layer bn2b_branch2b
I0416 17:32:42.571789 22622 net.cpp:408] bn2b_branch2b <- res2b_branch2b
I0416 17:32:42.571792 22622 net.cpp:369] bn2b_branch2b -> res2b_branch2b (in-place)
I0416 17:32:42.571899 22622 net.cpp:124] Setting up bn2b_branch2b
I0416 17:32:42.571903 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.571905 22622 net.cpp:139] Memory required for data: 11796552
I0416 17:32:42.571916 22622 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0416 17:32:42.571920 22622 net.cpp:86] Creating Layer scale2b_branch2b
I0416 17:32:42.571923 22622 net.cpp:408] scale2b_branch2b <- res2b_branch2b
I0416 17:32:42.571928 22622 net.cpp:369] scale2b_branch2b -> res2b_branch2b (in-place)
I0416 17:32:42.571947 22622 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0416 17:32:42.572008 22622 net.cpp:124] Setting up scale2b_branch2b
I0416 17:32:42.572012 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.572015 22622 net.cpp:139] Memory required for data: 12058696
I0416 17:32:42.572018 22622 layer_factory.hpp:77] Creating layer res2b
I0416 17:32:42.572021 22622 net.cpp:86] Creating Layer res2b
I0416 17:32:42.572024 22622 net.cpp:408] res2b <- res2a_res2a_relu_0_split_1
I0416 17:32:42.572027 22622 net.cpp:408] res2b <- res2b_branch2b
I0416 17:32:42.572031 22622 net.cpp:382] res2b -> res2b
I0416 17:32:42.572041 22622 net.cpp:124] Setting up res2b
I0416 17:32:42.572043 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.572046 22622 net.cpp:139] Memory required for data: 12320840
I0416 17:32:42.572047 22622 layer_factory.hpp:77] Creating layer res2b_relu
I0416 17:32:42.572053 22622 net.cpp:86] Creating Layer res2b_relu
I0416 17:32:42.572057 22622 net.cpp:408] res2b_relu <- res2b
I0416 17:32:42.572059 22622 net.cpp:369] res2b_relu -> res2b (in-place)
I0416 17:32:42.572329 22622 net.cpp:124] Setting up res2b_relu
I0416 17:32:42.572335 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.572337 22622 net.cpp:139] Memory required for data: 12582984
I0416 17:32:42.572340 22622 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0416 17:32:42.572343 22622 net.cpp:86] Creating Layer res2b_res2b_relu_0_split
I0416 17:32:42.572345 22622 net.cpp:408] res2b_res2b_relu_0_split <- res2b
I0416 17:32:42.572350 22622 net.cpp:382] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0416 17:32:42.572353 22622 net.cpp:382] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0416 17:32:42.572374 22622 net.cpp:124] Setting up res2b_res2b_relu_0_split
I0416 17:32:42.572377 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.572381 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.572382 22622 net.cpp:139] Memory required for data: 13107272
I0416 17:32:42.572386 22622 layer_factory.hpp:77] Creating layer res2c_branch2a
I0416 17:32:42.572392 22622 net.cpp:86] Creating Layer res2c_branch2a
I0416 17:32:42.572396 22622 net.cpp:408] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0416 17:32:42.572398 22622 net.cpp:382] res2c_branch2a -> res2c_branch2a
I0416 17:32:42.573642 22622 net.cpp:124] Setting up res2c_branch2a
I0416 17:32:42.573650 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.573652 22622 net.cpp:139] Memory required for data: 13369416
I0416 17:32:42.573657 22622 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0416 17:32:42.573660 22622 net.cpp:86] Creating Layer bn2c_branch2a
I0416 17:32:42.573663 22622 net.cpp:408] bn2c_branch2a <- res2c_branch2a
I0416 17:32:42.573666 22622 net.cpp:369] bn2c_branch2a -> res2c_branch2a (in-place)
I0416 17:32:42.573770 22622 net.cpp:124] Setting up bn2c_branch2a
I0416 17:32:42.573774 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.573776 22622 net.cpp:139] Memory required for data: 13631560
I0416 17:32:42.573781 22622 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0416 17:32:42.573784 22622 net.cpp:86] Creating Layer scale2c_branch2a
I0416 17:32:42.573786 22622 net.cpp:408] scale2c_branch2a <- res2c_branch2a
I0416 17:32:42.573791 22622 net.cpp:369] scale2c_branch2a -> res2c_branch2a (in-place)
I0416 17:32:42.573810 22622 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0416 17:32:42.573870 22622 net.cpp:124] Setting up scale2c_branch2a
I0416 17:32:42.573874 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.573876 22622 net.cpp:139] Memory required for data: 13893704
I0416 17:32:42.573884 22622 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0416 17:32:42.573887 22622 net.cpp:86] Creating Layer res2c_branch2a_relu
I0416 17:32:42.573889 22622 net.cpp:408] res2c_branch2a_relu <- res2c_branch2a
I0416 17:32:42.573892 22622 net.cpp:369] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0416 17:32:42.574241 22622 net.cpp:124] Setting up res2c_branch2a_relu
I0416 17:32:42.574249 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.574250 22622 net.cpp:139] Memory required for data: 14155848
I0416 17:32:42.574254 22622 layer_factory.hpp:77] Creating layer res2c_branch2b
I0416 17:32:42.574259 22622 net.cpp:86] Creating Layer res2c_branch2b
I0416 17:32:42.574261 22622 net.cpp:408] res2c_branch2b <- res2c_branch2a
I0416 17:32:42.574265 22622 net.cpp:382] res2c_branch2b -> res2c_branch2b
I0416 17:32:42.576007 22622 net.cpp:124] Setting up res2c_branch2b
I0416 17:32:42.576018 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.576020 22622 net.cpp:139] Memory required for data: 14417992
I0416 17:32:42.576025 22622 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0416 17:32:42.576028 22622 net.cpp:86] Creating Layer bn2c_branch2b
I0416 17:32:42.576031 22622 net.cpp:408] bn2c_branch2b <- res2c_branch2b
I0416 17:32:42.576035 22622 net.cpp:369] bn2c_branch2b -> res2c_branch2b (in-place)
I0416 17:32:42.576174 22622 net.cpp:124] Setting up bn2c_branch2b
I0416 17:32:42.576179 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.576181 22622 net.cpp:139] Memory required for data: 14680136
I0416 17:32:42.576186 22622 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0416 17:32:42.576189 22622 net.cpp:86] Creating Layer scale2c_branch2b
I0416 17:32:42.576192 22622 net.cpp:408] scale2c_branch2b <- res2c_branch2b
I0416 17:32:42.576195 22622 net.cpp:369] scale2c_branch2b -> res2c_branch2b (in-place)
I0416 17:32:42.576217 22622 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0416 17:32:42.576277 22622 net.cpp:124] Setting up scale2c_branch2b
I0416 17:32:42.576282 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.576283 22622 net.cpp:139] Memory required for data: 14942280
I0416 17:32:42.576287 22622 layer_factory.hpp:77] Creating layer res2c
I0416 17:32:42.576290 22622 net.cpp:86] Creating Layer res2c
I0416 17:32:42.576292 22622 net.cpp:408] res2c <- res2b_res2b_relu_0_split_1
I0416 17:32:42.576295 22622 net.cpp:408] res2c <- res2c_branch2b
I0416 17:32:42.576298 22622 net.cpp:382] res2c -> res2c
I0416 17:32:42.576309 22622 net.cpp:124] Setting up res2c
I0416 17:32:42.576313 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.576314 22622 net.cpp:139] Memory required for data: 15204424
I0416 17:32:42.576318 22622 layer_factory.hpp:77] Creating layer res2c_relu
I0416 17:32:42.576320 22622 net.cpp:86] Creating Layer res2c_relu
I0416 17:32:42.576323 22622 net.cpp:408] res2c_relu <- res2c
I0416 17:32:42.576326 22622 net.cpp:369] res2c_relu -> res2c (in-place)
I0416 17:32:42.576687 22622 net.cpp:124] Setting up res2c_relu
I0416 17:32:42.576695 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.576697 22622 net.cpp:139] Memory required for data: 15466568
I0416 17:32:42.576699 22622 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0416 17:32:42.576704 22622 net.cpp:86] Creating Layer res2c_res2c_relu_0_split
I0416 17:32:42.576706 22622 net.cpp:408] res2c_res2c_relu_0_split <- res2c
I0416 17:32:42.576709 22622 net.cpp:382] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0416 17:32:42.576714 22622 net.cpp:382] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0416 17:32:42.576735 22622 net.cpp:124] Setting up res2c_res2c_relu_0_split
I0416 17:32:42.576738 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.576741 22622 net.cpp:131] Top shape: 1 16 64 64 (65536)
I0416 17:32:42.576743 22622 net.cpp:139] Memory required for data: 15990856
I0416 17:32:42.576745 22622 layer_factory.hpp:77] Creating layer res3a_branch1
I0416 17:32:42.576751 22622 net.cpp:86] Creating Layer res3a_branch1
I0416 17:32:42.576755 22622 net.cpp:408] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0416 17:32:42.576761 22622 net.cpp:382] res3a_branch1 -> res3a_branch1
I0416 17:32:42.577814 22622 net.cpp:124] Setting up res3a_branch1
I0416 17:32:42.577822 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.577826 22622 net.cpp:139] Memory required for data: 16121928
I0416 17:32:42.577828 22622 layer_factory.hpp:77] Creating layer bn3a_branch1
I0416 17:32:42.577833 22622 net.cpp:86] Creating Layer bn3a_branch1
I0416 17:32:42.577836 22622 net.cpp:408] bn3a_branch1 <- res3a_branch1
I0416 17:32:42.577839 22622 net.cpp:369] bn3a_branch1 -> res3a_branch1 (in-place)
I0416 17:32:42.577944 22622 net.cpp:124] Setting up bn3a_branch1
I0416 17:32:42.577949 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.577950 22622 net.cpp:139] Memory required for data: 16253000
I0416 17:32:42.577955 22622 layer_factory.hpp:77] Creating layer scale3a_branch1
I0416 17:32:42.577960 22622 net.cpp:86] Creating Layer scale3a_branch1
I0416 17:32:42.577961 22622 net.cpp:408] scale3a_branch1 <- res3a_branch1
I0416 17:32:42.577965 22622 net.cpp:369] scale3a_branch1 -> res3a_branch1 (in-place)
I0416 17:32:42.577986 22622 layer_factory.hpp:77] Creating layer scale3a_branch1
I0416 17:32:42.578043 22622 net.cpp:124] Setting up scale3a_branch1
I0416 17:32:42.578047 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.578049 22622 net.cpp:139] Memory required for data: 16384072
I0416 17:32:42.578052 22622 layer_factory.hpp:77] Creating layer res3a_branch2a
I0416 17:32:42.578058 22622 net.cpp:86] Creating Layer res3a_branch2a
I0416 17:32:42.578060 22622 net.cpp:408] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0416 17:32:42.578063 22622 net.cpp:382] res3a_branch2a -> res3a_branch2a
I0416 17:32:42.579236 22622 net.cpp:124] Setting up res3a_branch2a
I0416 17:32:42.579244 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.579247 22622 net.cpp:139] Memory required for data: 16515144
I0416 17:32:42.579250 22622 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0416 17:32:42.579254 22622 net.cpp:86] Creating Layer bn3a_branch2a
I0416 17:32:42.579258 22622 net.cpp:408] bn3a_branch2a <- res3a_branch2a
I0416 17:32:42.579262 22622 net.cpp:369] bn3a_branch2a -> res3a_branch2a (in-place)
I0416 17:32:42.579363 22622 net.cpp:124] Setting up bn3a_branch2a
I0416 17:32:42.579367 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.579370 22622 net.cpp:139] Memory required for data: 16646216
I0416 17:32:42.579375 22622 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0416 17:32:42.579378 22622 net.cpp:86] Creating Layer scale3a_branch2a
I0416 17:32:42.579381 22622 net.cpp:408] scale3a_branch2a <- res3a_branch2a
I0416 17:32:42.579385 22622 net.cpp:369] scale3a_branch2a -> res3a_branch2a (in-place)
I0416 17:32:42.579406 22622 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0416 17:32:42.579463 22622 net.cpp:124] Setting up scale3a_branch2a
I0416 17:32:42.579468 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.579469 22622 net.cpp:139] Memory required for data: 16777288
I0416 17:32:42.579473 22622 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0416 17:32:42.579476 22622 net.cpp:86] Creating Layer res3a_branch2a_relu
I0416 17:32:42.579479 22622 net.cpp:408] res3a_branch2a_relu <- res3a_branch2a
I0416 17:32:42.579481 22622 net.cpp:369] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0416 17:32:42.579737 22622 net.cpp:124] Setting up res3a_branch2a_relu
I0416 17:32:42.579743 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.579746 22622 net.cpp:139] Memory required for data: 16908360
I0416 17:32:42.579748 22622 layer_factory.hpp:77] Creating layer res3a_branch2b
I0416 17:32:42.579753 22622 net.cpp:86] Creating Layer res3a_branch2b
I0416 17:32:42.579756 22622 net.cpp:408] res3a_branch2b <- res3a_branch2a
I0416 17:32:42.579759 22622 net.cpp:382] res3a_branch2b -> res3a_branch2b
I0416 17:32:42.581681 22622 net.cpp:124] Setting up res3a_branch2b
I0416 17:32:42.581691 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.581697 22622 net.cpp:139] Memory required for data: 17039432
I0416 17:32:42.581702 22622 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0416 17:32:42.581707 22622 net.cpp:86] Creating Layer bn3a_branch2b
I0416 17:32:42.581709 22622 net.cpp:408] bn3a_branch2b <- res3a_branch2b
I0416 17:32:42.581714 22622 net.cpp:369] bn3a_branch2b -> res3a_branch2b (in-place)
I0416 17:32:42.581820 22622 net.cpp:124] Setting up bn3a_branch2b
I0416 17:32:42.581823 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.581825 22622 net.cpp:139] Memory required for data: 17170504
I0416 17:32:42.581830 22622 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0416 17:32:42.581835 22622 net.cpp:86] Creating Layer scale3a_branch2b
I0416 17:32:42.581836 22622 net.cpp:408] scale3a_branch2b <- res3a_branch2b
I0416 17:32:42.581840 22622 net.cpp:369] scale3a_branch2b -> res3a_branch2b (in-place)
I0416 17:32:42.581861 22622 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0416 17:32:42.581916 22622 net.cpp:124] Setting up scale3a_branch2b
I0416 17:32:42.581920 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.581923 22622 net.cpp:139] Memory required for data: 17301576
I0416 17:32:42.581933 22622 layer_factory.hpp:77] Creating layer res3a
I0416 17:32:42.581938 22622 net.cpp:86] Creating Layer res3a
I0416 17:32:42.581939 22622 net.cpp:408] res3a <- res3a_branch1
I0416 17:32:42.581943 22622 net.cpp:408] res3a <- res3a_branch2b
I0416 17:32:42.581945 22622 net.cpp:382] res3a -> res3a
I0416 17:32:42.581955 22622 net.cpp:124] Setting up res3a
I0416 17:32:42.581959 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.581961 22622 net.cpp:139] Memory required for data: 17432648
I0416 17:32:42.581964 22622 layer_factory.hpp:77] Creating layer res3a_relu
I0416 17:32:42.581966 22622 net.cpp:86] Creating Layer res3a_relu
I0416 17:32:42.581969 22622 net.cpp:408] res3a_relu <- res3a
I0416 17:32:42.581971 22622 net.cpp:369] res3a_relu -> res3a (in-place)
I0416 17:32:42.582320 22622 net.cpp:124] Setting up res3a_relu
I0416 17:32:42.582329 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.582331 22622 net.cpp:139] Memory required for data: 17563720
I0416 17:32:42.582334 22622 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0416 17:32:42.582337 22622 net.cpp:86] Creating Layer res3a_res3a_relu_0_split
I0416 17:32:42.582340 22622 net.cpp:408] res3a_res3a_relu_0_split <- res3a
I0416 17:32:42.582343 22622 net.cpp:382] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0416 17:32:42.582347 22622 net.cpp:382] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0416 17:32:42.582368 22622 net.cpp:124] Setting up res3a_res3a_relu_0_split
I0416 17:32:42.582372 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.582374 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.582377 22622 net.cpp:139] Memory required for data: 17825864
I0416 17:32:42.582379 22622 layer_factory.hpp:77] Creating layer res3b_branch2a
I0416 17:32:42.582386 22622 net.cpp:86] Creating Layer res3b_branch2a
I0416 17:32:42.582387 22622 net.cpp:408] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0416 17:32:42.582391 22622 net.cpp:382] res3b_branch2a -> res3b_branch2a
I0416 17:32:42.583545 22622 net.cpp:124] Setting up res3b_branch2a
I0416 17:32:42.583554 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.583556 22622 net.cpp:139] Memory required for data: 17956936
I0416 17:32:42.583560 22622 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0416 17:32:42.583565 22622 net.cpp:86] Creating Layer bn3b_branch2a
I0416 17:32:42.583568 22622 net.cpp:408] bn3b_branch2a <- res3b_branch2a
I0416 17:32:42.583571 22622 net.cpp:369] bn3b_branch2a -> res3b_branch2a (in-place)
I0416 17:32:42.583674 22622 net.cpp:124] Setting up bn3b_branch2a
I0416 17:32:42.583678 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.583681 22622 net.cpp:139] Memory required for data: 18088008
I0416 17:32:42.583685 22622 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0416 17:32:42.583693 22622 net.cpp:86] Creating Layer scale3b_branch2a
I0416 17:32:42.583695 22622 net.cpp:408] scale3b_branch2a <- res3b_branch2a
I0416 17:32:42.583698 22622 net.cpp:369] scale3b_branch2a -> res3b_branch2a (in-place)
I0416 17:32:42.583719 22622 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0416 17:32:42.583779 22622 net.cpp:124] Setting up scale3b_branch2a
I0416 17:32:42.583783 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.583786 22622 net.cpp:139] Memory required for data: 18219080
I0416 17:32:42.583789 22622 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0416 17:32:42.583793 22622 net.cpp:86] Creating Layer res3b_branch2a_relu
I0416 17:32:42.583796 22622 net.cpp:408] res3b_branch2a_relu <- res3b_branch2a
I0416 17:32:42.583798 22622 net.cpp:369] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0416 17:32:42.584149 22622 net.cpp:124] Setting up res3b_branch2a_relu
I0416 17:32:42.584158 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.584161 22622 net.cpp:139] Memory required for data: 18350152
I0416 17:32:42.584163 22622 layer_factory.hpp:77] Creating layer res3b_branch2b
I0416 17:32:42.584168 22622 net.cpp:86] Creating Layer res3b_branch2b
I0416 17:32:42.584172 22622 net.cpp:408] res3b_branch2b <- res3b_branch2a
I0416 17:32:42.584174 22622 net.cpp:382] res3b_branch2b -> res3b_branch2b
I0416 17:32:42.585425 22622 net.cpp:124] Setting up res3b_branch2b
I0416 17:32:42.585435 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.585438 22622 net.cpp:139] Memory required for data: 18481224
I0416 17:32:42.585441 22622 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0416 17:32:42.585445 22622 net.cpp:86] Creating Layer bn3b_branch2b
I0416 17:32:42.585448 22622 net.cpp:408] bn3b_branch2b <- res3b_branch2b
I0416 17:32:42.585451 22622 net.cpp:369] bn3b_branch2b -> res3b_branch2b (in-place)
I0416 17:32:42.585559 22622 net.cpp:124] Setting up bn3b_branch2b
I0416 17:32:42.585563 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.585566 22622 net.cpp:139] Memory required for data: 18612296
I0416 17:32:42.585570 22622 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0416 17:32:42.585574 22622 net.cpp:86] Creating Layer scale3b_branch2b
I0416 17:32:42.585577 22622 net.cpp:408] scale3b_branch2b <- res3b_branch2b
I0416 17:32:42.585579 22622 net.cpp:369] scale3b_branch2b -> res3b_branch2b (in-place)
I0416 17:32:42.585599 22622 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0416 17:32:42.585657 22622 net.cpp:124] Setting up scale3b_branch2b
I0416 17:32:42.585661 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.585664 22622 net.cpp:139] Memory required for data: 18743368
I0416 17:32:42.585667 22622 layer_factory.hpp:77] Creating layer res3b
I0416 17:32:42.585671 22622 net.cpp:86] Creating Layer res3b
I0416 17:32:42.585673 22622 net.cpp:408] res3b <- res3a_res3a_relu_0_split_1
I0416 17:32:42.585676 22622 net.cpp:408] res3b <- res3b_branch2b
I0416 17:32:42.585680 22622 net.cpp:382] res3b -> res3b
I0416 17:32:42.585690 22622 net.cpp:124] Setting up res3b
I0416 17:32:42.585692 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.585695 22622 net.cpp:139] Memory required for data: 18874440
I0416 17:32:42.585697 22622 layer_factory.hpp:77] Creating layer res3b_relu
I0416 17:32:42.585701 22622 net.cpp:86] Creating Layer res3b_relu
I0416 17:32:42.585703 22622 net.cpp:408] res3b_relu <- res3b
I0416 17:32:42.585706 22622 net.cpp:369] res3b_relu -> res3b (in-place)
I0416 17:32:42.586701 22622 net.cpp:124] Setting up res3b_relu
I0416 17:32:42.586710 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.586712 22622 net.cpp:139] Memory required for data: 19005512
I0416 17:32:42.586715 22622 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0416 17:32:42.586724 22622 net.cpp:86] Creating Layer res3b_res3b_relu_0_split
I0416 17:32:42.586725 22622 net.cpp:408] res3b_res3b_relu_0_split <- res3b
I0416 17:32:42.586730 22622 net.cpp:382] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0416 17:32:42.586733 22622 net.cpp:382] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0416 17:32:42.586760 22622 net.cpp:124] Setting up res3b_res3b_relu_0_split
I0416 17:32:42.586764 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.586766 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.586768 22622 net.cpp:139] Memory required for data: 19267656
I0416 17:32:42.586771 22622 layer_factory.hpp:77] Creating layer res3c_branch2a
I0416 17:32:42.586776 22622 net.cpp:86] Creating Layer res3c_branch2a
I0416 17:32:42.586779 22622 net.cpp:408] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0416 17:32:42.586782 22622 net.cpp:382] res3c_branch2a -> res3c_branch2a
I0416 17:32:42.587954 22622 net.cpp:124] Setting up res3c_branch2a
I0416 17:32:42.587963 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.587965 22622 net.cpp:139] Memory required for data: 19398728
I0416 17:32:42.587970 22622 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0416 17:32:42.587975 22622 net.cpp:86] Creating Layer bn3c_branch2a
I0416 17:32:42.587977 22622 net.cpp:408] bn3c_branch2a <- res3c_branch2a
I0416 17:32:42.587980 22622 net.cpp:369] bn3c_branch2a -> res3c_branch2a (in-place)
I0416 17:32:42.588086 22622 net.cpp:124] Setting up bn3c_branch2a
I0416 17:32:42.588090 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.588093 22622 net.cpp:139] Memory required for data: 19529800
I0416 17:32:42.588097 22622 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0416 17:32:42.588101 22622 net.cpp:86] Creating Layer scale3c_branch2a
I0416 17:32:42.588105 22622 net.cpp:408] scale3c_branch2a <- res3c_branch2a
I0416 17:32:42.588109 22622 net.cpp:369] scale3c_branch2a -> res3c_branch2a (in-place)
I0416 17:32:42.588143 22622 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0416 17:32:42.588202 22622 net.cpp:124] Setting up scale3c_branch2a
I0416 17:32:42.588207 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.588208 22622 net.cpp:139] Memory required for data: 19660872
I0416 17:32:42.588212 22622 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0416 17:32:42.588217 22622 net.cpp:86] Creating Layer res3c_branch2a_relu
I0416 17:32:42.588218 22622 net.cpp:408] res3c_branch2a_relu <- res3c_branch2a
I0416 17:32:42.588222 22622 net.cpp:369] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0416 17:32:42.588568 22622 net.cpp:124] Setting up res3c_branch2a_relu
I0416 17:32:42.588577 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.588578 22622 net.cpp:139] Memory required for data: 19791944
I0416 17:32:42.588580 22622 layer_factory.hpp:77] Creating layer res3c_branch2b
I0416 17:32:42.588587 22622 net.cpp:86] Creating Layer res3c_branch2b
I0416 17:32:42.588589 22622 net.cpp:408] res3c_branch2b <- res3c_branch2a
I0416 17:32:42.588593 22622 net.cpp:382] res3c_branch2b -> res3c_branch2b
I0416 17:32:42.589834 22622 net.cpp:124] Setting up res3c_branch2b
I0416 17:32:42.589843 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.589845 22622 net.cpp:139] Memory required for data: 19923016
I0416 17:32:42.589848 22622 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0416 17:32:42.589854 22622 net.cpp:86] Creating Layer bn3c_branch2b
I0416 17:32:42.589856 22622 net.cpp:408] bn3c_branch2b <- res3c_branch2b
I0416 17:32:42.589859 22622 net.cpp:369] bn3c_branch2b -> res3c_branch2b (in-place)
I0416 17:32:42.589964 22622 net.cpp:124] Setting up bn3c_branch2b
I0416 17:32:42.589968 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.589970 22622 net.cpp:139] Memory required for data: 20054088
I0416 17:32:42.589974 22622 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0416 17:32:42.589979 22622 net.cpp:86] Creating Layer scale3c_branch2b
I0416 17:32:42.589982 22622 net.cpp:408] scale3c_branch2b <- res3c_branch2b
I0416 17:32:42.589984 22622 net.cpp:369] scale3c_branch2b -> res3c_branch2b (in-place)
I0416 17:32:42.590004 22622 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0416 17:32:42.590062 22622 net.cpp:124] Setting up scale3c_branch2b
I0416 17:32:42.590066 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.590072 22622 net.cpp:139] Memory required for data: 20185160
I0416 17:32:42.590076 22622 layer_factory.hpp:77] Creating layer res3c
I0416 17:32:42.590080 22622 net.cpp:86] Creating Layer res3c
I0416 17:32:42.590082 22622 net.cpp:408] res3c <- res3b_res3b_relu_0_split_1
I0416 17:32:42.590085 22622 net.cpp:408] res3c <- res3c_branch2b
I0416 17:32:42.590088 22622 net.cpp:382] res3c -> res3c
I0416 17:32:42.590101 22622 net.cpp:124] Setting up res3c
I0416 17:32:42.590106 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.590107 22622 net.cpp:139] Memory required for data: 20316232
I0416 17:32:42.590109 22622 layer_factory.hpp:77] Creating layer res3c_relu
I0416 17:32:42.590113 22622 net.cpp:86] Creating Layer res3c_relu
I0416 17:32:42.590116 22622 net.cpp:408] res3c_relu <- res3c
I0416 17:32:42.590121 22622 net.cpp:369] res3c_relu -> res3c (in-place)
I0416 17:32:42.590382 22622 net.cpp:124] Setting up res3c_relu
I0416 17:32:42.590389 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.590390 22622 net.cpp:139] Memory required for data: 20447304
I0416 17:32:42.590392 22622 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0416 17:32:42.590396 22622 net.cpp:86] Creating Layer res3c_res3c_relu_0_split
I0416 17:32:42.590399 22622 net.cpp:408] res3c_res3c_relu_0_split <- res3c
I0416 17:32:42.590402 22622 net.cpp:382] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0416 17:32:42.590405 22622 net.cpp:382] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0416 17:32:42.590426 22622 net.cpp:124] Setting up res3c_res3c_relu_0_split
I0416 17:32:42.590430 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.590432 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.590435 22622 net.cpp:139] Memory required for data: 20709448
I0416 17:32:42.590436 22622 layer_factory.hpp:77] Creating layer res3d_branch2a
I0416 17:32:42.590441 22622 net.cpp:86] Creating Layer res3d_branch2a
I0416 17:32:42.590445 22622 net.cpp:408] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0416 17:32:42.590448 22622 net.cpp:382] res3d_branch2a -> res3d_branch2a
I0416 17:32:42.592360 22622 net.cpp:124] Setting up res3d_branch2a
I0416 17:32:42.592371 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.592375 22622 net.cpp:139] Memory required for data: 20840520
I0416 17:32:42.592378 22622 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0416 17:32:42.592383 22622 net.cpp:86] Creating Layer bn3d_branch2a
I0416 17:32:42.592387 22622 net.cpp:408] bn3d_branch2a <- res3d_branch2a
I0416 17:32:42.592391 22622 net.cpp:369] bn3d_branch2a -> res3d_branch2a (in-place)
I0416 17:32:42.592497 22622 net.cpp:124] Setting up bn3d_branch2a
I0416 17:32:42.592501 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.592504 22622 net.cpp:139] Memory required for data: 20971592
I0416 17:32:42.592509 22622 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0416 17:32:42.592512 22622 net.cpp:86] Creating Layer scale3d_branch2a
I0416 17:32:42.592514 22622 net.cpp:408] scale3d_branch2a <- res3d_branch2a
I0416 17:32:42.592517 22622 net.cpp:369] scale3d_branch2a -> res3d_branch2a (in-place)
I0416 17:32:42.592538 22622 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0416 17:32:42.592597 22622 net.cpp:124] Setting up scale3d_branch2a
I0416 17:32:42.592602 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.592604 22622 net.cpp:139] Memory required for data: 21102664
I0416 17:32:42.592607 22622 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0416 17:32:42.592612 22622 net.cpp:86] Creating Layer res3d_branch2a_relu
I0416 17:32:42.592614 22622 net.cpp:408] res3d_branch2a_relu <- res3d_branch2a
I0416 17:32:42.592617 22622 net.cpp:369] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0416 17:32:42.592877 22622 net.cpp:124] Setting up res3d_branch2a_relu
I0416 17:32:42.592883 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.592885 22622 net.cpp:139] Memory required for data: 21233736
I0416 17:32:42.592892 22622 layer_factory.hpp:77] Creating layer res3d_branch2b
I0416 17:32:42.592897 22622 net.cpp:86] Creating Layer res3d_branch2b
I0416 17:32:42.592900 22622 net.cpp:408] res3d_branch2b <- res3d_branch2a
I0416 17:32:42.592905 22622 net.cpp:382] res3d_branch2b -> res3d_branch2b
I0416 17:32:42.594235 22622 net.cpp:124] Setting up res3d_branch2b
I0416 17:32:42.594244 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.594246 22622 net.cpp:139] Memory required for data: 21364808
I0416 17:32:42.594250 22622 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0416 17:32:42.594255 22622 net.cpp:86] Creating Layer bn3d_branch2b
I0416 17:32:42.594259 22622 net.cpp:408] bn3d_branch2b <- res3d_branch2b
I0416 17:32:42.594261 22622 net.cpp:369] bn3d_branch2b -> res3d_branch2b (in-place)
I0416 17:32:42.594367 22622 net.cpp:124] Setting up bn3d_branch2b
I0416 17:32:42.594370 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.594372 22622 net.cpp:139] Memory required for data: 21495880
I0416 17:32:42.594377 22622 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0416 17:32:42.594381 22622 net.cpp:86] Creating Layer scale3d_branch2b
I0416 17:32:42.594384 22622 net.cpp:408] scale3d_branch2b <- res3d_branch2b
I0416 17:32:42.594388 22622 net.cpp:369] scale3d_branch2b -> res3d_branch2b (in-place)
I0416 17:32:42.594408 22622 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0416 17:32:42.594465 22622 net.cpp:124] Setting up scale3d_branch2b
I0416 17:32:42.594468 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.594470 22622 net.cpp:139] Memory required for data: 21626952
I0416 17:32:42.594473 22622 layer_factory.hpp:77] Creating layer res3d
I0416 17:32:42.594477 22622 net.cpp:86] Creating Layer res3d
I0416 17:32:42.594480 22622 net.cpp:408] res3d <- res3c_res3c_relu_0_split_1
I0416 17:32:42.594482 22622 net.cpp:408] res3d <- res3d_branch2b
I0416 17:32:42.594486 22622 net.cpp:382] res3d -> res3d
I0416 17:32:42.594496 22622 net.cpp:124] Setting up res3d
I0416 17:32:42.594499 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.594501 22622 net.cpp:139] Memory required for data: 21758024
I0416 17:32:42.594503 22622 layer_factory.hpp:77] Creating layer res3d_relu
I0416 17:32:42.594507 22622 net.cpp:86] Creating Layer res3d_relu
I0416 17:32:42.594509 22622 net.cpp:408] res3d_relu <- res3d
I0416 17:32:42.594512 22622 net.cpp:369] res3d_relu -> res3d (in-place)
I0416 17:32:42.594861 22622 net.cpp:124] Setting up res3d_relu
I0416 17:32:42.594867 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.594871 22622 net.cpp:139] Memory required for data: 21889096
I0416 17:32:42.594872 22622 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0416 17:32:42.594877 22622 net.cpp:86] Creating Layer res3d_res3d_relu_0_split
I0416 17:32:42.594879 22622 net.cpp:408] res3d_res3d_relu_0_split <- res3d
I0416 17:32:42.594882 22622 net.cpp:382] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0416 17:32:42.594887 22622 net.cpp:382] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0416 17:32:42.594907 22622 net.cpp:124] Setting up res3d_res3d_relu_0_split
I0416 17:32:42.594911 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.594913 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.594915 22622 net.cpp:139] Memory required for data: 22151240
I0416 17:32:42.594918 22622 layer_factory.hpp:77] Creating layer res4a_branch1
I0416 17:32:42.594923 22622 net.cpp:86] Creating Layer res4a_branch1
I0416 17:32:42.594925 22622 net.cpp:408] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0416 17:32:42.594928 22622 net.cpp:382] res4a_branch1 -> res4a_branch1
I0416 17:32:42.596025 22622 net.cpp:124] Setting up res4a_branch1
I0416 17:32:42.596033 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.596036 22622 net.cpp:139] Memory required for data: 22216776
I0416 17:32:42.596040 22622 layer_factory.hpp:77] Creating layer bn4a_branch1
I0416 17:32:42.596045 22622 net.cpp:86] Creating Layer bn4a_branch1
I0416 17:32:42.596047 22622 net.cpp:408] bn4a_branch1 <- res4a_branch1
I0416 17:32:42.596053 22622 net.cpp:369] bn4a_branch1 -> res4a_branch1 (in-place)
I0416 17:32:42.596163 22622 net.cpp:124] Setting up bn4a_branch1
I0416 17:32:42.596168 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.596170 22622 net.cpp:139] Memory required for data: 22282312
I0416 17:32:42.596174 22622 layer_factory.hpp:77] Creating layer scale4a_branch1
I0416 17:32:42.596179 22622 net.cpp:86] Creating Layer scale4a_branch1
I0416 17:32:42.596181 22622 net.cpp:408] scale4a_branch1 <- res4a_branch1
I0416 17:32:42.596184 22622 net.cpp:369] scale4a_branch1 -> res4a_branch1 (in-place)
I0416 17:32:42.596205 22622 layer_factory.hpp:77] Creating layer scale4a_branch1
I0416 17:32:42.596262 22622 net.cpp:124] Setting up scale4a_branch1
I0416 17:32:42.596266 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.596268 22622 net.cpp:139] Memory required for data: 22347848
I0416 17:32:42.596272 22622 layer_factory.hpp:77] Creating layer res4a_branch2a
I0416 17:32:42.596277 22622 net.cpp:86] Creating Layer res4a_branch2a
I0416 17:32:42.596280 22622 net.cpp:408] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0416 17:32:42.596283 22622 net.cpp:382] res4a_branch2a -> res4a_branch2a
I0416 17:32:42.598332 22622 net.cpp:124] Setting up res4a_branch2a
I0416 17:32:42.598343 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.598345 22622 net.cpp:139] Memory required for data: 22413384
I0416 17:32:42.598349 22622 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0416 17:32:42.598354 22622 net.cpp:86] Creating Layer bn4a_branch2a
I0416 17:32:42.598357 22622 net.cpp:408] bn4a_branch2a <- res4a_branch2a
I0416 17:32:42.598361 22622 net.cpp:369] bn4a_branch2a -> res4a_branch2a (in-place)
I0416 17:32:42.598465 22622 net.cpp:124] Setting up bn4a_branch2a
I0416 17:32:42.598470 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.598472 22622 net.cpp:139] Memory required for data: 22478920
I0416 17:32:42.598477 22622 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0416 17:32:42.598481 22622 net.cpp:86] Creating Layer scale4a_branch2a
I0416 17:32:42.598484 22622 net.cpp:408] scale4a_branch2a <- res4a_branch2a
I0416 17:32:42.598486 22622 net.cpp:369] scale4a_branch2a -> res4a_branch2a (in-place)
I0416 17:32:42.598510 22622 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0416 17:32:42.598567 22622 net.cpp:124] Setting up scale4a_branch2a
I0416 17:32:42.598570 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.598573 22622 net.cpp:139] Memory required for data: 22544456
I0416 17:32:42.598577 22622 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0416 17:32:42.598582 22622 net.cpp:86] Creating Layer res4a_branch2a_relu
I0416 17:32:42.598583 22622 net.cpp:408] res4a_branch2a_relu <- res4a_branch2a
I0416 17:32:42.598587 22622 net.cpp:369] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0416 17:32:42.598841 22622 net.cpp:124] Setting up res4a_branch2a_relu
I0416 17:32:42.598847 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.598850 22622 net.cpp:139] Memory required for data: 22609992
I0416 17:32:42.598852 22622 layer_factory.hpp:77] Creating layer res4a_branch2b
I0416 17:32:42.598860 22622 net.cpp:86] Creating Layer res4a_branch2b
I0416 17:32:42.598862 22622 net.cpp:408] res4a_branch2b <- res4a_branch2a
I0416 17:32:42.598865 22622 net.cpp:382] res4a_branch2b -> res4a_branch2b
I0416 17:32:42.600489 22622 net.cpp:124] Setting up res4a_branch2b
I0416 17:32:42.600498 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.600500 22622 net.cpp:139] Memory required for data: 22675528
I0416 17:32:42.600504 22622 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0416 17:32:42.600508 22622 net.cpp:86] Creating Layer bn4a_branch2b
I0416 17:32:42.600512 22622 net.cpp:408] bn4a_branch2b <- res4a_branch2b
I0416 17:32:42.600514 22622 net.cpp:369] bn4a_branch2b -> res4a_branch2b (in-place)
I0416 17:32:42.600620 22622 net.cpp:124] Setting up bn4a_branch2b
I0416 17:32:42.600623 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.600630 22622 net.cpp:139] Memory required for data: 22741064
I0416 17:32:42.600634 22622 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0416 17:32:42.600638 22622 net.cpp:86] Creating Layer scale4a_branch2b
I0416 17:32:42.600641 22622 net.cpp:408] scale4a_branch2b <- res4a_branch2b
I0416 17:32:42.600643 22622 net.cpp:369] scale4a_branch2b -> res4a_branch2b (in-place)
I0416 17:32:42.600666 22622 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0416 17:32:42.600723 22622 net.cpp:124] Setting up scale4a_branch2b
I0416 17:32:42.600728 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.600729 22622 net.cpp:139] Memory required for data: 22806600
I0416 17:32:42.600733 22622 layer_factory.hpp:77] Creating layer res4a
I0416 17:32:42.600736 22622 net.cpp:86] Creating Layer res4a
I0416 17:32:42.600739 22622 net.cpp:408] res4a <- res4a_branch1
I0416 17:32:42.600741 22622 net.cpp:408] res4a <- res4a_branch2b
I0416 17:32:42.600744 22622 net.cpp:382] res4a -> res4a
I0416 17:32:42.600755 22622 net.cpp:124] Setting up res4a
I0416 17:32:42.600759 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.600760 22622 net.cpp:139] Memory required for data: 22872136
I0416 17:32:42.600762 22622 layer_factory.hpp:77] Creating layer res4a_relu
I0416 17:32:42.600765 22622 net.cpp:86] Creating Layer res4a_relu
I0416 17:32:42.600769 22622 net.cpp:408] res4a_relu <- res4a
I0416 17:32:42.600771 22622 net.cpp:369] res4a_relu -> res4a (in-place)
I0416 17:32:42.601029 22622 net.cpp:124] Setting up res4a_relu
I0416 17:32:42.601037 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.601039 22622 net.cpp:139] Memory required for data: 22937672
I0416 17:32:42.601042 22622 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0416 17:32:42.601047 22622 net.cpp:86] Creating Layer res4a_res4a_relu_0_split
I0416 17:32:42.601049 22622 net.cpp:408] res4a_res4a_relu_0_split <- res4a
I0416 17:32:42.601053 22622 net.cpp:382] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0416 17:32:42.601058 22622 net.cpp:382] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0416 17:32:42.601079 22622 net.cpp:124] Setting up res4a_res4a_relu_0_split
I0416 17:32:42.601083 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.601085 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.601088 22622 net.cpp:139] Memory required for data: 23068744
I0416 17:32:42.601089 22622 layer_factory.hpp:77] Creating layer res4b_branch2a
I0416 17:32:42.601094 22622 net.cpp:86] Creating Layer res4b_branch2a
I0416 17:32:42.601096 22622 net.cpp:408] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0416 17:32:42.601100 22622 net.cpp:382] res4b_branch2a -> res4b_branch2a
I0416 17:32:42.603471 22622 net.cpp:124] Setting up res4b_branch2a
I0416 17:32:42.603482 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.603484 22622 net.cpp:139] Memory required for data: 23134280
I0416 17:32:42.603487 22622 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0416 17:32:42.603493 22622 net.cpp:86] Creating Layer bn4b_branch2a
I0416 17:32:42.603497 22622 net.cpp:408] bn4b_branch2a <- res4b_branch2a
I0416 17:32:42.603499 22622 net.cpp:369] bn4b_branch2a -> res4b_branch2a (in-place)
I0416 17:32:42.603608 22622 net.cpp:124] Setting up bn4b_branch2a
I0416 17:32:42.603612 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.603615 22622 net.cpp:139] Memory required for data: 23199816
I0416 17:32:42.603619 22622 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0416 17:32:42.603623 22622 net.cpp:86] Creating Layer scale4b_branch2a
I0416 17:32:42.603626 22622 net.cpp:408] scale4b_branch2a <- res4b_branch2a
I0416 17:32:42.603628 22622 net.cpp:369] scale4b_branch2a -> res4b_branch2a (in-place)
I0416 17:32:42.603649 22622 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0416 17:32:42.603708 22622 net.cpp:124] Setting up scale4b_branch2a
I0416 17:32:42.603713 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.603714 22622 net.cpp:139] Memory required for data: 23265352
I0416 17:32:42.603718 22622 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0416 17:32:42.603725 22622 net.cpp:86] Creating Layer res4b_branch2a_relu
I0416 17:32:42.603729 22622 net.cpp:408] res4b_branch2a_relu <- res4b_branch2a
I0416 17:32:42.603731 22622 net.cpp:369] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0416 17:32:42.604080 22622 net.cpp:124] Setting up res4b_branch2a_relu
I0416 17:32:42.604089 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.604090 22622 net.cpp:139] Memory required for data: 23330888
I0416 17:32:42.604094 22622 layer_factory.hpp:77] Creating layer res4b_branch2b
I0416 17:32:42.604100 22622 net.cpp:86] Creating Layer res4b_branch2b
I0416 17:32:42.604102 22622 net.cpp:408] res4b_branch2b <- res4b_branch2a
I0416 17:32:42.604106 22622 net.cpp:382] res4b_branch2b -> res4b_branch2b
I0416 17:32:42.605690 22622 net.cpp:124] Setting up res4b_branch2b
I0416 17:32:42.605698 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.605700 22622 net.cpp:139] Memory required for data: 23396424
I0416 17:32:42.605705 22622 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0416 17:32:42.605710 22622 net.cpp:86] Creating Layer bn4b_branch2b
I0416 17:32:42.605711 22622 net.cpp:408] bn4b_branch2b <- res4b_branch2b
I0416 17:32:42.605715 22622 net.cpp:369] bn4b_branch2b -> res4b_branch2b (in-place)
I0416 17:32:42.605823 22622 net.cpp:124] Setting up bn4b_branch2b
I0416 17:32:42.605829 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.605830 22622 net.cpp:139] Memory required for data: 23461960
I0416 17:32:42.605846 22622 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0416 17:32:42.605850 22622 net.cpp:86] Creating Layer scale4b_branch2b
I0416 17:32:42.605852 22622 net.cpp:408] scale4b_branch2b <- res4b_branch2b
I0416 17:32:42.605855 22622 net.cpp:369] scale4b_branch2b -> res4b_branch2b (in-place)
I0416 17:32:42.605880 22622 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0416 17:32:42.605938 22622 net.cpp:124] Setting up scale4b_branch2b
I0416 17:32:42.605942 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.605944 22622 net.cpp:139] Memory required for data: 23527496
I0416 17:32:42.605948 22622 layer_factory.hpp:77] Creating layer res4b
I0416 17:32:42.605952 22622 net.cpp:86] Creating Layer res4b
I0416 17:32:42.605954 22622 net.cpp:408] res4b <- res4a_res4a_relu_0_split_1
I0416 17:32:42.605957 22622 net.cpp:408] res4b <- res4b_branch2b
I0416 17:32:42.605960 22622 net.cpp:382] res4b -> res4b
I0416 17:32:42.605970 22622 net.cpp:124] Setting up res4b
I0416 17:32:42.605974 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.605976 22622 net.cpp:139] Memory required for data: 23593032
I0416 17:32:42.605978 22622 layer_factory.hpp:77] Creating layer res4b_relu
I0416 17:32:42.605981 22622 net.cpp:86] Creating Layer res4b_relu
I0416 17:32:42.605984 22622 net.cpp:408] res4b_relu <- res4b
I0416 17:32:42.605986 22622 net.cpp:369] res4b_relu -> res4b (in-place)
I0416 17:32:42.606338 22622 net.cpp:124] Setting up res4b_relu
I0416 17:32:42.606346 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.606348 22622 net.cpp:139] Memory required for data: 23658568
I0416 17:32:42.606351 22622 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0416 17:32:42.606355 22622 net.cpp:86] Creating Layer res4b_res4b_relu_0_split
I0416 17:32:42.606357 22622 net.cpp:408] res4b_res4b_relu_0_split <- res4b
I0416 17:32:42.606361 22622 net.cpp:382] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0416 17:32:42.606365 22622 net.cpp:382] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0416 17:32:42.606387 22622 net.cpp:124] Setting up res4b_res4b_relu_0_split
I0416 17:32:42.606391 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.606395 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.606396 22622 net.cpp:139] Memory required for data: 23789640
I0416 17:32:42.606398 22622 layer_factory.hpp:77] Creating layer res4c_branch2a
I0416 17:32:42.606403 22622 net.cpp:86] Creating Layer res4c_branch2a
I0416 17:32:42.606406 22622 net.cpp:408] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0416 17:32:42.606412 22622 net.cpp:382] res4c_branch2a -> res4c_branch2a
I0416 17:32:42.608515 22622 net.cpp:124] Setting up res4c_branch2a
I0416 17:32:42.608527 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.608530 22622 net.cpp:139] Memory required for data: 23855176
I0416 17:32:42.608534 22622 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0416 17:32:42.608539 22622 net.cpp:86] Creating Layer bn4c_branch2a
I0416 17:32:42.608542 22622 net.cpp:408] bn4c_branch2a <- res4c_branch2a
I0416 17:32:42.608546 22622 net.cpp:369] bn4c_branch2a -> res4c_branch2a (in-place)
I0416 17:32:42.608659 22622 net.cpp:124] Setting up bn4c_branch2a
I0416 17:32:42.608664 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.608665 22622 net.cpp:139] Memory required for data: 23920712
I0416 17:32:42.608670 22622 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0416 17:32:42.608675 22622 net.cpp:86] Creating Layer scale4c_branch2a
I0416 17:32:42.608677 22622 net.cpp:408] scale4c_branch2a <- res4c_branch2a
I0416 17:32:42.608680 22622 net.cpp:369] scale4c_branch2a -> res4c_branch2a (in-place)
I0416 17:32:42.608702 22622 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0416 17:32:42.608763 22622 net.cpp:124] Setting up scale4c_branch2a
I0416 17:32:42.608768 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.608770 22622 net.cpp:139] Memory required for data: 23986248
I0416 17:32:42.608773 22622 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0416 17:32:42.608777 22622 net.cpp:86] Creating Layer res4c_branch2a_relu
I0416 17:32:42.608780 22622 net.cpp:408] res4c_branch2a_relu <- res4c_branch2a
I0416 17:32:42.608783 22622 net.cpp:369] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0416 17:32:42.609131 22622 net.cpp:124] Setting up res4c_branch2a_relu
I0416 17:32:42.609139 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.609141 22622 net.cpp:139] Memory required for data: 24051784
I0416 17:32:42.609144 22622 layer_factory.hpp:77] Creating layer res4c_branch2b
I0416 17:32:42.609150 22622 net.cpp:86] Creating Layer res4c_branch2b
I0416 17:32:42.609153 22622 net.cpp:408] res4c_branch2b <- res4c_branch2a
I0416 17:32:42.609156 22622 net.cpp:382] res4c_branch2b -> res4c_branch2b
I0416 17:32:42.611517 22622 net.cpp:124] Setting up res4c_branch2b
I0416 17:32:42.611529 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.611532 22622 net.cpp:139] Memory required for data: 24117320
I0416 17:32:42.611536 22622 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0416 17:32:42.611541 22622 net.cpp:86] Creating Layer bn4c_branch2b
I0416 17:32:42.611544 22622 net.cpp:408] bn4c_branch2b <- res4c_branch2b
I0416 17:32:42.611548 22622 net.cpp:369] bn4c_branch2b -> res4c_branch2b (in-place)
I0416 17:32:42.611660 22622 net.cpp:124] Setting up bn4c_branch2b
I0416 17:32:42.611665 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.611667 22622 net.cpp:139] Memory required for data: 24182856
I0416 17:32:42.611672 22622 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0416 17:32:42.611677 22622 net.cpp:86] Creating Layer scale4c_branch2b
I0416 17:32:42.611680 22622 net.cpp:408] scale4c_branch2b <- res4c_branch2b
I0416 17:32:42.611683 22622 net.cpp:369] scale4c_branch2b -> res4c_branch2b (in-place)
I0416 17:32:42.611706 22622 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0416 17:32:42.611766 22622 net.cpp:124] Setting up scale4c_branch2b
I0416 17:32:42.611770 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.611773 22622 net.cpp:139] Memory required for data: 24248392
I0416 17:32:42.611776 22622 layer_factory.hpp:77] Creating layer res4c
I0416 17:32:42.611780 22622 net.cpp:86] Creating Layer res4c
I0416 17:32:42.611783 22622 net.cpp:408] res4c <- res4b_res4b_relu_0_split_1
I0416 17:32:42.611785 22622 net.cpp:408] res4c <- res4c_branch2b
I0416 17:32:42.611788 22622 net.cpp:382] res4c -> res4c
I0416 17:32:42.611799 22622 net.cpp:124] Setting up res4c
I0416 17:32:42.611802 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.611809 22622 net.cpp:139] Memory required for data: 24313928
I0416 17:32:42.611810 22622 layer_factory.hpp:77] Creating layer res4c_relu
I0416 17:32:42.611814 22622 net.cpp:86] Creating Layer res4c_relu
I0416 17:32:42.611816 22622 net.cpp:408] res4c_relu <- res4c
I0416 17:32:42.611819 22622 net.cpp:369] res4c_relu -> res4c (in-place)
I0416 17:32:42.612188 22622 net.cpp:124] Setting up res4c_relu
I0416 17:32:42.612196 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.612198 22622 net.cpp:139] Memory required for data: 24379464
I0416 17:32:42.612201 22622 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0416 17:32:42.612205 22622 net.cpp:86] Creating Layer res4c_res4c_relu_0_split
I0416 17:32:42.612208 22622 net.cpp:408] res4c_res4c_relu_0_split <- res4c
I0416 17:32:42.612211 22622 net.cpp:382] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0416 17:32:42.612215 22622 net.cpp:382] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0416 17:32:42.612238 22622 net.cpp:124] Setting up res4c_res4c_relu_0_split
I0416 17:32:42.612242 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.612246 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.612247 22622 net.cpp:139] Memory required for data: 24510536
I0416 17:32:42.612249 22622 layer_factory.hpp:77] Creating layer res4d_branch2a
I0416 17:32:42.612254 22622 net.cpp:86] Creating Layer res4d_branch2a
I0416 17:32:42.612257 22622 net.cpp:408] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0416 17:32:42.612260 22622 net.cpp:382] res4d_branch2a -> res4d_branch2a
I0416 17:32:42.613946 22622 net.cpp:124] Setting up res4d_branch2a
I0416 17:32:42.613955 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.613958 22622 net.cpp:139] Memory required for data: 24576072
I0416 17:32:42.613961 22622 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0416 17:32:42.613966 22622 net.cpp:86] Creating Layer bn4d_branch2a
I0416 17:32:42.613970 22622 net.cpp:408] bn4d_branch2a <- res4d_branch2a
I0416 17:32:42.613973 22622 net.cpp:369] bn4d_branch2a -> res4d_branch2a (in-place)
I0416 17:32:42.614081 22622 net.cpp:124] Setting up bn4d_branch2a
I0416 17:32:42.614085 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.614087 22622 net.cpp:139] Memory required for data: 24641608
I0416 17:32:42.614092 22622 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0416 17:32:42.614095 22622 net.cpp:86] Creating Layer scale4d_branch2a
I0416 17:32:42.614099 22622 net.cpp:408] scale4d_branch2a <- res4d_branch2a
I0416 17:32:42.614101 22622 net.cpp:369] scale4d_branch2a -> res4d_branch2a (in-place)
I0416 17:32:42.614123 22622 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0416 17:32:42.614197 22622 net.cpp:124] Setting up scale4d_branch2a
I0416 17:32:42.614208 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.614210 22622 net.cpp:139] Memory required for data: 24707144
I0416 17:32:42.614215 22622 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0416 17:32:42.614219 22622 net.cpp:86] Creating Layer res4d_branch2a_relu
I0416 17:32:42.614223 22622 net.cpp:408] res4d_branch2a_relu <- res4d_branch2a
I0416 17:32:42.614225 22622 net.cpp:369] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0416 17:32:42.614483 22622 net.cpp:124] Setting up res4d_branch2a_relu
I0416 17:32:42.614490 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.614491 22622 net.cpp:139] Memory required for data: 24772680
I0416 17:32:42.614495 22622 layer_factory.hpp:77] Creating layer res4d_branch2b
I0416 17:32:42.614500 22622 net.cpp:86] Creating Layer res4d_branch2b
I0416 17:32:42.614501 22622 net.cpp:408] res4d_branch2b <- res4d_branch2a
I0416 17:32:42.614506 22622 net.cpp:382] res4d_branch2b -> res4d_branch2b
I0416 17:32:42.616907 22622 net.cpp:124] Setting up res4d_branch2b
I0416 17:32:42.616919 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.616922 22622 net.cpp:139] Memory required for data: 24838216
I0416 17:32:42.616926 22622 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0416 17:32:42.616933 22622 net.cpp:86] Creating Layer bn4d_branch2b
I0416 17:32:42.616937 22622 net.cpp:408] bn4d_branch2b <- res4d_branch2b
I0416 17:32:42.616940 22622 net.cpp:369] bn4d_branch2b -> res4d_branch2b (in-place)
I0416 17:32:42.617055 22622 net.cpp:124] Setting up bn4d_branch2b
I0416 17:32:42.617059 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.617061 22622 net.cpp:139] Memory required for data: 24903752
I0416 17:32:42.617066 22622 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0416 17:32:42.617070 22622 net.cpp:86] Creating Layer scale4d_branch2b
I0416 17:32:42.617074 22622 net.cpp:408] scale4d_branch2b <- res4d_branch2b
I0416 17:32:42.617076 22622 net.cpp:369] scale4d_branch2b -> res4d_branch2b (in-place)
I0416 17:32:42.617099 22622 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0416 17:32:42.617158 22622 net.cpp:124] Setting up scale4d_branch2b
I0416 17:32:42.617162 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.617166 22622 net.cpp:139] Memory required for data: 24969288
I0416 17:32:42.617168 22622 layer_factory.hpp:77] Creating layer res4d
I0416 17:32:42.617172 22622 net.cpp:86] Creating Layer res4d
I0416 17:32:42.617174 22622 net.cpp:408] res4d <- res4c_res4c_relu_0_split_1
I0416 17:32:42.617177 22622 net.cpp:408] res4d <- res4d_branch2b
I0416 17:32:42.617180 22622 net.cpp:382] res4d -> res4d
I0416 17:32:42.617197 22622 net.cpp:124] Setting up res4d
I0416 17:32:42.617200 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.617202 22622 net.cpp:139] Memory required for data: 25034824
I0416 17:32:42.617205 22622 layer_factory.hpp:77] Creating layer res4d_relu
I0416 17:32:42.617208 22622 net.cpp:86] Creating Layer res4d_relu
I0416 17:32:42.617210 22622 net.cpp:408] res4d_relu <- res4d
I0416 17:32:42.617213 22622 net.cpp:369] res4d_relu -> res4d (in-place)
I0416 17:32:42.617563 22622 net.cpp:124] Setting up res4d_relu
I0416 17:32:42.617571 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.617573 22622 net.cpp:139] Memory required for data: 25100360
I0416 17:32:42.617576 22622 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0416 17:32:42.617579 22622 net.cpp:86] Creating Layer res4d_res4d_relu_0_split
I0416 17:32:42.617583 22622 net.cpp:408] res4d_res4d_relu_0_split <- res4d
I0416 17:32:42.617588 22622 net.cpp:382] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0416 17:32:42.617591 22622 net.cpp:382] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0416 17:32:42.617612 22622 net.cpp:124] Setting up res4d_res4d_relu_0_split
I0416 17:32:42.617616 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.617619 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.617621 22622 net.cpp:139] Memory required for data: 25231432
I0416 17:32:42.617624 22622 layer_factory.hpp:77] Creating layer res4e_branch2a
I0416 17:32:42.617636 22622 net.cpp:86] Creating Layer res4e_branch2a
I0416 17:32:42.617640 22622 net.cpp:408] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0416 17:32:42.617642 22622 net.cpp:382] res4e_branch2a -> res4e_branch2a
I0416 17:32:42.619238 22622 net.cpp:124] Setting up res4e_branch2a
I0416 17:32:42.619247 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.619249 22622 net.cpp:139] Memory required for data: 25296968
I0416 17:32:42.619253 22622 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0416 17:32:42.619257 22622 net.cpp:86] Creating Layer bn4e_branch2a
I0416 17:32:42.619261 22622 net.cpp:408] bn4e_branch2a <- res4e_branch2a
I0416 17:32:42.619263 22622 net.cpp:369] bn4e_branch2a -> res4e_branch2a (in-place)
I0416 17:32:42.619382 22622 net.cpp:124] Setting up bn4e_branch2a
I0416 17:32:42.619386 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.619388 22622 net.cpp:139] Memory required for data: 25362504
I0416 17:32:42.619392 22622 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0416 17:32:42.619397 22622 net.cpp:86] Creating Layer scale4e_branch2a
I0416 17:32:42.619400 22622 net.cpp:408] scale4e_branch2a <- res4e_branch2a
I0416 17:32:42.619406 22622 net.cpp:369] scale4e_branch2a -> res4e_branch2a (in-place)
I0416 17:32:42.619428 22622 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0416 17:32:42.619488 22622 net.cpp:124] Setting up scale4e_branch2a
I0416 17:32:42.619493 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.619494 22622 net.cpp:139] Memory required for data: 25428040
I0416 17:32:42.619498 22622 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0416 17:32:42.619503 22622 net.cpp:86] Creating Layer res4e_branch2a_relu
I0416 17:32:42.619504 22622 net.cpp:408] res4e_branch2a_relu <- res4e_branch2a
I0416 17:32:42.619508 22622 net.cpp:369] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0416 17:32:42.619856 22622 net.cpp:124] Setting up res4e_branch2a_relu
I0416 17:32:42.619864 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.619866 22622 net.cpp:139] Memory required for data: 25493576
I0416 17:32:42.619868 22622 layer_factory.hpp:77] Creating layer res4e_branch2b
I0416 17:32:42.619874 22622 net.cpp:86] Creating Layer res4e_branch2b
I0416 17:32:42.619877 22622 net.cpp:408] res4e_branch2b <- res4e_branch2a
I0416 17:32:42.619880 22622 net.cpp:382] res4e_branch2b -> res4e_branch2b
I0416 17:32:42.621493 22622 net.cpp:124] Setting up res4e_branch2b
I0416 17:32:42.621502 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.621505 22622 net.cpp:139] Memory required for data: 25559112
I0416 17:32:42.621508 22622 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0416 17:32:42.621512 22622 net.cpp:86] Creating Layer bn4e_branch2b
I0416 17:32:42.621515 22622 net.cpp:408] bn4e_branch2b <- res4e_branch2b
I0416 17:32:42.621520 22622 net.cpp:369] bn4e_branch2b -> res4e_branch2b (in-place)
I0416 17:32:42.621626 22622 net.cpp:124] Setting up bn4e_branch2b
I0416 17:32:42.621631 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.621634 22622 net.cpp:139] Memory required for data: 25624648
I0416 17:32:42.621639 22622 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0416 17:32:42.621641 22622 net.cpp:86] Creating Layer scale4e_branch2b
I0416 17:32:42.621644 22622 net.cpp:408] scale4e_branch2b <- res4e_branch2b
I0416 17:32:42.621646 22622 net.cpp:369] scale4e_branch2b -> res4e_branch2b (in-place)
I0416 17:32:42.621668 22622 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0416 17:32:42.621726 22622 net.cpp:124] Setting up scale4e_branch2b
I0416 17:32:42.621731 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.621732 22622 net.cpp:139] Memory required for data: 25690184
I0416 17:32:42.621737 22622 layer_factory.hpp:77] Creating layer res4e
I0416 17:32:42.621739 22622 net.cpp:86] Creating Layer res4e
I0416 17:32:42.621742 22622 net.cpp:408] res4e <- res4d_res4d_relu_0_split_1
I0416 17:32:42.621745 22622 net.cpp:408] res4e <- res4e_branch2b
I0416 17:32:42.621748 22622 net.cpp:382] res4e -> res4e
I0416 17:32:42.621758 22622 net.cpp:124] Setting up res4e
I0416 17:32:42.621762 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.621763 22622 net.cpp:139] Memory required for data: 25755720
I0416 17:32:42.621767 22622 layer_factory.hpp:77] Creating layer res4e_relu
I0416 17:32:42.621770 22622 net.cpp:86] Creating Layer res4e_relu
I0416 17:32:42.621773 22622 net.cpp:408] res4e_relu <- res4e
I0416 17:32:42.621775 22622 net.cpp:369] res4e_relu -> res4e (in-place)
I0416 17:32:42.622128 22622 net.cpp:124] Setting up res4e_relu
I0416 17:32:42.622134 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.622138 22622 net.cpp:139] Memory required for data: 25821256
I0416 17:32:42.622139 22622 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0416 17:32:42.622143 22622 net.cpp:86] Creating Layer res4e_res4e_relu_0_split
I0416 17:32:42.622146 22622 net.cpp:408] res4e_res4e_relu_0_split <- res4e
I0416 17:32:42.622150 22622 net.cpp:382] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0416 17:32:42.622154 22622 net.cpp:382] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0416 17:32:42.622176 22622 net.cpp:124] Setting up res4e_res4e_relu_0_split
I0416 17:32:42.622184 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.622186 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.622189 22622 net.cpp:139] Memory required for data: 25952328
I0416 17:32:42.622190 22622 layer_factory.hpp:77] Creating layer res4f_branch2a
I0416 17:32:42.622195 22622 net.cpp:86] Creating Layer res4f_branch2a
I0416 17:32:42.622198 22622 net.cpp:408] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0416 17:32:42.622201 22622 net.cpp:382] res4f_branch2a -> res4f_branch2a
I0416 17:32:42.624505 22622 net.cpp:124] Setting up res4f_branch2a
I0416 17:32:42.624516 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.624519 22622 net.cpp:139] Memory required for data: 26017864
I0416 17:32:42.624523 22622 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0416 17:32:42.624528 22622 net.cpp:86] Creating Layer bn4f_branch2a
I0416 17:32:42.624531 22622 net.cpp:408] bn4f_branch2a <- res4f_branch2a
I0416 17:32:42.624536 22622 net.cpp:369] bn4f_branch2a -> res4f_branch2a (in-place)
I0416 17:32:42.624650 22622 net.cpp:124] Setting up bn4f_branch2a
I0416 17:32:42.624653 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.624656 22622 net.cpp:139] Memory required for data: 26083400
I0416 17:32:42.624660 22622 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0416 17:32:42.624665 22622 net.cpp:86] Creating Layer scale4f_branch2a
I0416 17:32:42.624667 22622 net.cpp:408] scale4f_branch2a <- res4f_branch2a
I0416 17:32:42.624670 22622 net.cpp:369] scale4f_branch2a -> res4f_branch2a (in-place)
I0416 17:32:42.624691 22622 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0416 17:32:42.624749 22622 net.cpp:124] Setting up scale4f_branch2a
I0416 17:32:42.624754 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.624756 22622 net.cpp:139] Memory required for data: 26148936
I0416 17:32:42.624759 22622 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0416 17:32:42.624763 22622 net.cpp:86] Creating Layer res4f_branch2a_relu
I0416 17:32:42.624766 22622 net.cpp:408] res4f_branch2a_relu <- res4f_branch2a
I0416 17:32:42.624769 22622 net.cpp:369] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0416 17:32:42.625121 22622 net.cpp:124] Setting up res4f_branch2a_relu
I0416 17:32:42.625130 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.625133 22622 net.cpp:139] Memory required for data: 26214472
I0416 17:32:42.625135 22622 layer_factory.hpp:77] Creating layer res4f_branch2b
I0416 17:32:42.625141 22622 net.cpp:86] Creating Layer res4f_branch2b
I0416 17:32:42.625144 22622 net.cpp:408] res4f_branch2b <- res4f_branch2a
I0416 17:32:42.625147 22622 net.cpp:382] res4f_branch2b -> res4f_branch2b
I0416 17:32:42.626821 22622 net.cpp:124] Setting up res4f_branch2b
I0416 17:32:42.626830 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.626832 22622 net.cpp:139] Memory required for data: 26280008
I0416 17:32:42.626835 22622 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0416 17:32:42.626842 22622 net.cpp:86] Creating Layer bn4f_branch2b
I0416 17:32:42.626843 22622 net.cpp:408] bn4f_branch2b <- res4f_branch2b
I0416 17:32:42.626847 22622 net.cpp:369] bn4f_branch2b -> res4f_branch2b (in-place)
I0416 17:32:42.626955 22622 net.cpp:124] Setting up bn4f_branch2b
I0416 17:32:42.626960 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.626962 22622 net.cpp:139] Memory required for data: 26345544
I0416 17:32:42.626967 22622 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0416 17:32:42.626971 22622 net.cpp:86] Creating Layer scale4f_branch2b
I0416 17:32:42.626973 22622 net.cpp:408] scale4f_branch2b <- res4f_branch2b
I0416 17:32:42.626977 22622 net.cpp:369] scale4f_branch2b -> res4f_branch2b (in-place)
I0416 17:32:42.626998 22622 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0416 17:32:42.627058 22622 net.cpp:124] Setting up scale4f_branch2b
I0416 17:32:42.627061 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.627064 22622 net.cpp:139] Memory required for data: 26411080
I0416 17:32:42.627071 22622 layer_factory.hpp:77] Creating layer res4f
I0416 17:32:42.627075 22622 net.cpp:86] Creating Layer res4f
I0416 17:32:42.627079 22622 net.cpp:408] res4f <- res4e_res4e_relu_0_split_1
I0416 17:32:42.627081 22622 net.cpp:408] res4f <- res4f_branch2b
I0416 17:32:42.627084 22622 net.cpp:382] res4f -> res4f
I0416 17:32:42.627095 22622 net.cpp:124] Setting up res4f
I0416 17:32:42.627099 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.627100 22622 net.cpp:139] Memory required for data: 26476616
I0416 17:32:42.627104 22622 layer_factory.hpp:77] Creating layer res4f_relu
I0416 17:32:42.627106 22622 net.cpp:86] Creating Layer res4f_relu
I0416 17:32:42.627108 22622 net.cpp:408] res4f_relu <- res4f
I0416 17:32:42.627111 22622 net.cpp:369] res4f_relu -> res4f (in-place)
I0416 17:32:42.627370 22622 net.cpp:124] Setting up res4f_relu
I0416 17:32:42.627377 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.627378 22622 net.cpp:139] Memory required for data: 26542152
I0416 17:32:42.627382 22622 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0416 17:32:42.627385 22622 net.cpp:86] Creating Layer res4f_res4f_relu_0_split
I0416 17:32:42.627388 22622 net.cpp:408] res4f_res4f_relu_0_split <- res4f
I0416 17:32:42.627391 22622 net.cpp:382] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0416 17:32:42.627395 22622 net.cpp:382] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0416 17:32:42.627398 22622 net.cpp:382] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0416 17:32:42.627429 22622 net.cpp:124] Setting up res4f_res4f_relu_0_split
I0416 17:32:42.627432 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.627435 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.627437 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.627439 22622 net.cpp:139] Memory required for data: 26738760
I0416 17:32:42.627442 22622 layer_factory.hpp:77] Creating layer res5a_branch1
I0416 17:32:42.627447 22622 net.cpp:86] Creating Layer res5a_branch1
I0416 17:32:42.627449 22622 net.cpp:408] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0416 17:32:42.627452 22622 net.cpp:382] res5a_branch1 -> res5a_branch1
I0416 17:32:42.629544 22622 net.cpp:124] Setting up res5a_branch1
I0416 17:32:42.629554 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.629557 22622 net.cpp:139] Memory required for data: 26869832
I0416 17:32:42.629561 22622 layer_factory.hpp:77] Creating layer bn5a_branch1
I0416 17:32:42.629565 22622 net.cpp:86] Creating Layer bn5a_branch1
I0416 17:32:42.629568 22622 net.cpp:408] bn5a_branch1 <- res5a_branch1
I0416 17:32:42.629572 22622 net.cpp:369] bn5a_branch1 -> res5a_branch1 (in-place)
I0416 17:32:42.629671 22622 net.cpp:124] Setting up bn5a_branch1
I0416 17:32:42.629675 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.629678 22622 net.cpp:139] Memory required for data: 27000904
I0416 17:32:42.629683 22622 layer_factory.hpp:77] Creating layer scale5a_branch1
I0416 17:32:42.629686 22622 net.cpp:86] Creating Layer scale5a_branch1
I0416 17:32:42.629689 22622 net.cpp:408] scale5a_branch1 <- res5a_branch1
I0416 17:32:42.629693 22622 net.cpp:369] scale5a_branch1 -> res5a_branch1 (in-place)
I0416 17:32:42.629714 22622 layer_factory.hpp:77] Creating layer scale5a_branch1
I0416 17:32:42.629767 22622 net.cpp:124] Setting up scale5a_branch1
I0416 17:32:42.629771 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.629773 22622 net.cpp:139] Memory required for data: 27131976
I0416 17:32:42.629778 22622 layer_factory.hpp:77] Creating layer res5a_branch2a
I0416 17:32:42.629783 22622 net.cpp:86] Creating Layer res5a_branch2a
I0416 17:32:42.629786 22622 net.cpp:408] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0416 17:32:42.629789 22622 net.cpp:382] res5a_branch2a -> res5a_branch2a
I0416 17:32:42.631831 22622 net.cpp:124] Setting up res5a_branch2a
I0416 17:32:42.631840 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.631844 22622 net.cpp:139] Memory required for data: 27263048
I0416 17:32:42.631850 22622 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0416 17:32:42.631855 22622 net.cpp:86] Creating Layer bn5a_branch2a
I0416 17:32:42.631858 22622 net.cpp:408] bn5a_branch2a <- res5a_branch2a
I0416 17:32:42.631861 22622 net.cpp:369] bn5a_branch2a -> res5a_branch2a (in-place)
I0416 17:32:42.631963 22622 net.cpp:124] Setting up bn5a_branch2a
I0416 17:32:42.631966 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.631968 22622 net.cpp:139] Memory required for data: 27394120
I0416 17:32:42.631973 22622 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0416 17:32:42.631976 22622 net.cpp:86] Creating Layer scale5a_branch2a
I0416 17:32:42.631979 22622 net.cpp:408] scale5a_branch2a <- res5a_branch2a
I0416 17:32:42.631983 22622 net.cpp:369] scale5a_branch2a -> res5a_branch2a (in-place)
I0416 17:32:42.632004 22622 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0416 17:32:42.632055 22622 net.cpp:124] Setting up scale5a_branch2a
I0416 17:32:42.632059 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.632061 22622 net.cpp:139] Memory required for data: 27525192
I0416 17:32:42.632064 22622 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0416 17:32:42.632069 22622 net.cpp:86] Creating Layer res5a_branch2a_relu
I0416 17:32:42.632071 22622 net.cpp:408] res5a_branch2a_relu <- res5a_branch2a
I0416 17:32:42.632074 22622 net.cpp:369] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0416 17:32:42.632447 22622 net.cpp:124] Setting up res5a_branch2a_relu
I0416 17:32:42.632454 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.632457 22622 net.cpp:139] Memory required for data: 27656264
I0416 17:32:42.632459 22622 layer_factory.hpp:77] Creating layer res5a_branch2b
I0416 17:32:42.632465 22622 net.cpp:86] Creating Layer res5a_branch2b
I0416 17:32:42.632468 22622 net.cpp:408] res5a_branch2b <- res5a_branch2a
I0416 17:32:42.632472 22622 net.cpp:382] res5a_branch2b -> res5a_branch2b
I0416 17:32:42.634853 22622 net.cpp:124] Setting up res5a_branch2b
I0416 17:32:42.634860 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.634863 22622 net.cpp:139] Memory required for data: 27787336
I0416 17:32:42.634866 22622 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0416 17:32:42.634871 22622 net.cpp:86] Creating Layer bn5a_branch2b
I0416 17:32:42.634873 22622 net.cpp:408] bn5a_branch2b <- res5a_branch2b
I0416 17:32:42.634876 22622 net.cpp:369] bn5a_branch2b -> res5a_branch2b (in-place)
I0416 17:32:42.634975 22622 net.cpp:124] Setting up bn5a_branch2b
I0416 17:32:42.634979 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.634981 22622 net.cpp:139] Memory required for data: 27918408
I0416 17:32:42.634985 22622 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0416 17:32:42.634990 22622 net.cpp:86] Creating Layer scale5a_branch2b
I0416 17:32:42.634992 22622 net.cpp:408] scale5a_branch2b <- res5a_branch2b
I0416 17:32:42.634995 22622 net.cpp:369] scale5a_branch2b -> res5a_branch2b (in-place)
I0416 17:32:42.635016 22622 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0416 17:32:42.635069 22622 net.cpp:124] Setting up scale5a_branch2b
I0416 17:32:42.635073 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.635076 22622 net.cpp:139] Memory required for data: 28049480
I0416 17:32:42.635079 22622 layer_factory.hpp:77] Creating layer res5a
I0416 17:32:42.635083 22622 net.cpp:86] Creating Layer res5a
I0416 17:32:42.635085 22622 net.cpp:408] res5a <- res5a_branch1
I0416 17:32:42.635088 22622 net.cpp:408] res5a <- res5a_branch2b
I0416 17:32:42.635092 22622 net.cpp:382] res5a -> res5a
I0416 17:32:42.635102 22622 net.cpp:124] Setting up res5a
I0416 17:32:42.635105 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.635107 22622 net.cpp:139] Memory required for data: 28180552
I0416 17:32:42.635110 22622 layer_factory.hpp:77] Creating layer res5a_relu
I0416 17:32:42.635113 22622 net.cpp:86] Creating Layer res5a_relu
I0416 17:32:42.635116 22622 net.cpp:408] res5a_relu <- res5a
I0416 17:32:42.635118 22622 net.cpp:369] res5a_relu -> res5a (in-place)
I0416 17:32:42.635478 22622 net.cpp:124] Setting up res5a_relu
I0416 17:32:42.635484 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.635486 22622 net.cpp:139] Memory required for data: 28311624
I0416 17:32:42.635489 22622 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0416 17:32:42.635493 22622 net.cpp:86] Creating Layer res5a_res5a_relu_0_split
I0416 17:32:42.635496 22622 net.cpp:408] res5a_res5a_relu_0_split <- res5a
I0416 17:32:42.635499 22622 net.cpp:382] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0416 17:32:42.635504 22622 net.cpp:382] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0416 17:32:42.635527 22622 net.cpp:124] Setting up res5a_res5a_relu_0_split
I0416 17:32:42.635531 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.635533 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.635535 22622 net.cpp:139] Memory required for data: 28573768
I0416 17:32:42.635538 22622 layer_factory.hpp:77] Creating layer res5b_branch2a
I0416 17:32:42.635542 22622 net.cpp:86] Creating Layer res5b_branch2a
I0416 17:32:42.635545 22622 net.cpp:408] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0416 17:32:42.635548 22622 net.cpp:382] res5b_branch2a -> res5b_branch2a
I0416 17:32:42.637452 22622 net.cpp:124] Setting up res5b_branch2a
I0416 17:32:42.637457 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.637460 22622 net.cpp:139] Memory required for data: 28704840
I0416 17:32:42.637464 22622 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0416 17:32:42.637466 22622 net.cpp:86] Creating Layer bn5b_branch2a
I0416 17:32:42.637470 22622 net.cpp:408] bn5b_branch2a <- res5b_branch2a
I0416 17:32:42.637472 22622 net.cpp:369] bn5b_branch2a -> res5b_branch2a (in-place)
I0416 17:32:42.637573 22622 net.cpp:124] Setting up bn5b_branch2a
I0416 17:32:42.637578 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.637579 22622 net.cpp:139] Memory required for data: 28835912
I0416 17:32:42.637583 22622 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0416 17:32:42.637588 22622 net.cpp:86] Creating Layer scale5b_branch2a
I0416 17:32:42.637590 22622 net.cpp:408] scale5b_branch2a <- res5b_branch2a
I0416 17:32:42.637593 22622 net.cpp:369] scale5b_branch2a -> res5b_branch2a (in-place)
I0416 17:32:42.637614 22622 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0416 17:32:42.637666 22622 net.cpp:124] Setting up scale5b_branch2a
I0416 17:32:42.637670 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.637672 22622 net.cpp:139] Memory required for data: 28966984
I0416 17:32:42.637676 22622 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0416 17:32:42.637679 22622 net.cpp:86] Creating Layer res5b_branch2a_relu
I0416 17:32:42.637682 22622 net.cpp:408] res5b_branch2a_relu <- res5b_branch2a
I0416 17:32:42.637686 22622 net.cpp:369] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0416 17:32:42.637940 22622 net.cpp:124] Setting up res5b_branch2a_relu
I0416 17:32:42.637946 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.637948 22622 net.cpp:139] Memory required for data: 29098056
I0416 17:32:42.637951 22622 layer_factory.hpp:77] Creating layer res5b_branch2b
I0416 17:32:42.637956 22622 net.cpp:86] Creating Layer res5b_branch2b
I0416 17:32:42.637959 22622 net.cpp:408] res5b_branch2b <- res5b_branch2a
I0416 17:32:42.637962 22622 net.cpp:382] res5b_branch2b -> res5b_branch2b
I0416 17:32:42.639899 22622 net.cpp:124] Setting up res5b_branch2b
I0416 17:32:42.639904 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.639906 22622 net.cpp:139] Memory required for data: 29229128
I0416 17:32:42.639909 22622 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0416 17:32:42.639914 22622 net.cpp:86] Creating Layer bn5b_branch2b
I0416 17:32:42.639916 22622 net.cpp:408] bn5b_branch2b <- res5b_branch2b
I0416 17:32:42.639919 22622 net.cpp:369] bn5b_branch2b -> res5b_branch2b (in-place)
I0416 17:32:42.640018 22622 net.cpp:124] Setting up bn5b_branch2b
I0416 17:32:42.640022 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.640027 22622 net.cpp:139] Memory required for data: 29360200
I0416 17:32:42.640033 22622 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0416 17:32:42.640036 22622 net.cpp:86] Creating Layer scale5b_branch2b
I0416 17:32:42.640038 22622 net.cpp:408] scale5b_branch2b <- res5b_branch2b
I0416 17:32:42.640041 22622 net.cpp:369] scale5b_branch2b -> res5b_branch2b (in-place)
I0416 17:32:42.640064 22622 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0416 17:32:42.640122 22622 net.cpp:124] Setting up scale5b_branch2b
I0416 17:32:42.640128 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.640130 22622 net.cpp:139] Memory required for data: 29491272
I0416 17:32:42.640134 22622 layer_factory.hpp:77] Creating layer res5b
I0416 17:32:42.640137 22622 net.cpp:86] Creating Layer res5b
I0416 17:32:42.640141 22622 net.cpp:408] res5b <- res5a_res5a_relu_0_split_1
I0416 17:32:42.640143 22622 net.cpp:408] res5b <- res5b_branch2b
I0416 17:32:42.640146 22622 net.cpp:382] res5b -> res5b
I0416 17:32:42.640156 22622 net.cpp:124] Setting up res5b
I0416 17:32:42.640161 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.640162 22622 net.cpp:139] Memory required for data: 29622344
I0416 17:32:42.640164 22622 layer_factory.hpp:77] Creating layer res5b_relu
I0416 17:32:42.640167 22622 net.cpp:86] Creating Layer res5b_relu
I0416 17:32:42.640170 22622 net.cpp:408] res5b_relu <- res5b
I0416 17:32:42.640173 22622 net.cpp:369] res5b_relu -> res5b (in-place)
I0416 17:32:42.640527 22622 net.cpp:124] Setting up res5b_relu
I0416 17:32:42.640534 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.640537 22622 net.cpp:139] Memory required for data: 29753416
I0416 17:32:42.640539 22622 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0416 17:32:42.640543 22622 net.cpp:86] Creating Layer res5b_res5b_relu_0_split
I0416 17:32:42.640547 22622 net.cpp:408] res5b_res5b_relu_0_split <- res5b
I0416 17:32:42.640549 22622 net.cpp:382] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0416 17:32:42.640553 22622 net.cpp:382] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0416 17:32:42.640578 22622 net.cpp:124] Setting up res5b_res5b_relu_0_split
I0416 17:32:42.640581 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.640583 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.640585 22622 net.cpp:139] Memory required for data: 30015560
I0416 17:32:42.640588 22622 layer_factory.hpp:77] Creating layer res5c_branch2a
I0416 17:32:42.640594 22622 net.cpp:86] Creating Layer res5c_branch2a
I0416 17:32:42.640595 22622 net.cpp:408] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0416 17:32:42.640599 22622 net.cpp:382] res5c_branch2a -> res5c_branch2a
I0416 17:32:42.642998 22622 net.cpp:124] Setting up res5c_branch2a
I0416 17:32:42.643007 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.643008 22622 net.cpp:139] Memory required for data: 30146632
I0416 17:32:42.643012 22622 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0416 17:32:42.643016 22622 net.cpp:86] Creating Layer bn5c_branch2a
I0416 17:32:42.643019 22622 net.cpp:408] bn5c_branch2a <- res5c_branch2a
I0416 17:32:42.643023 22622 net.cpp:369] bn5c_branch2a -> res5c_branch2a (in-place)
I0416 17:32:42.643126 22622 net.cpp:124] Setting up bn5c_branch2a
I0416 17:32:42.643131 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.643132 22622 net.cpp:139] Memory required for data: 30277704
I0416 17:32:42.643136 22622 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0416 17:32:42.643141 22622 net.cpp:86] Creating Layer scale5c_branch2a
I0416 17:32:42.643143 22622 net.cpp:408] scale5c_branch2a <- res5c_branch2a
I0416 17:32:42.643146 22622 net.cpp:369] scale5c_branch2a -> res5c_branch2a (in-place)
I0416 17:32:42.643167 22622 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0416 17:32:42.643220 22622 net.cpp:124] Setting up scale5c_branch2a
I0416 17:32:42.643224 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.643226 22622 net.cpp:139] Memory required for data: 30408776
I0416 17:32:42.643234 22622 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0416 17:32:42.643239 22622 net.cpp:86] Creating Layer res5c_branch2a_relu
I0416 17:32:42.643241 22622 net.cpp:408] res5c_branch2a_relu <- res5c_branch2a
I0416 17:32:42.643244 22622 net.cpp:369] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0416 17:32:42.643599 22622 net.cpp:124] Setting up res5c_branch2a_relu
I0416 17:32:42.643605 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.643609 22622 net.cpp:139] Memory required for data: 30539848
I0416 17:32:42.643610 22622 layer_factory.hpp:77] Creating layer res5c_branch2b
I0416 17:32:42.643616 22622 net.cpp:86] Creating Layer res5c_branch2b
I0416 17:32:42.643620 22622 net.cpp:408] res5c_branch2b <- res5c_branch2a
I0416 17:32:42.643622 22622 net.cpp:382] res5c_branch2b -> res5c_branch2b
I0416 17:32:42.645565 22622 net.cpp:124] Setting up res5c_branch2b
I0416 17:32:42.645571 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.645573 22622 net.cpp:139] Memory required for data: 30670920
I0416 17:32:42.645576 22622 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0416 17:32:42.645581 22622 net.cpp:86] Creating Layer bn5c_branch2b
I0416 17:32:42.645583 22622 net.cpp:408] bn5c_branch2b <- res5c_branch2b
I0416 17:32:42.645586 22622 net.cpp:369] bn5c_branch2b -> res5c_branch2b (in-place)
I0416 17:32:42.645687 22622 net.cpp:124] Setting up bn5c_branch2b
I0416 17:32:42.645692 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.645694 22622 net.cpp:139] Memory required for data: 30801992
I0416 17:32:42.645699 22622 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0416 17:32:42.645702 22622 net.cpp:86] Creating Layer scale5c_branch2b
I0416 17:32:42.645704 22622 net.cpp:408] scale5c_branch2b <- res5c_branch2b
I0416 17:32:42.645707 22622 net.cpp:369] scale5c_branch2b -> res5c_branch2b (in-place)
I0416 17:32:42.645730 22622 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0416 17:32:42.645784 22622 net.cpp:124] Setting up scale5c_branch2b
I0416 17:32:42.645789 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.645792 22622 net.cpp:139] Memory required for data: 30933064
I0416 17:32:42.645794 22622 layer_factory.hpp:77] Creating layer res5c
I0416 17:32:42.645799 22622 net.cpp:86] Creating Layer res5c
I0416 17:32:42.645802 22622 net.cpp:408] res5c <- res5b_res5b_relu_0_split_1
I0416 17:32:42.645804 22622 net.cpp:408] res5c <- res5c_branch2b
I0416 17:32:42.645807 22622 net.cpp:382] res5c -> res5c
I0416 17:32:42.645819 22622 net.cpp:124] Setting up res5c
I0416 17:32:42.645823 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.645824 22622 net.cpp:139] Memory required for data: 31064136
I0416 17:32:42.645828 22622 layer_factory.hpp:77] Creating layer res5c_relu
I0416 17:32:42.645830 22622 net.cpp:86] Creating Layer res5c_relu
I0416 17:32:42.645833 22622 net.cpp:408] res5c_relu <- res5c
I0416 17:32:42.645836 22622 net.cpp:369] res5c_relu -> res5c (in-place)
I0416 17:32:42.646193 22622 net.cpp:124] Setting up res5c_relu
I0416 17:32:42.646200 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.646203 22622 net.cpp:139] Memory required for data: 31195208
I0416 17:32:42.646205 22622 layer_factory.hpp:77] Creating layer rpn_deconv
I0416 17:32:42.646211 22622 net.cpp:86] Creating Layer rpn_deconv
I0416 17:32:42.646214 22622 net.cpp:408] rpn_deconv <- res4f_res4f_relu_0_split_2
I0416 17:32:42.646219 22622 net.cpp:382] rpn_deconv -> rpn/output
I0416 17:32:42.651975 22622 net.cpp:124] Setting up rpn_deconv
I0416 17:32:42.651990 22622 net.cpp:131] Top shape: 1 256 32 32 (262144)
I0416 17:32:42.651993 22622 net.cpp:139] Memory required for data: 32243784
I0416 17:32:42.651998 22622 layer_factory.hpp:77] Creating layer rpn_relu
I0416 17:32:42.652004 22622 net.cpp:86] Creating Layer rpn_relu
I0416 17:32:42.652007 22622 net.cpp:408] rpn_relu <- rpn/output
I0416 17:32:42.652011 22622 net.cpp:369] rpn_relu -> rpn/output (in-place)
I0416 17:32:42.652369 22622 net.cpp:124] Setting up rpn_relu
I0416 17:32:42.652380 22622 net.cpp:131] Top shape: 1 256 32 32 (262144)
I0416 17:32:42.652382 22622 net.cpp:139] Memory required for data: 33292360
I0416 17:32:42.652385 22622 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu_0_split
I0416 17:32:42.652390 22622 net.cpp:86] Creating Layer rpn/output_rpn_relu_0_split
I0416 17:32:42.652393 22622 net.cpp:408] rpn/output_rpn_relu_0_split <- rpn/output
I0416 17:32:42.652396 22622 net.cpp:382] rpn/output_rpn_relu_0_split -> rpn/output_rpn_relu_0_split_0
I0416 17:32:42.652400 22622 net.cpp:382] rpn/output_rpn_relu_0_split -> rpn/output_rpn_relu_0_split_1
I0416 17:32:42.652426 22622 net.cpp:124] Setting up rpn/output_rpn_relu_0_split
I0416 17:32:42.652429 22622 net.cpp:131] Top shape: 1 256 32 32 (262144)
I0416 17:32:42.652431 22622 net.cpp:131] Top shape: 1 256 32 32 (262144)
I0416 17:32:42.652434 22622 net.cpp:139] Memory required for data: 35389512
I0416 17:32:42.652436 22622 layer_factory.hpp:77] Creating layer rpn_cls_score
I0416 17:32:42.652443 22622 net.cpp:86] Creating Layer rpn_cls_score
I0416 17:32:42.652446 22622 net.cpp:408] rpn_cls_score <- rpn/output_rpn_relu_0_split_0
I0416 17:32:42.652449 22622 net.cpp:382] rpn_cls_score -> rpn_cls_score
I0416 17:32:42.653652 22622 net.cpp:124] Setting up rpn_cls_score
I0416 17:32:42.653661 22622 net.cpp:131] Top shape: 1 30 32 32 (30720)
I0416 17:32:42.653663 22622 net.cpp:139] Memory required for data: 35512392
I0416 17:32:42.653667 22622 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0416 17:32:42.653673 22622 net.cpp:86] Creating Layer rpn_bbox_pred
I0416 17:32:42.653676 22622 net.cpp:408] rpn_bbox_pred <- rpn/output_rpn_relu_0_split_1
I0416 17:32:42.653681 22622 net.cpp:382] rpn_bbox_pred -> rpn_bbox_pred
I0416 17:32:42.655081 22622 net.cpp:124] Setting up rpn_bbox_pred
I0416 17:32:42.655089 22622 net.cpp:131] Top shape: 1 60 32 32 (61440)
I0416 17:32:42.655092 22622 net.cpp:139] Memory required for data: 35758152
I0416 17:32:42.655097 22622 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0416 17:32:42.655136 22622 net.cpp:86] Creating Layer rpn_cls_score_reshape
I0416 17:32:42.655139 22622 net.cpp:408] rpn_cls_score_reshape <- rpn_cls_score
I0416 17:32:42.655143 22622 net.cpp:382] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0416 17:32:42.655192 22622 net.cpp:124] Setting up rpn_cls_score_reshape
I0416 17:32:42.655196 22622 net.cpp:131] Top shape: 1 2 480 32 (30720)
I0416 17:32:42.655198 22622 net.cpp:139] Memory required for data: 35881032
I0416 17:32:42.655201 22622 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0416 17:32:42.655210 22622 net.cpp:86] Creating Layer rpn_cls_prob
I0416 17:32:42.655212 22622 net.cpp:408] rpn_cls_prob <- rpn_cls_score_reshape
I0416 17:32:42.655215 22622 net.cpp:382] rpn_cls_prob -> rpn_cls_prob
I0416 17:32:42.656440 22622 net.cpp:124] Setting up rpn_cls_prob
I0416 17:32:42.656450 22622 net.cpp:131] Top shape: 1 2 480 32 (30720)
I0416 17:32:42.656453 22622 net.cpp:139] Memory required for data: 36003912
I0416 17:32:42.656455 22622 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0416 17:32:42.656461 22622 net.cpp:86] Creating Layer rpn_cls_prob_reshape
I0416 17:32:42.656463 22622 net.cpp:408] rpn_cls_prob_reshape <- rpn_cls_prob
I0416 17:32:42.656466 22622 net.cpp:382] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0416 17:32:42.656483 22622 net.cpp:124] Setting up rpn_cls_prob_reshape
I0416 17:32:42.656486 22622 net.cpp:131] Top shape: 1 30 32 32 (30720)
I0416 17:32:42.656488 22622 net.cpp:139] Memory required for data: 36126792
I0416 17:32:42.656491 22622 layer_factory.hpp:77] Creating layer conv_new
I0416 17:32:42.656497 22622 net.cpp:86] Creating Layer conv_new
I0416 17:32:42.656500 22622 net.cpp:408] conv_new <- res5c
I0416 17:32:42.656504 22622 net.cpp:382] conv_new -> conv_new
I0416 17:32:42.660948 22622 net.cpp:124] Setting up conv_new
I0416 17:32:42.660957 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.660959 22622 net.cpp:139] Memory required for data: 36651080
I0416 17:32:42.660964 22622 layer_factory.hpp:77] Creating layer conv_new_relu
I0416 17:32:42.660971 22622 net.cpp:86] Creating Layer conv_new_relu
I0416 17:32:42.660974 22622 net.cpp:408] conv_new_relu <- conv_new
I0416 17:32:42.660979 22622 net.cpp:369] conv_new_relu -> conv_new (in-place)
I0416 17:32:42.661325 22622 net.cpp:124] Setting up conv_new_relu
I0416 17:32:42.661332 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.661335 22622 net.cpp:139] Memory required for data: 37175368
I0416 17:32:42.661337 22622 layer_factory.hpp:77] Creating layer conv_new_conv_new_relu_0_split
I0416 17:32:42.661342 22622 net.cpp:86] Creating Layer conv_new_conv_new_relu_0_split
I0416 17:32:42.661345 22622 net.cpp:408] conv_new_conv_new_relu_0_split <- conv_new
I0416 17:32:42.661348 22622 net.cpp:382] conv_new_conv_new_relu_0_split -> conv_new_conv_new_relu_0_split_0
I0416 17:32:42.661352 22622 net.cpp:382] conv_new_conv_new_relu_0_split -> conv_new_conv_new_relu_0_split_1
I0416 17:32:42.661376 22622 net.cpp:124] Setting up conv_new_conv_new_relu_0_split
I0416 17:32:42.661381 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.661383 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.661386 22622 net.cpp:139] Memory required for data: 38223944
I0416 17:32:42.661387 22622 layer_factory.hpp:77] Creating layer conv_left_kx1
I0416 17:32:42.661393 22622 net.cpp:86] Creating Layer conv_left_kx1
I0416 17:32:42.661396 22622 net.cpp:408] conv_left_kx1 <- conv_new_conv_new_relu_0_split_0
I0416 17:32:42.661398 22622 net.cpp:382] conv_left_kx1 -> conv_left_kx1
I0416 17:32:42.664355 22622 net.cpp:124] Setting up conv_left_kx1
I0416 17:32:42.664364 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.664366 22622 net.cpp:139] Memory required for data: 38748232
I0416 17:32:42.664371 22622 layer_factory.hpp:77] Creating layer conv_left_kx1_relu
I0416 17:32:42.664376 22622 net.cpp:86] Creating Layer conv_left_kx1_relu
I0416 17:32:42.664378 22622 net.cpp:408] conv_left_kx1_relu <- conv_left_kx1
I0416 17:32:42.664381 22622 net.cpp:369] conv_left_kx1_relu -> conv_left_kx1 (in-place)
I0416 17:32:42.664741 22622 net.cpp:124] Setting up conv_left_kx1_relu
I0416 17:32:42.664748 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.664752 22622 net.cpp:139] Memory required for data: 39272520
I0416 17:32:42.664753 22622 layer_factory.hpp:77] Creating layer conv_left_1xk
I0416 17:32:42.664760 22622 net.cpp:86] Creating Layer conv_left_1xk
I0416 17:32:42.664762 22622 net.cpp:408] conv_left_1xk <- conv_left_kx1
I0416 17:32:42.664767 22622 net.cpp:382] conv_left_1xk -> conv_left_1xk
I0416 17:32:42.674201 22622 net.cpp:124] Setting up conv_left_1xk
I0416 17:32:42.674216 22622 net.cpp:131] Top shape: 1 490 32 32 (501760)
I0416 17:32:42.674217 22622 net.cpp:139] Memory required for data: 41279560
I0416 17:32:42.674222 22622 layer_factory.hpp:77] Creating layer conv_left_1xk_relu
I0416 17:32:42.674228 22622 net.cpp:86] Creating Layer conv_left_1xk_relu
I0416 17:32:42.674232 22622 net.cpp:408] conv_left_1xk_relu <- conv_left_1xk
I0416 17:32:42.674235 22622 net.cpp:369] conv_left_1xk_relu -> conv_left_1xk (in-place)
I0416 17:32:42.674598 22622 net.cpp:124] Setting up conv_left_1xk_relu
I0416 17:32:42.674607 22622 net.cpp:131] Top shape: 1 490 32 32 (501760)
I0416 17:32:42.674609 22622 net.cpp:139] Memory required for data: 43286600
I0416 17:32:42.674612 22622 layer_factory.hpp:77] Creating layer conv_right_1xk
I0416 17:32:42.674619 22622 net.cpp:86] Creating Layer conv_right_1xk
I0416 17:32:42.674623 22622 net.cpp:408] conv_right_1xk <- conv_new_conv_new_relu_0_split_1
I0416 17:32:42.674626 22622 net.cpp:382] conv_right_1xk -> conv_right_1xk
I0416 17:32:42.678201 22622 net.cpp:124] Setting up conv_right_1xk
I0416 17:32:42.678212 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.678215 22622 net.cpp:139] Memory required for data: 43810888
I0416 17:32:42.678220 22622 layer_factory.hpp:77] Creating layer conv_right_1xk_relu
I0416 17:32:42.678225 22622 net.cpp:86] Creating Layer conv_right_1xk_relu
I0416 17:32:42.678228 22622 net.cpp:408] conv_right_1xk_relu <- conv_right_1xk
I0416 17:32:42.678236 22622 net.cpp:369] conv_right_1xk_relu -> conv_right_1xk (in-place)
I0416 17:32:42.678496 22622 net.cpp:124] Setting up conv_right_1xk_relu
I0416 17:32:42.678503 22622 net.cpp:131] Top shape: 1 128 32 32 (131072)
I0416 17:32:42.678504 22622 net.cpp:139] Memory required for data: 44335176
I0416 17:32:42.678506 22622 layer_factory.hpp:77] Creating layer conv_right_kx1
I0416 17:32:42.678514 22622 net.cpp:86] Creating Layer conv_right_kx1
I0416 17:32:42.678516 22622 net.cpp:408] conv_right_kx1 <- conv_right_1xk
I0416 17:32:42.678520 22622 net.cpp:382] conv_right_kx1 -> conv_right_kx1
I0416 17:32:42.687181 22622 net.cpp:124] Setting up conv_right_kx1
I0416 17:32:42.687196 22622 net.cpp:131] Top shape: 1 490 32 32 (501760)
I0416 17:32:42.687197 22622 net.cpp:139] Memory required for data: 46342216
I0416 17:32:42.687202 22622 layer_factory.hpp:77] Creating layer conv_right_kx1_relu
I0416 17:32:42.687207 22622 net.cpp:86] Creating Layer conv_right_kx1_relu
I0416 17:32:42.687211 22622 net.cpp:408] conv_right_kx1_relu <- conv_right_kx1
I0416 17:32:42.687214 22622 net.cpp:369] conv_right_kx1_relu -> conv_right_kx1 (in-place)
I0416 17:32:42.687481 22622 net.cpp:124] Setting up conv_right_kx1_relu
I0416 17:32:42.687487 22622 net.cpp:131] Top shape: 1 490 32 32 (501760)
I0416 17:32:42.687489 22622 net.cpp:139] Memory required for data: 48349256
I0416 17:32:42.687492 22622 layer_factory.hpp:77] Creating layer ft_add_left_right
I0416 17:32:42.687496 22622 net.cpp:86] Creating Layer ft_add_left_right
I0416 17:32:42.687500 22622 net.cpp:408] ft_add_left_right <- conv_left_1xk
I0416 17:32:42.687502 22622 net.cpp:408] ft_add_left_right <- conv_right_kx1
I0416 17:32:42.687505 22622 net.cpp:382] ft_add_left_right -> ft_add_left_right
I0416 17:32:42.687522 22622 net.cpp:124] Setting up ft_add_left_right
I0416 17:32:42.687525 22622 net.cpp:131] Top shape: 1 490 32 32 (501760)
I0416 17:32:42.687528 22622 net.cpp:139] Memory required for data: 50356296
I0416 17:32:42.687530 22622 layer_factory.hpp:77] Creating layer proposal
I0416 17:32:42.687611 22622 net.cpp:86] Creating Layer proposal
I0416 17:32:42.687616 22622 net.cpp:408] proposal <- rpn_cls_prob_reshape
I0416 17:32:42.687619 22622 net.cpp:408] proposal <- rpn_bbox_pred
I0416 17:32:42.687623 22622 net.cpp:408] proposal <- im_info_input_1_split_0
I0416 17:32:42.687628 22622 net.cpp:382] proposal -> rois
I0416 17:32:42.692266 22622 net.cpp:124] Setting up proposal
I0416 17:32:42.692282 22622 net.cpp:131] Top shape: 1 5 1 1 (5)
I0416 17:32:42.692284 22622 net.cpp:139] Memory required for data: 50356316
I0416 17:32:42.692288 22622 layer_factory.hpp:77] Creating layer rois_proposal_0_split
I0416 17:32:42.692294 22622 net.cpp:86] Creating Layer rois_proposal_0_split
I0416 17:32:42.692298 22622 net.cpp:408] rois_proposal_0_split <- rois
I0416 17:32:42.692302 22622 net.cpp:382] rois_proposal_0_split -> rois_proposal_0_split_0
I0416 17:32:42.692307 22622 net.cpp:382] rois_proposal_0_split -> rois_proposal_0_split_1
I0416 17:32:42.692330 22622 net.cpp:124] Setting up rois_proposal_0_split
I0416 17:32:42.692334 22622 net.cpp:131] Top shape: 1 5 1 1 (5)
I0416 17:32:42.692337 22622 net.cpp:131] Top shape: 1 5 1 1 (5)
I0416 17:32:42.692339 22622 net.cpp:139] Memory required for data: 50356356
I0416 17:32:42.692342 22622 layer_factory.hpp:77] Creating layer psroi_rois
I0416 17:32:42.692353 22622 net.cpp:86] Creating Layer psroi_rois
I0416 17:32:42.692355 22622 net.cpp:408] psroi_rois <- ft_add_left_right
I0416 17:32:42.692358 22622 net.cpp:408] psroi_rois <- rois_proposal_0_split_0
I0416 17:32:42.692363 22622 net.cpp:382] psroi_rois -> psroi_rois
I0416 17:32:42.692394 22622 net.cpp:124] Setting up psroi_rois
I0416 17:32:42.692397 22622 net.cpp:131] Top shape: 1 10 7 7 (490)
I0416 17:32:42.692399 22622 net.cpp:139] Memory required for data: 50358316
I0416 17:32:42.692402 22622 layer_factory.hpp:77] Creating layer inner_rois
I0416 17:32:42.692412 22622 net.cpp:86] Creating Layer inner_rois
I0416 17:32:42.692414 22622 net.cpp:408] inner_rois <- psroi_rois
I0416 17:32:42.692422 22622 net.cpp:382] inner_rois -> inner_rois
I0416 17:32:42.705768 22622 net.cpp:124] Setting up inner_rois
I0416 17:32:42.705783 22622 net.cpp:131] Top shape: 1 2048 (2048)
I0416 17:32:42.705785 22622 net.cpp:139] Memory required for data: 50366508
I0416 17:32:42.705790 22622 layer_factory.hpp:77] Creating layer inner_rois_relu
I0416 17:32:42.705797 22622 net.cpp:86] Creating Layer inner_rois_relu
I0416 17:32:42.705801 22622 net.cpp:408] inner_rois_relu <- inner_rois
I0416 17:32:42.705803 22622 net.cpp:369] inner_rois_relu -> inner_rois (in-place)
I0416 17:32:42.706432 22622 net.cpp:124] Setting up inner_rois_relu
I0416 17:32:42.706440 22622 net.cpp:131] Top shape: 1 2048 (2048)
I0416 17:32:42.706442 22622 net.cpp:139] Memory required for data: 50374700
I0416 17:32:42.706444 22622 layer_factory.hpp:77] Creating layer inner_rois_inner_rois_relu_0_split
I0416 17:32:42.706449 22622 net.cpp:86] Creating Layer inner_rois_inner_rois_relu_0_split
I0416 17:32:42.706451 22622 net.cpp:408] inner_rois_inner_rois_relu_0_split <- inner_rois
I0416 17:32:42.706455 22622 net.cpp:382] inner_rois_inner_rois_relu_0_split -> inner_rois_inner_rois_relu_0_split_0
I0416 17:32:42.706459 22622 net.cpp:382] inner_rois_inner_rois_relu_0_split -> inner_rois_inner_rois_relu_0_split_1
I0416 17:32:42.706512 22622 net.cpp:124] Setting up inner_rois_inner_rois_relu_0_split
I0416 17:32:42.706516 22622 net.cpp:131] Top shape: 1 2048 (2048)
I0416 17:32:42.706519 22622 net.cpp:131] Top shape: 1 2048 (2048)
I0416 17:32:42.706521 22622 net.cpp:139] Memory required for data: 50391084
I0416 17:32:42.706523 22622 layer_factory.hpp:77] Creating layer inner_cls_score_rois
I0416 17:32:42.706528 22622 net.cpp:86] Creating Layer inner_cls_score_rois
I0416 17:32:42.706532 22622 net.cpp:408] inner_cls_score_rois <- inner_rois_inner_rois_relu_0_split_0
I0416 17:32:42.706535 22622 net.cpp:382] inner_cls_score_rois -> cls_score
I0416 17:32:42.706703 22622 net.cpp:124] Setting up inner_cls_score_rois
I0416 17:32:42.706707 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.706710 22622 net.cpp:139] Memory required for data: 50391100
I0416 17:32:42.706714 22622 layer_factory.hpp:77] Creating layer inner_bbox_pred_rois
I0416 17:32:42.706717 22622 net.cpp:86] Creating Layer inner_bbox_pred_rois
I0416 17:32:42.706720 22622 net.cpp:408] inner_bbox_pred_rois <- inner_rois_inner_rois_relu_0_split_1
I0416 17:32:42.706724 22622 net.cpp:382] inner_bbox_pred_rois -> bbox_pred
I0416 17:32:42.707201 22622 net.cpp:124] Setting up inner_bbox_pred_rois
I0416 17:32:42.707206 22622 net.cpp:131] Top shape: 1 16 (16)
I0416 17:32:42.707207 22622 net.cpp:139] Memory required for data: 50391164
I0416 17:32:42.707211 22622 layer_factory.hpp:77] Creating layer cls_score_softmax
I0416 17:32:42.707216 22622 net.cpp:86] Creating Layer cls_score_softmax
I0416 17:32:42.707217 22622 net.cpp:408] cls_score_softmax <- cls_score
I0416 17:32:42.707221 22622 net.cpp:382] cls_score_softmax -> cls_score_softmax
I0416 17:32:42.707645 22622 net.cpp:124] Setting up cls_score_softmax
I0416 17:32:42.707653 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.707656 22622 net.cpp:139] Memory required for data: 50391180
I0416 17:32:42.707659 22622 layer_factory.hpp:77] Creating layer rcnn_proposal
I0416 17:32:42.707684 22622 net.cpp:86] Creating Layer rcnn_proposal
I0416 17:32:42.707689 22622 net.cpp:408] rcnn_proposal <- cls_score_softmax
I0416 17:32:42.707691 22622 net.cpp:408] rcnn_proposal <- bbox_pred
I0416 17:32:42.707695 22622 net.cpp:408] rcnn_proposal <- rois_proposal_0_split_1
I0416 17:32:42.707697 22622 net.cpp:408] rcnn_proposal <- im_info_input_1_split_1
I0416 17:32:42.707705 22622 net.cpp:382] rcnn_proposal -> bboxes
I0416 17:32:42.707809 22622 net.cpp:124] Setting up rcnn_proposal
I0416 17:32:42.707814 22622 net.cpp:131] Top shape: 1 9 1 1 (9)
I0416 17:32:42.707816 22622 net.cpp:139] Memory required for data: 50391216
I0416 17:32:42.707819 22622 net.cpp:202] rcnn_proposal does not need backward computation.
I0416 17:32:42.707823 22622 net.cpp:202] cls_score_softmax does not need backward computation.
I0416 17:32:42.707828 22622 net.cpp:202] inner_bbox_pred_rois does not need backward computation.
I0416 17:32:42.707831 22622 net.cpp:202] inner_cls_score_rois does not need backward computation.
I0416 17:32:42.707834 22622 net.cpp:202] inner_rois_inner_rois_relu_0_split does not need backward computation.
I0416 17:32:42.707836 22622 net.cpp:202] inner_rois_relu does not need backward computation.
I0416 17:32:42.707839 22622 net.cpp:202] inner_rois does not need backward computation.
I0416 17:32:42.707841 22622 net.cpp:202] psroi_rois does not need backward computation.
I0416 17:32:42.707844 22622 net.cpp:202] rois_proposal_0_split does not need backward computation.
I0416 17:32:42.707846 22622 net.cpp:202] proposal does not need backward computation.
I0416 17:32:42.707849 22622 net.cpp:202] ft_add_left_right does not need backward computation.
I0416 17:32:42.707852 22622 net.cpp:202] conv_right_kx1_relu does not need backward computation.
I0416 17:32:42.707854 22622 net.cpp:202] conv_right_kx1 does not need backward computation.
I0416 17:32:42.707857 22622 net.cpp:202] conv_right_1xk_relu does not need backward computation.
I0416 17:32:42.707860 22622 net.cpp:202] conv_right_1xk does not need backward computation.
I0416 17:32:42.707862 22622 net.cpp:202] conv_left_1xk_relu does not need backward computation.
I0416 17:32:42.707865 22622 net.cpp:202] conv_left_1xk does not need backward computation.
I0416 17:32:42.707868 22622 net.cpp:202] conv_left_kx1_relu does not need backward computation.
I0416 17:32:42.707870 22622 net.cpp:202] conv_left_kx1 does not need backward computation.
I0416 17:32:42.707873 22622 net.cpp:202] conv_new_conv_new_relu_0_split does not need backward computation.
I0416 17:32:42.707876 22622 net.cpp:202] conv_new_relu does not need backward computation.
I0416 17:32:42.707878 22622 net.cpp:202] conv_new does not need backward computation.
I0416 17:32:42.707881 22622 net.cpp:202] rpn_cls_prob_reshape does not need backward computation.
I0416 17:32:42.707885 22622 net.cpp:202] rpn_cls_prob does not need backward computation.
I0416 17:32:42.707887 22622 net.cpp:202] rpn_cls_score_reshape does not need backward computation.
I0416 17:32:42.707890 22622 net.cpp:202] rpn_bbox_pred does not need backward computation.
I0416 17:32:42.707892 22622 net.cpp:202] rpn_cls_score does not need backward computation.
I0416 17:32:42.707895 22622 net.cpp:202] rpn/output_rpn_relu_0_split does not need backward computation.
I0416 17:32:42.707898 22622 net.cpp:202] rpn_relu does not need backward computation.
I0416 17:32:42.707901 22622 net.cpp:202] rpn_deconv does not need backward computation.
I0416 17:32:42.707903 22622 net.cpp:202] res5c_relu does not need backward computation.
I0416 17:32:42.707906 22622 net.cpp:202] res5c does not need backward computation.
I0416 17:32:42.707909 22622 net.cpp:202] scale5c_branch2b does not need backward computation.
I0416 17:32:42.707911 22622 net.cpp:202] bn5c_branch2b does not need backward computation.
I0416 17:32:42.707914 22622 net.cpp:202] res5c_branch2b does not need backward computation.
I0416 17:32:42.707916 22622 net.cpp:202] res5c_branch2a_relu does not need backward computation.
I0416 17:32:42.707919 22622 net.cpp:202] scale5c_branch2a does not need backward computation.
I0416 17:32:42.707921 22622 net.cpp:202] bn5c_branch2a does not need backward computation.
I0416 17:32:42.707923 22622 net.cpp:202] res5c_branch2a does not need backward computation.
I0416 17:32:42.707926 22622 net.cpp:202] res5b_res5b_relu_0_split does not need backward computation.
I0416 17:32:42.707929 22622 net.cpp:202] res5b_relu does not need backward computation.
I0416 17:32:42.707932 22622 net.cpp:202] res5b does not need backward computation.
I0416 17:32:42.707935 22622 net.cpp:202] scale5b_branch2b does not need backward computation.
I0416 17:32:42.707938 22622 net.cpp:202] bn5b_branch2b does not need backward computation.
I0416 17:32:42.707942 22622 net.cpp:202] res5b_branch2b does not need backward computation.
I0416 17:32:42.707943 22622 net.cpp:202] res5b_branch2a_relu does not need backward computation.
I0416 17:32:42.707948 22622 net.cpp:202] scale5b_branch2a does not need backward computation.
I0416 17:32:42.707950 22622 net.cpp:202] bn5b_branch2a does not need backward computation.
I0416 17:32:42.707953 22622 net.cpp:202] res5b_branch2a does not need backward computation.
I0416 17:32:42.707955 22622 net.cpp:202] res5a_res5a_relu_0_split does not need backward computation.
I0416 17:32:42.707958 22622 net.cpp:202] res5a_relu does not need backward computation.
I0416 17:32:42.707960 22622 net.cpp:202] res5a does not need backward computation.
I0416 17:32:42.707964 22622 net.cpp:202] scale5a_branch2b does not need backward computation.
I0416 17:32:42.707967 22622 net.cpp:202] bn5a_branch2b does not need backward computation.
I0416 17:32:42.707969 22622 net.cpp:202] res5a_branch2b does not need backward computation.
I0416 17:32:42.707973 22622 net.cpp:202] res5a_branch2a_relu does not need backward computation.
I0416 17:32:42.707974 22622 net.cpp:202] scale5a_branch2a does not need backward computation.
I0416 17:32:42.707978 22622 net.cpp:202] bn5a_branch2a does not need backward computation.
I0416 17:32:42.707980 22622 net.cpp:202] res5a_branch2a does not need backward computation.
I0416 17:32:42.707983 22622 net.cpp:202] scale5a_branch1 does not need backward computation.
I0416 17:32:42.707985 22622 net.cpp:202] bn5a_branch1 does not need backward computation.
I0416 17:32:42.707988 22622 net.cpp:202] res5a_branch1 does not need backward computation.
I0416 17:32:42.707990 22622 net.cpp:202] res4f_res4f_relu_0_split does not need backward computation.
I0416 17:32:42.707993 22622 net.cpp:202] res4f_relu does not need backward computation.
I0416 17:32:42.707996 22622 net.cpp:202] res4f does not need backward computation.
I0416 17:32:42.707999 22622 net.cpp:202] scale4f_branch2b does not need backward computation.
I0416 17:32:42.708003 22622 net.cpp:202] bn4f_branch2b does not need backward computation.
I0416 17:32:42.708004 22622 net.cpp:202] res4f_branch2b does not need backward computation.
I0416 17:32:42.708007 22622 net.cpp:202] res4f_branch2a_relu does not need backward computation.
I0416 17:32:42.708010 22622 net.cpp:202] scale4f_branch2a does not need backward computation.
I0416 17:32:42.708012 22622 net.cpp:202] bn4f_branch2a does not need backward computation.
I0416 17:32:42.708015 22622 net.cpp:202] res4f_branch2a does not need backward computation.
I0416 17:32:42.708019 22622 net.cpp:202] res4e_res4e_relu_0_split does not need backward computation.
I0416 17:32:42.708021 22622 net.cpp:202] res4e_relu does not need backward computation.
I0416 17:32:42.708024 22622 net.cpp:202] res4e does not need backward computation.
I0416 17:32:42.708027 22622 net.cpp:202] scale4e_branch2b does not need backward computation.
I0416 17:32:42.708029 22622 net.cpp:202] bn4e_branch2b does not need backward computation.
I0416 17:32:42.708032 22622 net.cpp:202] res4e_branch2b does not need backward computation.
I0416 17:32:42.708034 22622 net.cpp:202] res4e_branch2a_relu does not need backward computation.
I0416 17:32:42.708037 22622 net.cpp:202] scale4e_branch2a does not need backward computation.
I0416 17:32:42.708040 22622 net.cpp:202] bn4e_branch2a does not need backward computation.
I0416 17:32:42.708042 22622 net.cpp:202] res4e_branch2a does not need backward computation.
I0416 17:32:42.708045 22622 net.cpp:202] res4d_res4d_relu_0_split does not need backward computation.
I0416 17:32:42.708048 22622 net.cpp:202] res4d_relu does not need backward computation.
I0416 17:32:42.708050 22622 net.cpp:202] res4d does not need backward computation.
I0416 17:32:42.708053 22622 net.cpp:202] scale4d_branch2b does not need backward computation.
I0416 17:32:42.708056 22622 net.cpp:202] bn4d_branch2b does not need backward computation.
I0416 17:32:42.708060 22622 net.cpp:202] res4d_branch2b does not need backward computation.
I0416 17:32:42.708062 22622 net.cpp:202] res4d_branch2a_relu does not need backward computation.
I0416 17:32:42.708065 22622 net.cpp:202] scale4d_branch2a does not need backward computation.
I0416 17:32:42.708068 22622 net.cpp:202] bn4d_branch2a does not need backward computation.
I0416 17:32:42.708071 22622 net.cpp:202] res4d_branch2a does not need backward computation.
I0416 17:32:42.708075 22622 net.cpp:202] res4c_res4c_relu_0_split does not need backward computation.
I0416 17:32:42.708076 22622 net.cpp:202] res4c_relu does not need backward computation.
I0416 17:32:42.708079 22622 net.cpp:202] res4c does not need backward computation.
I0416 17:32:42.708082 22622 net.cpp:202] scale4c_branch2b does not need backward computation.
I0416 17:32:42.708086 22622 net.cpp:202] bn4c_branch2b does not need backward computation.
I0416 17:32:42.708087 22622 net.cpp:202] res4c_branch2b does not need backward computation.
I0416 17:32:42.708091 22622 net.cpp:202] res4c_branch2a_relu does not need backward computation.
I0416 17:32:42.708093 22622 net.cpp:202] scale4c_branch2a does not need backward computation.
I0416 17:32:42.708096 22622 net.cpp:202] bn4c_branch2a does not need backward computation.
I0416 17:32:42.708098 22622 net.cpp:202] res4c_branch2a does not need backward computation.
I0416 17:32:42.708101 22622 net.cpp:202] res4b_res4b_relu_0_split does not need backward computation.
I0416 17:32:42.708106 22622 net.cpp:202] res4b_relu does not need backward computation.
I0416 17:32:42.708108 22622 net.cpp:202] res4b does not need backward computation.
I0416 17:32:42.708122 22622 net.cpp:202] scale4b_branch2b does not need backward computation.
I0416 17:32:42.708127 22622 net.cpp:202] bn4b_branch2b does not need backward computation.
I0416 17:32:42.708129 22622 net.cpp:202] res4b_branch2b does not need backward computation.
I0416 17:32:42.708132 22622 net.cpp:202] res4b_branch2a_relu does not need backward computation.
I0416 17:32:42.708135 22622 net.cpp:202] scale4b_branch2a does not need backward computation.
I0416 17:32:42.708137 22622 net.cpp:202] bn4b_branch2a does not need backward computation.
I0416 17:32:42.708140 22622 net.cpp:202] res4b_branch2a does not need backward computation.
I0416 17:32:42.708143 22622 net.cpp:202] res4a_res4a_relu_0_split does not need backward computation.
I0416 17:32:42.708146 22622 net.cpp:202] res4a_relu does not need backward computation.
I0416 17:32:42.708148 22622 net.cpp:202] res4a does not need backward computation.
I0416 17:32:42.708153 22622 net.cpp:202] scale4a_branch2b does not need backward computation.
I0416 17:32:42.708155 22622 net.cpp:202] bn4a_branch2b does not need backward computation.
I0416 17:32:42.708158 22622 net.cpp:202] res4a_branch2b does not need backward computation.
I0416 17:32:42.708160 22622 net.cpp:202] res4a_branch2a_relu does not need backward computation.
I0416 17:32:42.708163 22622 net.cpp:202] scale4a_branch2a does not need backward computation.
I0416 17:32:42.708166 22622 net.cpp:202] bn4a_branch2a does not need backward computation.
I0416 17:32:42.708168 22622 net.cpp:202] res4a_branch2a does not need backward computation.
I0416 17:32:42.708171 22622 net.cpp:202] scale4a_branch1 does not need backward computation.
I0416 17:32:42.708174 22622 net.cpp:202] bn4a_branch1 does not need backward computation.
I0416 17:32:42.708176 22622 net.cpp:202] res4a_branch1 does not need backward computation.
I0416 17:32:42.708179 22622 net.cpp:202] res3d_res3d_relu_0_split does not need backward computation.
I0416 17:32:42.708182 22622 net.cpp:202] res3d_relu does not need backward computation.
I0416 17:32:42.708185 22622 net.cpp:202] res3d does not need backward computation.
I0416 17:32:42.708189 22622 net.cpp:202] scale3d_branch2b does not need backward computation.
I0416 17:32:42.708191 22622 net.cpp:202] bn3d_branch2b does not need backward computation.
I0416 17:32:42.708194 22622 net.cpp:202] res3d_branch2b does not need backward computation.
I0416 17:32:42.708196 22622 net.cpp:202] res3d_branch2a_relu does not need backward computation.
I0416 17:32:42.708199 22622 net.cpp:202] scale3d_branch2a does not need backward computation.
I0416 17:32:42.708201 22622 net.cpp:202] bn3d_branch2a does not need backward computation.
I0416 17:32:42.708204 22622 net.cpp:202] res3d_branch2a does not need backward computation.
I0416 17:32:42.708209 22622 net.cpp:202] res3c_res3c_relu_0_split does not need backward computation.
I0416 17:32:42.708212 22622 net.cpp:202] res3c_relu does not need backward computation.
I0416 17:32:42.708215 22622 net.cpp:202] res3c does not need backward computation.
I0416 17:32:42.708218 22622 net.cpp:202] scale3c_branch2b does not need backward computation.
I0416 17:32:42.708221 22622 net.cpp:202] bn3c_branch2b does not need backward computation.
I0416 17:32:42.708223 22622 net.cpp:202] res3c_branch2b does not need backward computation.
I0416 17:32:42.708227 22622 net.cpp:202] res3c_branch2a_relu does not need backward computation.
I0416 17:32:42.708230 22622 net.cpp:202] scale3c_branch2a does not need backward computation.
I0416 17:32:42.708232 22622 net.cpp:202] bn3c_branch2a does not need backward computation.
I0416 17:32:42.708235 22622 net.cpp:202] res3c_branch2a does not need backward computation.
I0416 17:32:42.708237 22622 net.cpp:202] res3b_res3b_relu_0_split does not need backward computation.
I0416 17:32:42.708240 22622 net.cpp:202] res3b_relu does not need backward computation.
I0416 17:32:42.708243 22622 net.cpp:202] res3b does not need backward computation.
I0416 17:32:42.708246 22622 net.cpp:202] scale3b_branch2b does not need backward computation.
I0416 17:32:42.708250 22622 net.cpp:202] bn3b_branch2b does not need backward computation.
I0416 17:32:42.708251 22622 net.cpp:202] res3b_branch2b does not need backward computation.
I0416 17:32:42.708254 22622 net.cpp:202] res3b_branch2a_relu does not need backward computation.
I0416 17:32:42.708256 22622 net.cpp:202] scale3b_branch2a does not need backward computation.
I0416 17:32:42.708259 22622 net.cpp:202] bn3b_branch2a does not need backward computation.
I0416 17:32:42.708262 22622 net.cpp:202] res3b_branch2a does not need backward computation.
I0416 17:32:42.708266 22622 net.cpp:202] res3a_res3a_relu_0_split does not need backward computation.
I0416 17:32:42.708268 22622 net.cpp:202] res3a_relu does not need backward computation.
I0416 17:32:42.708271 22622 net.cpp:202] res3a does not need backward computation.
I0416 17:32:42.708274 22622 net.cpp:202] scale3a_branch2b does not need backward computation.
I0416 17:32:42.708277 22622 net.cpp:202] bn3a_branch2b does not need backward computation.
I0416 17:32:42.708279 22622 net.cpp:202] res3a_branch2b does not need backward computation.
I0416 17:32:42.708282 22622 net.cpp:202] res3a_branch2a_relu does not need backward computation.
I0416 17:32:42.708286 22622 net.cpp:202] scale3a_branch2a does not need backward computation.
I0416 17:32:42.708287 22622 net.cpp:202] bn3a_branch2a does not need backward computation.
I0416 17:32:42.708290 22622 net.cpp:202] res3a_branch2a does not need backward computation.
I0416 17:32:42.708292 22622 net.cpp:202] scale3a_branch1 does not need backward computation.
I0416 17:32:42.708295 22622 net.cpp:202] bn3a_branch1 does not need backward computation.
I0416 17:32:42.708298 22622 net.cpp:202] res3a_branch1 does not need backward computation.
I0416 17:32:42.708302 22622 net.cpp:202] res2c_res2c_relu_0_split does not need backward computation.
I0416 17:32:42.708303 22622 net.cpp:202] res2c_relu does not need backward computation.
I0416 17:32:42.708307 22622 net.cpp:202] res2c does not need backward computation.
I0416 17:32:42.708309 22622 net.cpp:202] scale2c_branch2b does not need backward computation.
I0416 17:32:42.708312 22622 net.cpp:202] bn2c_branch2b does not need backward computation.
I0416 17:32:42.708315 22622 net.cpp:202] res2c_branch2b does not need backward computation.
I0416 17:32:42.708317 22622 net.cpp:202] res2c_branch2a_relu does not need backward computation.
I0416 17:32:42.708320 22622 net.cpp:202] scale2c_branch2a does not need backward computation.
I0416 17:32:42.708323 22622 net.cpp:202] bn2c_branch2a does not need backward computation.
I0416 17:32:42.708325 22622 net.cpp:202] res2c_branch2a does not need backward computation.
I0416 17:32:42.708328 22622 net.cpp:202] res2b_res2b_relu_0_split does not need backward computation.
I0416 17:32:42.708333 22622 net.cpp:202] res2b_relu does not need backward computation.
I0416 17:32:42.708335 22622 net.cpp:202] res2b does not need backward computation.
I0416 17:32:42.708338 22622 net.cpp:202] scale2b_branch2b does not need backward computation.
I0416 17:32:42.708340 22622 net.cpp:202] bn2b_branch2b does not need backward computation.
I0416 17:32:42.708343 22622 net.cpp:202] res2b_branch2b does not need backward computation.
I0416 17:32:42.708346 22622 net.cpp:202] res2b_branch2a_relu does not need backward computation.
I0416 17:32:42.708348 22622 net.cpp:202] scale2b_branch2a does not need backward computation.
I0416 17:32:42.708351 22622 net.cpp:202] bn2b_branch2a does not need backward computation.
I0416 17:32:42.708353 22622 net.cpp:202] res2b_branch2a does not need backward computation.
I0416 17:32:42.708356 22622 net.cpp:202] res2a_res2a_relu_0_split does not need backward computation.
I0416 17:32:42.708359 22622 net.cpp:202] res2a_relu does not need backward computation.
I0416 17:32:42.708362 22622 net.cpp:202] res2a does not need backward computation.
I0416 17:32:42.708365 22622 net.cpp:202] scale2a_branch2b does not need backward computation.
I0416 17:32:42.708367 22622 net.cpp:202] bn2a_branch2b does not need backward computation.
I0416 17:32:42.708370 22622 net.cpp:202] res2a_branch2b does not need backward computation.
I0416 17:32:42.708374 22622 net.cpp:202] res2a_branch2a_relu does not need backward computation.
I0416 17:32:42.708375 22622 net.cpp:202] scale2a_branch2a does not need backward computation.
I0416 17:32:42.708379 22622 net.cpp:202] bn2a_branch2a does not need backward computation.
I0416 17:32:42.708380 22622 net.cpp:202] res2a_branch2a does not need backward computation.
I0416 17:32:42.708384 22622 net.cpp:202] scale2a_branch1 does not need backward computation.
I0416 17:32:42.708386 22622 net.cpp:202] bn2a_branch1 does not need backward computation.
I0416 17:32:42.708389 22622 net.cpp:202] res2a_branch1 does not need backward computation.
I0416 17:32:42.708391 22622 net.cpp:202] pool1_pool1_0_split does not need backward computation.
I0416 17:32:42.708395 22622 net.cpp:202] pool1 does not need backward computation.
I0416 17:32:42.708397 22622 net.cpp:202] conv1_relu does not need backward computation.
I0416 17:32:42.708400 22622 net.cpp:202] scale_conv1 does not need backward computation.
I0416 17:32:42.708402 22622 net.cpp:202] bn_conv1 does not need backward computation.
I0416 17:32:42.708405 22622 net.cpp:202] conv1 does not need backward computation.
I0416 17:32:42.708406 22622 net.cpp:202] permute does not need backward computation.
I0416 17:32:42.708410 22622 net.cpp:202] im_info_input_1_split does not need backward computation.
I0416 17:32:42.708412 22622 net.cpp:202] input does not need backward computation.
I0416 17:32:42.708415 22622 net.cpp:244] This network produces output bboxes
I0416 17:32:42.708492 22622 net.cpp:257] Network initialization done.
I0416 17:32:42.715215 22622 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /apollo/modules/perception/production/data/perception/camera/models/traffic_light_detection/./baidu_iter_140000.caffemodel
I0416 17:32:42.715245 22622 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0416 17:32:42.715253 22622 net.cpp:746] Ignoring source layer data
I0416 17:32:42.715256 22622 net.cpp:746] Ignoring source layer gt_labels_data_1_split
I0416 17:32:42.715258 22622 net.cpp:746] Ignoring source layer im_info_data_2_split
I0416 17:32:42.715261 22622 net.cpp:746] Ignoring source layer image_distort
I0416 17:32:42.716251 22622 net.cpp:746] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0416 17:32:42.716269 22622 net.cpp:746] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0416 17:32:42.716271 22622 net.cpp:746] Ignoring source layer rpn_data
I0416 17:32:42.716274 22622 net.cpp:746] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0416 17:32:42.716277 22622 net.cpp:746] Ignoring source layer rpn_loss_cls
I0416 17:32:42.716285 22622 net.cpp:746] Ignoring source layer rpn_loss_bbox
I0416 17:32:42.716289 22622 net.cpp:746] Ignoring source layer proposal_target
I0416 17:32:42.716292 22622 net.cpp:746] Ignoring source layer rois_proposal_target_0_split
I0416 17:32:42.716295 22622 net.cpp:746] Ignoring source layer cls_labels_proposal_target_1_split
I0416 17:32:42.716297 22622 net.cpp:746] Ignoring source layer box_labels_proposal_target_2_split
I0416 17:32:42.716300 22622 net.cpp:746] Ignoring source layer box_inside_weights_proposal_target_3_split
I0416 17:32:42.716301 22622 net.cpp:746] Ignoring source layer box_outside_weights_proposal_target_4_split
I0416 17:32:42.716305 22622 net.cpp:746] Ignoring source layer cls_label_weights_proposal_target_5_split
I0416 17:32:42.717624 22622 net.cpp:746] Ignoring source layer cls_score_inner_cls_score_rois_0_split
I0416 17:32:42.717650 22622 net.cpp:746] Ignoring source layer bbox_pred_inner_bbox_pred_rois_0_split
I0416 17:32:42.717653 22622 net.cpp:746] Ignoring source layer per_roi_loss_cls
I0416 17:32:42.717655 22622 net.cpp:746] Ignoring source layer per_roi_loss_bbox
I0416 17:32:42.717658 22622 net.cpp:746] Ignoring source layer per_roi_loss
I0416 17:32:42.717660 22622 net.cpp:746] Ignoring source layer box_annotator_ohem
I0416 17:32:42.717662 22622 net.cpp:746] Ignoring source layer labels_ohem_box_annotator_ohem_0_split
I0416 17:32:42.717665 22622 net.cpp:746] Ignoring source layer silence
I0416 17:32:42.717667 22622 net.cpp:746] Ignoring source layer loss_cls
I0416 17:32:42.717670 22622 net.cpp:746] Ignoring source layer accuracy
I0416 17:32:42.717672 22622 net.cpp:746] Ignoring source layer loss_bbox
I0416 17:32:42.721412 22622 detection.cc:124] []net init success.
I0416 17:32:42.721439 22622 recognition.cc:29] []proto_path /apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/recognition.pt
I0416 17:32:42.721583 22622 classify.cc:34] []Enter Classify init
I0416 17:32:42.721587 22622 classify.cc:37] []clear success
I0416 17:32:42.721590 22622 classify.cc:41] []1
I0416 17:32:42.721592 22622 classify.cc:42] []1
I0416 17:32:42.721594 22622 classify.cc:45] []net input blobs: data_org
I0416 17:32:42.721596 22622 classify.cc:48] []net output blobs: prob
I0416 17:32:42.721599 22622 classify.cc:56] []proto_file /apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/quadrate/deploy.prototxt
I0416 17:32:42.721602 22622 classify.cc:61] []model_root/apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/./
I0416 17:32:42.721606 22622 classify.cc:66] []create success
I0416 17:32:42.721611 22622 classify.cc:94] []input_reshape: 1, 64, 64, 3
I0416 17:32:42.721750 22622 common.cpp:178] Device id:                     0
I0416 17:32:42.721753 22622 common.cpp:179] Major revision number:         6
I0416 17:32:42.721755 22622 common.cpp:180] Minor revision number:         1
I0416 17:32:42.721757 22622 common.cpp:181] Name:                          GeForce GTX 1070 Ti
I0416 17:32:42.721760 22622 common.cpp:182] Total global memory:           8510701568
I0416 17:32:42.721762 22622 common.cpp:183] Total shared memory per block: 49152
I0416 17:32:42.721765 22622 common.cpp:184] Total registers per block:     65536
I0416 17:32:42.721766 22622 common.cpp:185] Warp size:                     32
I0416 17:32:42.721768 22622 common.cpp:186] Maximum memory pitch:          2147483647
I0416 17:32:42.721771 22622 common.cpp:187] Maximum threads per block:     1024
I0416 17:32:42.721772 22622 common.cpp:188] Maximum dimension of block:    1024, 1024, 64
I0416 17:32:42.721774 22622 common.cpp:191] Maximum dimension of grid:     2147483647, 65535, 65535
I0416 17:32:42.721777 22622 common.cpp:194] Clock rate:                    1683000
I0416 17:32:42.721779 22622 common.cpp:195] Total constant memory:         65536
I0416 17:32:42.721781 22622 common.cpp:196] Texture alignment:             512
I0416 17:32:42.721783 22622 common.cpp:197] Concurrent copy and execution: Yes
I0416 17:32:42.721791 22622 common.cpp:199] Number of multiprocessors:     19
I0416 17:32:42.721792 22622 common.cpp:200] Kernel execution timeout:      Yes
I0416 17:32:42.722296 22622 net.cpp:53] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data_org"
  input_param {
    shape {
      dim: 1
      dim: 64
      dim: 64
      dim: 3
    }
  }
}
layer {
  name: "permute"
  type: "Permute"
  bottom: "data_org"
  top: "data"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1_bn_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_bn_scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv2_relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv3_bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_bn_scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv3_relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_bn_scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv4_relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_bn_scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv5_relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_h: 4
    kernel_w: 4
    stride_h: 4
    stride_w: 4
    round_mode: FLOOR
  }
}
layer {
  name: "ft"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ft"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ft_bn"
  type: "BatchNorm"
  bottom: "ft"
  top: "ft"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "ft_bn_scale"
  type: "Scale"
  bottom: "ft"
  top: "ft"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "ft_relu"
  type: "ReLU"
  bottom: "ft"
  top: "ft"
}
layer {
  name: "logits"
  type: "InnerProduct"
  bottom: "ft"
  top: "logits"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "logits"
  top: "prob"
}
I0416 17:32:42.722352 22622 layer_factory.hpp:77] Creating layer input
I0416 17:32:42.722357 22622 net.cpp:86] Creating Layer input
I0416 17:32:42.722360 22622 net.cpp:382] input -> data_org
I0416 17:32:42.722383 22622 net.cpp:124] Setting up input
I0416 17:32:42.722388 22622 net.cpp:131] Top shape: 1 64 64 3 (12288)
I0416 17:32:42.722390 22622 net.cpp:139] Memory required for data: 49152
I0416 17:32:42.722393 22622 layer_factory.hpp:77] Creating layer permute
I0416 17:32:42.722398 22622 net.cpp:86] Creating Layer permute
I0416 17:32:42.722400 22622 net.cpp:408] permute <- data_org
I0416 17:32:42.722404 22622 net.cpp:382] permute -> data
I0416 17:32:42.722471 22622 net.cpp:124] Setting up permute
I0416 17:32:42.722476 22622 net.cpp:131] Top shape: 1 3 64 64 (12288)
I0416 17:32:42.722477 22622 net.cpp:139] Memory required for data: 98304
I0416 17:32:42.722479 22622 layer_factory.hpp:77] Creating layer conv1
I0416 17:32:42.722486 22622 net.cpp:86] Creating Layer conv1
I0416 17:32:42.722488 22622 net.cpp:408] conv1 <- data
I0416 17:32:42.722491 22622 net.cpp:382] conv1 -> conv1
I0416 17:32:42.723692 22622 net.cpp:124] Setting up conv1
I0416 17:32:42.723701 22622 net.cpp:131] Top shape: 1 32 64 64 (131072)
I0416 17:32:42.723703 22622 net.cpp:139] Memory required for data: 622592
I0416 17:32:42.723709 22622 layer_factory.hpp:77] Creating layer conv1_bn
I0416 17:32:42.723714 22622 net.cpp:86] Creating Layer conv1_bn
I0416 17:32:42.723716 22622 net.cpp:408] conv1_bn <- conv1
I0416 17:32:42.723719 22622 net.cpp:369] conv1_bn -> conv1 (in-place)
I0416 17:32:42.723861 22622 net.cpp:124] Setting up conv1_bn
I0416 17:32:42.723866 22622 net.cpp:131] Top shape: 1 32 64 64 (131072)
I0416 17:32:42.723871 22622 net.cpp:139] Memory required for data: 1146880
I0416 17:32:42.723877 22622 layer_factory.hpp:77] Creating layer conv1_bn_scale
I0416 17:32:42.723881 22622 net.cpp:86] Creating Layer conv1_bn_scale
I0416 17:32:42.723883 22622 net.cpp:408] conv1_bn_scale <- conv1
I0416 17:32:42.723886 22622 net.cpp:369] conv1_bn_scale -> conv1 (in-place)
I0416 17:32:42.723946 22622 net.cpp:124] Setting up conv1_bn_scale
I0416 17:32:42.723949 22622 net.cpp:131] Top shape: 1 32 64 64 (131072)
I0416 17:32:42.723953 22622 net.cpp:139] Memory required for data: 1671168
I0416 17:32:42.723954 22622 layer_factory.hpp:77] Creating layer conv1_relu
I0416 17:32:42.723958 22622 net.cpp:86] Creating Layer conv1_relu
I0416 17:32:42.723960 22622 net.cpp:408] conv1_relu <- conv1
I0416 17:32:42.723963 22622 net.cpp:369] conv1_relu -> conv1 (in-place)
I0416 17:32:42.724189 22622 net.cpp:124] Setting up conv1_relu
I0416 17:32:42.724195 22622 net.cpp:131] Top shape: 1 32 64 64 (131072)
I0416 17:32:42.724197 22622 net.cpp:139] Memory required for data: 2195456
I0416 17:32:42.724200 22622 layer_factory.hpp:77] Creating layer pool1
I0416 17:32:42.724203 22622 net.cpp:86] Creating Layer pool1
I0416 17:32:42.724206 22622 net.cpp:408] pool1 <- conv1
I0416 17:32:42.724210 22622 net.cpp:382] pool1 -> pool1
I0416 17:32:42.724236 22622 net.cpp:124] Setting up pool1
I0416 17:32:42.724239 22622 net.cpp:131] Top shape: 1 32 32 32 (32768)
I0416 17:32:42.724242 22622 net.cpp:139] Memory required for data: 2326528
I0416 17:32:42.724244 22622 layer_factory.hpp:77] Creating layer conv2
I0416 17:32:42.724249 22622 net.cpp:86] Creating Layer conv2
I0416 17:32:42.724251 22622 net.cpp:408] conv2 <- pool1
I0416 17:32:42.724254 22622 net.cpp:382] conv2 -> conv2
I0416 17:32:42.725595 22622 net.cpp:124] Setting up conv2
I0416 17:32:42.725603 22622 net.cpp:131] Top shape: 1 64 32 32 (65536)
I0416 17:32:42.725606 22622 net.cpp:139] Memory required for data: 2588672
I0416 17:32:42.725610 22622 layer_factory.hpp:77] Creating layer conv2_bn
I0416 17:32:42.725615 22622 net.cpp:86] Creating Layer conv2_bn
I0416 17:32:42.725617 22622 net.cpp:408] conv2_bn <- conv2
I0416 17:32:42.725620 22622 net.cpp:369] conv2_bn -> conv2 (in-place)
I0416 17:32:42.725770 22622 net.cpp:124] Setting up conv2_bn
I0416 17:32:42.725775 22622 net.cpp:131] Top shape: 1 64 32 32 (65536)
I0416 17:32:42.725776 22622 net.cpp:139] Memory required for data: 2850816
I0416 17:32:42.725781 22622 layer_factory.hpp:77] Creating layer conv2_bn_scale
I0416 17:32:42.725785 22622 net.cpp:86] Creating Layer conv2_bn_scale
I0416 17:32:42.725787 22622 net.cpp:408] conv2_bn_scale <- conv2
I0416 17:32:42.725790 22622 net.cpp:369] conv2_bn_scale -> conv2 (in-place)
I0416 17:32:42.725852 22622 net.cpp:124] Setting up conv2_bn_scale
I0416 17:32:42.725857 22622 net.cpp:131] Top shape: 1 64 32 32 (65536)
I0416 17:32:42.725858 22622 net.cpp:139] Memory required for data: 3112960
I0416 17:32:42.725862 22622 layer_factory.hpp:77] Creating layer conv2_relu
I0416 17:32:42.725864 22622 net.cpp:86] Creating Layer conv2_relu
I0416 17:32:42.725867 22622 net.cpp:408] conv2_relu <- conv2
I0416 17:32:42.725869 22622 net.cpp:369] conv2_relu -> conv2 (in-place)
I0416 17:32:42.726097 22622 net.cpp:124] Setting up conv2_relu
I0416 17:32:42.726104 22622 net.cpp:131] Top shape: 1 64 32 32 (65536)
I0416 17:32:42.726105 22622 net.cpp:139] Memory required for data: 3375104
I0416 17:32:42.726107 22622 layer_factory.hpp:77] Creating layer pool2
I0416 17:32:42.726112 22622 net.cpp:86] Creating Layer pool2
I0416 17:32:42.726114 22622 net.cpp:408] pool2 <- conv2
I0416 17:32:42.726117 22622 net.cpp:382] pool2 -> pool2
I0416 17:32:42.726145 22622 net.cpp:124] Setting up pool2
I0416 17:32:42.726148 22622 net.cpp:131] Top shape: 1 64 16 16 (16384)
I0416 17:32:42.726150 22622 net.cpp:139] Memory required for data: 3440640
I0416 17:32:42.726152 22622 layer_factory.hpp:77] Creating layer conv3
I0416 17:32:42.726157 22622 net.cpp:86] Creating Layer conv3
I0416 17:32:42.726159 22622 net.cpp:408] conv3 <- pool2
I0416 17:32:42.726166 22622 net.cpp:382] conv3 -> conv3
I0416 17:32:42.729317 22622 net.cpp:124] Setting up conv3
I0416 17:32:42.729331 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.729333 22622 net.cpp:139] Memory required for data: 3571712
I0416 17:32:42.729337 22622 layer_factory.hpp:77] Creating layer conv3_bn
I0416 17:32:42.729342 22622 net.cpp:86] Creating Layer conv3_bn
I0416 17:32:42.729346 22622 net.cpp:408] conv3_bn <- conv3
I0416 17:32:42.729348 22622 net.cpp:369] conv3_bn -> conv3 (in-place)
I0416 17:32:42.729497 22622 net.cpp:124] Setting up conv3_bn
I0416 17:32:42.729502 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.729504 22622 net.cpp:139] Memory required for data: 3702784
I0416 17:32:42.729511 22622 layer_factory.hpp:77] Creating layer conv3_bn_scale
I0416 17:32:42.729516 22622 net.cpp:86] Creating Layer conv3_bn_scale
I0416 17:32:42.729518 22622 net.cpp:408] conv3_bn_scale <- conv3
I0416 17:32:42.729521 22622 net.cpp:369] conv3_bn_scale -> conv3 (in-place)
I0416 17:32:42.729583 22622 net.cpp:124] Setting up conv3_bn_scale
I0416 17:32:42.729586 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.729588 22622 net.cpp:139] Memory required for data: 3833856
I0416 17:32:42.729591 22622 layer_factory.hpp:77] Creating layer conv3_relu
I0416 17:32:42.729594 22622 net.cpp:86] Creating Layer conv3_relu
I0416 17:32:42.729596 22622 net.cpp:408] conv3_relu <- conv3
I0416 17:32:42.729599 22622 net.cpp:369] conv3_relu -> conv3 (in-place)
I0416 17:32:42.729907 22622 net.cpp:124] Setting up conv3_relu
I0416 17:32:42.729914 22622 net.cpp:131] Top shape: 1 128 16 16 (32768)
I0416 17:32:42.729916 22622 net.cpp:139] Memory required for data: 3964928
I0416 17:32:42.729918 22622 layer_factory.hpp:77] Creating layer pool3
I0416 17:32:42.729923 22622 net.cpp:86] Creating Layer pool3
I0416 17:32:42.729926 22622 net.cpp:408] pool3 <- conv3
I0416 17:32:42.729929 22622 net.cpp:382] pool3 -> pool3
I0416 17:32:42.729959 22622 net.cpp:124] Setting up pool3
I0416 17:32:42.729962 22622 net.cpp:131] Top shape: 1 128 8 8 (8192)
I0416 17:32:42.729964 22622 net.cpp:139] Memory required for data: 3997696
I0416 17:32:42.729966 22622 layer_factory.hpp:77] Creating layer conv4
I0416 17:32:42.729972 22622 net.cpp:86] Creating Layer conv4
I0416 17:32:42.729974 22622 net.cpp:408] conv4 <- pool3
I0416 17:32:42.729977 22622 net.cpp:382] conv4 -> conv4
I0416 17:32:42.732913 22622 net.cpp:124] Setting up conv4
I0416 17:32:42.732923 22622 net.cpp:131] Top shape: 1 128 8 8 (8192)
I0416 17:32:42.732925 22622 net.cpp:139] Memory required for data: 4030464
I0416 17:32:42.732929 22622 layer_factory.hpp:77] Creating layer conv4_bn
I0416 17:32:42.732933 22622 net.cpp:86] Creating Layer conv4_bn
I0416 17:32:42.732936 22622 net.cpp:408] conv4_bn <- conv4
I0416 17:32:42.732939 22622 net.cpp:369] conv4_bn -> conv4 (in-place)
I0416 17:32:42.733094 22622 net.cpp:124] Setting up conv4_bn
I0416 17:32:42.733098 22622 net.cpp:131] Top shape: 1 128 8 8 (8192)
I0416 17:32:42.733100 22622 net.cpp:139] Memory required for data: 4063232
I0416 17:32:42.733105 22622 layer_factory.hpp:77] Creating layer conv4_bn_scale
I0416 17:32:42.733108 22622 net.cpp:86] Creating Layer conv4_bn_scale
I0416 17:32:42.733111 22622 net.cpp:408] conv4_bn_scale <- conv4
I0416 17:32:42.733114 22622 net.cpp:369] conv4_bn_scale -> conv4 (in-place)
I0416 17:32:42.733177 22622 net.cpp:124] Setting up conv4_bn_scale
I0416 17:32:42.733181 22622 net.cpp:131] Top shape: 1 128 8 8 (8192)
I0416 17:32:42.733184 22622 net.cpp:139] Memory required for data: 4096000
I0416 17:32:42.733187 22622 layer_factory.hpp:77] Creating layer conv4_relu
I0416 17:32:42.733191 22622 net.cpp:86] Creating Layer conv4_relu
I0416 17:32:42.733193 22622 net.cpp:408] conv4_relu <- conv4
I0416 17:32:42.733196 22622 net.cpp:369] conv4_relu -> conv4 (in-place)
I0416 17:32:42.733503 22622 net.cpp:124] Setting up conv4_relu
I0416 17:32:42.733511 22622 net.cpp:131] Top shape: 1 128 8 8 (8192)
I0416 17:32:42.733513 22622 net.cpp:139] Memory required for data: 4128768
I0416 17:32:42.733516 22622 layer_factory.hpp:77] Creating layer pool4
I0416 17:32:42.733525 22622 net.cpp:86] Creating Layer pool4
I0416 17:32:42.733527 22622 net.cpp:408] pool4 <- conv4
I0416 17:32:42.733531 22622 net.cpp:382] pool4 -> pool4
I0416 17:32:42.733561 22622 net.cpp:124] Setting up pool4
I0416 17:32:42.733566 22622 net.cpp:131] Top shape: 1 128 4 4 (2048)
I0416 17:32:42.733567 22622 net.cpp:139] Memory required for data: 4136960
I0416 17:32:42.733569 22622 layer_factory.hpp:77] Creating layer conv5
I0416 17:32:42.733574 22622 net.cpp:86] Creating Layer conv5
I0416 17:32:42.733577 22622 net.cpp:408] conv5 <- pool4
I0416 17:32:42.733580 22622 net.cpp:382] conv5 -> conv5
I0416 17:32:42.737843 22622 net.cpp:124] Setting up conv5
I0416 17:32:42.737857 22622 net.cpp:131] Top shape: 1 128 4 4 (2048)
I0416 17:32:42.737860 22622 net.cpp:139] Memory required for data: 4145152
I0416 17:32:42.737865 22622 layer_factory.hpp:77] Creating layer conv5_bn
I0416 17:32:42.737870 22622 net.cpp:86] Creating Layer conv5_bn
I0416 17:32:42.737874 22622 net.cpp:408] conv5_bn <- conv5
I0416 17:32:42.737877 22622 net.cpp:369] conv5_bn -> conv5 (in-place)
I0416 17:32:42.738008 22622 net.cpp:124] Setting up conv5_bn
I0416 17:32:42.738011 22622 net.cpp:131] Top shape: 1 128 4 4 (2048)
I0416 17:32:42.738013 22622 net.cpp:139] Memory required for data: 4153344
I0416 17:32:42.738018 22622 layer_factory.hpp:77] Creating layer conv5_bn_scale
I0416 17:32:42.738023 22622 net.cpp:86] Creating Layer conv5_bn_scale
I0416 17:32:42.738025 22622 net.cpp:408] conv5_bn_scale <- conv5
I0416 17:32:42.738027 22622 net.cpp:369] conv5_bn_scale -> conv5 (in-place)
I0416 17:32:42.738080 22622 net.cpp:124] Setting up conv5_bn_scale
I0416 17:32:42.738085 22622 net.cpp:131] Top shape: 1 128 4 4 (2048)
I0416 17:32:42.738086 22622 net.cpp:139] Memory required for data: 4161536
I0416 17:32:42.738090 22622 layer_factory.hpp:77] Creating layer conv5_relu
I0416 17:32:42.738093 22622 net.cpp:86] Creating Layer conv5_relu
I0416 17:32:42.738095 22622 net.cpp:408] conv5_relu <- conv5
I0416 17:32:42.738098 22622 net.cpp:369] conv5_relu -> conv5 (in-place)
I0416 17:32:42.738410 22622 net.cpp:124] Setting up conv5_relu
I0416 17:32:42.738418 22622 net.cpp:131] Top shape: 1 128 4 4 (2048)
I0416 17:32:42.738420 22622 net.cpp:139] Memory required for data: 4169728
I0416 17:32:42.738423 22622 layer_factory.hpp:77] Creating layer pool5
I0416 17:32:42.738427 22622 net.cpp:86] Creating Layer pool5
I0416 17:32:42.738430 22622 net.cpp:408] pool5 <- conv5
I0416 17:32:42.738433 22622 net.cpp:382] pool5 -> pool5
I0416 17:32:42.738795 22622 net.cpp:124] Setting up pool5
I0416 17:32:42.738803 22622 net.cpp:131] Top shape: 1 128 1 1 (128)
I0416 17:32:42.738806 22622 net.cpp:139] Memory required for data: 4170240
I0416 17:32:42.738807 22622 layer_factory.hpp:77] Creating layer ft
I0416 17:32:42.738812 22622 net.cpp:86] Creating Layer ft
I0416 17:32:42.738816 22622 net.cpp:408] ft <- pool5
I0416 17:32:42.738818 22622 net.cpp:382] ft -> ft
I0416 17:32:42.739089 22622 net.cpp:124] Setting up ft
I0416 17:32:42.739094 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.739096 22622 net.cpp:139] Memory required for data: 4170752
I0416 17:32:42.739100 22622 layer_factory.hpp:77] Creating layer ft_bn
I0416 17:32:42.739104 22622 net.cpp:86] Creating Layer ft_bn
I0416 17:32:42.739107 22622 net.cpp:408] ft_bn <- ft
I0416 17:32:42.739111 22622 net.cpp:369] ft_bn -> ft (in-place)
I0416 17:32:42.739230 22622 net.cpp:124] Setting up ft_bn
I0416 17:32:42.739234 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.739236 22622 net.cpp:139] Memory required for data: 4171264
I0416 17:32:42.739243 22622 layer_factory.hpp:77] Creating layer ft_bn_scale
I0416 17:32:42.739248 22622 net.cpp:86] Creating Layer ft_bn_scale
I0416 17:32:42.739249 22622 net.cpp:408] ft_bn_scale <- ft
I0416 17:32:42.739253 22622 net.cpp:369] ft_bn_scale -> ft (in-place)
I0416 17:32:42.739305 22622 net.cpp:124] Setting up ft_bn_scale
I0416 17:32:42.739308 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.739311 22622 net.cpp:139] Memory required for data: 4171776
I0416 17:32:42.739318 22622 layer_factory.hpp:77] Creating layer ft_relu
I0416 17:32:42.739322 22622 net.cpp:86] Creating Layer ft_relu
I0416 17:32:42.739325 22622 net.cpp:408] ft_relu <- ft
I0416 17:32:42.739327 22622 net.cpp:369] ft_relu -> ft (in-place)
I0416 17:32:42.739641 22622 net.cpp:124] Setting up ft_relu
I0416 17:32:42.739648 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.739650 22622 net.cpp:139] Memory required for data: 4172288
I0416 17:32:42.739653 22622 layer_factory.hpp:77] Creating layer logits
I0416 17:32:42.739657 22622 net.cpp:86] Creating Layer logits
I0416 17:32:42.739660 22622 net.cpp:408] logits <- ft
I0416 17:32:42.739663 22622 net.cpp:382] logits -> logits
I0416 17:32:42.739730 22622 net.cpp:124] Setting up logits
I0416 17:32:42.739734 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.739737 22622 net.cpp:139] Memory required for data: 4172304
I0416 17:32:42.739739 22622 layer_factory.hpp:77] Creating layer prob
I0416 17:32:42.739744 22622 net.cpp:86] Creating Layer prob
I0416 17:32:42.739748 22622 net.cpp:408] prob <- logits
I0416 17:32:42.739750 22622 net.cpp:382] prob -> prob
I0416 17:32:42.740003 22622 net.cpp:124] Setting up prob
I0416 17:32:42.740010 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.740011 22622 net.cpp:139] Memory required for data: 4172320
I0416 17:32:42.740015 22622 net.cpp:202] prob does not need backward computation.
I0416 17:32:42.740016 22622 net.cpp:202] logits does not need backward computation.
I0416 17:32:42.740020 22622 net.cpp:202] ft_relu does not need backward computation.
I0416 17:32:42.740021 22622 net.cpp:202] ft_bn_scale does not need backward computation.
I0416 17:32:42.740023 22622 net.cpp:202] ft_bn does not need backward computation.
I0416 17:32:42.740025 22622 net.cpp:202] ft does not need backward computation.
I0416 17:32:42.740027 22622 net.cpp:202] pool5 does not need backward computation.
I0416 17:32:42.740031 22622 net.cpp:202] conv5_relu does not need backward computation.
I0416 17:32:42.740032 22622 net.cpp:202] conv5_bn_scale does not need backward computation.
I0416 17:32:42.740034 22622 net.cpp:202] conv5_bn does not need backward computation.
I0416 17:32:42.740036 22622 net.cpp:202] conv5 does not need backward computation.
I0416 17:32:42.740039 22622 net.cpp:202] pool4 does not need backward computation.
I0416 17:32:42.740041 22622 net.cpp:202] conv4_relu does not need backward computation.
I0416 17:32:42.740043 22622 net.cpp:202] conv4_bn_scale does not need backward computation.
I0416 17:32:42.740046 22622 net.cpp:202] conv4_bn does not need backward computation.
I0416 17:32:42.740048 22622 net.cpp:202] conv4 does not need backward computation.
I0416 17:32:42.740051 22622 net.cpp:202] pool3 does not need backward computation.
I0416 17:32:42.740053 22622 net.cpp:202] conv3_relu does not need backward computation.
I0416 17:32:42.740056 22622 net.cpp:202] conv3_bn_scale does not need backward computation.
I0416 17:32:42.740057 22622 net.cpp:202] conv3_bn does not need backward computation.
I0416 17:32:42.740061 22622 net.cpp:202] conv3 does not need backward computation.
I0416 17:32:42.740062 22622 net.cpp:202] pool2 does not need backward computation.
I0416 17:32:42.740064 22622 net.cpp:202] conv2_relu does not need backward computation.
I0416 17:32:42.740067 22622 net.cpp:202] conv2_bn_scale does not need backward computation.
I0416 17:32:42.740069 22622 net.cpp:202] conv2_bn does not need backward computation.
I0416 17:32:42.740072 22622 net.cpp:202] conv2 does not need backward computation.
I0416 17:32:42.740074 22622 net.cpp:202] pool1 does not need backward computation.
I0416 17:32:42.740077 22622 net.cpp:202] conv1_relu does not need backward computation.
I0416 17:32:42.740079 22622 net.cpp:202] conv1_bn_scale does not need backward computation.
I0416 17:32:42.740082 22622 net.cpp:202] conv1_bn does not need backward computation.
I0416 17:32:42.740083 22622 net.cpp:202] conv1 does not need backward computation.
I0416 17:32:42.740087 22622 net.cpp:202] permute does not need backward computation.
I0416 17:32:42.740092 22622 net.cpp:202] input does not need backward computation.
I0416 17:32:42.740094 22622 net.cpp:244] This network produces output prob
I0416 17:32:42.740106 22622 net.cpp:257] Network initialization done.
I0416 17:32:42.740567 22622 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/quadrate/baidu_iter_200000.caffemodel
I0416 17:32:42.740572 22622 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0416 17:32:42.740576 22622 net.cpp:746] Ignoring source layer traffic_light
I0416 17:32:42.740577 22622 net.cpp:746] Ignoring source layer distort
I0416 17:32:42.740725 22622 net.cpp:746] Ignoring source layer ft_drop
I0416 17:32:42.740728 22622 net.cpp:746] Ignoring source layer softmaxloss
I0416 17:32:42.740837 22622 classify.cc:105] []Init Done
I0416 17:32:42.740842 22622 classify.cc:34] []Enter Classify init
I0416 17:32:42.740844 22622 classify.cc:37] []clear success
I0416 17:32:42.740847 22622 classify.cc:41] []1
I0416 17:32:42.740849 22622 classify.cc:42] []1
I0416 17:32:42.740851 22622 classify.cc:45] []net input blobs: data_org
I0416 17:32:42.740854 22622 classify.cc:48] []net output blobs: prob
I0416 17:32:42.740856 22622 classify.cc:56] []proto_file /apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/vertical/deploy.prototxt
I0416 17:32:42.740859 22622 classify.cc:61] []model_root/apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/./
I0416 17:32:42.740862 22622 classify.cc:66] []create success
I0416 17:32:42.740866 22622 classify.cc:94] []input_reshape: 1, 96, 32, 3
I0416 17:32:42.740995 22622 common.cpp:178] Device id:                     0
I0416 17:32:42.740999 22622 common.cpp:179] Major revision number:         6
I0416 17:32:42.741001 22622 common.cpp:180] Minor revision number:         1
I0416 17:32:42.741003 22622 common.cpp:181] Name:                          GeForce GTX 1070 Ti
I0416 17:32:42.741005 22622 common.cpp:182] Total global memory:           8510701568
I0416 17:32:42.741008 22622 common.cpp:183] Total shared memory per block: 49152
I0416 17:32:42.741009 22622 common.cpp:184] Total registers per block:     65536
I0416 17:32:42.741011 22622 common.cpp:185] Warp size:                     32
I0416 17:32:42.741014 22622 common.cpp:186] Maximum memory pitch:          2147483647
I0416 17:32:42.741015 22622 common.cpp:187] Maximum threads per block:     1024
I0416 17:32:42.741017 22622 common.cpp:188] Maximum dimension of block:    1024, 1024, 64
I0416 17:32:42.741019 22622 common.cpp:191] Maximum dimension of grid:     2147483647, 65535, 65535
I0416 17:32:42.741022 22622 common.cpp:194] Clock rate:                    1683000
I0416 17:32:42.741024 22622 common.cpp:195] Total constant memory:         65536
I0416 17:32:42.741026 22622 common.cpp:196] Texture alignment:             512
I0416 17:32:42.741029 22622 common.cpp:197] Concurrent copy and execution: Yes
I0416 17:32:42.741030 22622 common.cpp:199] Number of multiprocessors:     19
I0416 17:32:42.741032 22622 common.cpp:200] Kernel execution timeout:      Yes
I0416 17:32:42.741537 22622 net.cpp:53] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data_org"
  input_param {
    shape {
      dim: 1
      dim: 96
      dim: 32
      dim: 3
    }
  }
}
layer {
  name: "permute"
  type: "Permute"
  bottom: "data_org"
  top: "data"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1_bn_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_bn_scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv2_relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv3_bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_bn_scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv3_relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_bn_scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv4_relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_bn_scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv5_relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_h: 6
    kernel_w: 2
    stride_h: 6
    stride_w: 2
    round_mode: FLOOR
  }
}
layer {
  name: "ft"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ft"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ft_bn"
  type: "BatchNorm"
  bottom: "ft"
  top: "ft"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "ft_bn_scale"
  type: "Scale"
  bottom: "ft"
  top: "ft"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "ft_relu"
  type: "ReLU"
  bottom: "ft"
  top: "ft"
}
layer {
  name: "logits"
  type: "InnerProduct"
  bottom: "ft"
  top: "logits"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "logits"
  top: "prob"
}
I0416 17:32:42.741593 22622 layer_factory.hpp:77] Creating layer input
I0416 17:32:42.741598 22622 net.cpp:86] Creating Layer input
I0416 17:32:42.741601 22622 net.cpp:382] input -> data_org
I0416 17:32:42.741632 22622 net.cpp:124] Setting up input
I0416 17:32:42.741637 22622 net.cpp:131] Top shape: 1 96 32 3 (9216)
I0416 17:32:42.741639 22622 net.cpp:139] Memory required for data: 36864
I0416 17:32:42.741642 22622 layer_factory.hpp:77] Creating layer permute
I0416 17:32:42.741645 22622 net.cpp:86] Creating Layer permute
I0416 17:32:42.741648 22622 net.cpp:408] permute <- data_org
I0416 17:32:42.741652 22622 net.cpp:382] permute -> data
I0416 17:32:42.741708 22622 net.cpp:124] Setting up permute
I0416 17:32:42.741711 22622 net.cpp:131] Top shape: 1 3 96 32 (9216)
I0416 17:32:42.741714 22622 net.cpp:139] Memory required for data: 73728
I0416 17:32:42.741715 22622 layer_factory.hpp:77] Creating layer conv1
I0416 17:32:42.741720 22622 net.cpp:86] Creating Layer conv1
I0416 17:32:42.741724 22622 net.cpp:408] conv1 <- data
I0416 17:32:42.741726 22622 net.cpp:382] conv1 -> conv1
I0416 17:32:42.742889 22622 net.cpp:124] Setting up conv1
I0416 17:32:42.742898 22622 net.cpp:131] Top shape: 1 32 96 32 (98304)
I0416 17:32:42.742900 22622 net.cpp:139] Memory required for data: 466944
I0416 17:32:42.742907 22622 layer_factory.hpp:77] Creating layer conv1_bn
I0416 17:32:42.742910 22622 net.cpp:86] Creating Layer conv1_bn
I0416 17:32:42.742913 22622 net.cpp:408] conv1_bn <- conv1
I0416 17:32:42.742915 22622 net.cpp:369] conv1_bn -> conv1 (in-place)
I0416 17:32:42.743032 22622 net.cpp:124] Setting up conv1_bn
I0416 17:32:42.743037 22622 net.cpp:131] Top shape: 1 32 96 32 (98304)
I0416 17:32:42.743039 22622 net.cpp:139] Memory required for data: 860160
I0416 17:32:42.743044 22622 layer_factory.hpp:77] Creating layer conv1_bn_scale
I0416 17:32:42.743048 22622 net.cpp:86] Creating Layer conv1_bn_scale
I0416 17:32:42.743052 22622 net.cpp:408] conv1_bn_scale <- conv1
I0416 17:32:42.743053 22622 net.cpp:369] conv1_bn_scale -> conv1 (in-place)
I0416 17:32:42.743113 22622 net.cpp:124] Setting up conv1_bn_scale
I0416 17:32:42.743119 22622 net.cpp:131] Top shape: 1 32 96 32 (98304)
I0416 17:32:42.743121 22622 net.cpp:139] Memory required for data: 1253376
I0416 17:32:42.743124 22622 layer_factory.hpp:77] Creating layer conv1_relu
I0416 17:32:42.743127 22622 net.cpp:86] Creating Layer conv1_relu
I0416 17:32:42.743129 22622 net.cpp:408] conv1_relu <- conv1
I0416 17:32:42.743132 22622 net.cpp:369] conv1_relu -> conv1 (in-place)
I0416 17:32:42.743360 22622 net.cpp:124] Setting up conv1_relu
I0416 17:32:42.743366 22622 net.cpp:131] Top shape: 1 32 96 32 (98304)
I0416 17:32:42.743367 22622 net.cpp:139] Memory required for data: 1646592
I0416 17:32:42.743372 22622 layer_factory.hpp:77] Creating layer pool1
I0416 17:32:42.743376 22622 net.cpp:86] Creating Layer pool1
I0416 17:32:42.743379 22622 net.cpp:408] pool1 <- conv1
I0416 17:32:42.743382 22622 net.cpp:382] pool1 -> pool1
I0416 17:32:42.743404 22622 net.cpp:124] Setting up pool1
I0416 17:32:42.743407 22622 net.cpp:131] Top shape: 1 32 48 16 (24576)
I0416 17:32:42.743409 22622 net.cpp:139] Memory required for data: 1744896
I0416 17:32:42.743412 22622 layer_factory.hpp:77] Creating layer conv2
I0416 17:32:42.743417 22622 net.cpp:86] Creating Layer conv2
I0416 17:32:42.743418 22622 net.cpp:408] conv2 <- pool1
I0416 17:32:42.743422 22622 net.cpp:382] conv2 -> conv2
I0416 17:32:42.745677 22622 net.cpp:124] Setting up conv2
I0416 17:32:42.745692 22622 net.cpp:131] Top shape: 1 64 48 16 (49152)
I0416 17:32:42.745694 22622 net.cpp:139] Memory required for data: 1941504
I0416 17:32:42.745698 22622 layer_factory.hpp:77] Creating layer conv2_bn
I0416 17:32:42.745704 22622 net.cpp:86] Creating Layer conv2_bn
I0416 17:32:42.745707 22622 net.cpp:408] conv2_bn <- conv2
I0416 17:32:42.745710 22622 net.cpp:369] conv2_bn -> conv2 (in-place)
I0416 17:32:42.745821 22622 net.cpp:124] Setting up conv2_bn
I0416 17:32:42.745826 22622 net.cpp:131] Top shape: 1 64 48 16 (49152)
I0416 17:32:42.745827 22622 net.cpp:139] Memory required for data: 2138112
I0416 17:32:42.745833 22622 layer_factory.hpp:77] Creating layer conv2_bn_scale
I0416 17:32:42.745837 22622 net.cpp:86] Creating Layer conv2_bn_scale
I0416 17:32:42.745841 22622 net.cpp:408] conv2_bn_scale <- conv2
I0416 17:32:42.745842 22622 net.cpp:369] conv2_bn_scale -> conv2 (in-place)
I0416 17:32:42.745895 22622 net.cpp:124] Setting up conv2_bn_scale
I0416 17:32:42.745899 22622 net.cpp:131] Top shape: 1 64 48 16 (49152)
I0416 17:32:42.745901 22622 net.cpp:139] Memory required for data: 2334720
I0416 17:32:42.745904 22622 layer_factory.hpp:77] Creating layer conv2_relu
I0416 17:32:42.745908 22622 net.cpp:86] Creating Layer conv2_relu
I0416 17:32:42.745910 22622 net.cpp:408] conv2_relu <- conv2
I0416 17:32:42.745913 22622 net.cpp:369] conv2_relu -> conv2 (in-place)
I0416 17:32:42.746225 22622 net.cpp:124] Setting up conv2_relu
I0416 17:32:42.746233 22622 net.cpp:131] Top shape: 1 64 48 16 (49152)
I0416 17:32:42.746235 22622 net.cpp:139] Memory required for data: 2531328
I0416 17:32:42.746237 22622 layer_factory.hpp:77] Creating layer pool2
I0416 17:32:42.746243 22622 net.cpp:86] Creating Layer pool2
I0416 17:32:42.746244 22622 net.cpp:408] pool2 <- conv2
I0416 17:32:42.746248 22622 net.cpp:382] pool2 -> pool2
I0416 17:32:42.746273 22622 net.cpp:124] Setting up pool2
I0416 17:32:42.746276 22622 net.cpp:131] Top shape: 1 64 24 8 (12288)
I0416 17:32:42.746279 22622 net.cpp:139] Memory required for data: 2580480
I0416 17:32:42.746280 22622 layer_factory.hpp:77] Creating layer conv3
I0416 17:32:42.746286 22622 net.cpp:86] Creating Layer conv3
I0416 17:32:42.746289 22622 net.cpp:408] conv3 <- pool2
I0416 17:32:42.746292 22622 net.cpp:382] conv3 -> conv3
I0416 17:32:42.748293 22622 net.cpp:124] Setting up conv3
I0416 17:32:42.748302 22622 net.cpp:131] Top shape: 1 128 24 8 (24576)
I0416 17:32:42.748304 22622 net.cpp:139] Memory required for data: 2678784
I0416 17:32:42.748309 22622 layer_factory.hpp:77] Creating layer conv3_bn
I0416 17:32:42.748313 22622 net.cpp:86] Creating Layer conv3_bn
I0416 17:32:42.748317 22622 net.cpp:408] conv3_bn <- conv3
I0416 17:32:42.748319 22622 net.cpp:369] conv3_bn -> conv3 (in-place)
I0416 17:32:42.748432 22622 net.cpp:124] Setting up conv3_bn
I0416 17:32:42.748436 22622 net.cpp:131] Top shape: 1 128 24 8 (24576)
I0416 17:32:42.748440 22622 net.cpp:139] Memory required for data: 2777088
I0416 17:32:42.748445 22622 layer_factory.hpp:77] Creating layer conv3_bn_scale
I0416 17:32:42.748448 22622 net.cpp:86] Creating Layer conv3_bn_scale
I0416 17:32:42.748450 22622 net.cpp:408] conv3_bn_scale <- conv3
I0416 17:32:42.748453 22622 net.cpp:369] conv3_bn_scale -> conv3 (in-place)
I0416 17:32:42.748497 22622 net.cpp:124] Setting up conv3_bn_scale
I0416 17:32:42.748505 22622 net.cpp:131] Top shape: 1 128 24 8 (24576)
I0416 17:32:42.748507 22622 net.cpp:139] Memory required for data: 2875392
I0416 17:32:42.748510 22622 layer_factory.hpp:77] Creating layer conv3_relu
I0416 17:32:42.748513 22622 net.cpp:86] Creating Layer conv3_relu
I0416 17:32:42.748517 22622 net.cpp:408] conv3_relu <- conv3
I0416 17:32:42.748518 22622 net.cpp:369] conv3_relu -> conv3 (in-place)
I0416 17:32:42.748832 22622 net.cpp:124] Setting up conv3_relu
I0416 17:32:42.748841 22622 net.cpp:131] Top shape: 1 128 24 8 (24576)
I0416 17:32:42.748842 22622 net.cpp:139] Memory required for data: 2973696
I0416 17:32:42.748844 22622 layer_factory.hpp:77] Creating layer pool3
I0416 17:32:42.748849 22622 net.cpp:86] Creating Layer pool3
I0416 17:32:42.748852 22622 net.cpp:408] pool3 <- conv3
I0416 17:32:42.748855 22622 net.cpp:382] pool3 -> pool3
I0416 17:32:42.748878 22622 net.cpp:124] Setting up pool3
I0416 17:32:42.748881 22622 net.cpp:131] Top shape: 1 128 12 4 (6144)
I0416 17:32:42.748883 22622 net.cpp:139] Memory required for data: 2998272
I0416 17:32:42.748886 22622 layer_factory.hpp:77] Creating layer conv4
I0416 17:32:42.748890 22622 net.cpp:86] Creating Layer conv4
I0416 17:32:42.748893 22622 net.cpp:408] conv4 <- pool3
I0416 17:32:42.748896 22622 net.cpp:382] conv4 -> conv4
I0416 17:32:42.751785 22622 net.cpp:124] Setting up conv4
I0416 17:32:42.751794 22622 net.cpp:131] Top shape: 1 128 12 4 (6144)
I0416 17:32:42.751796 22622 net.cpp:139] Memory required for data: 3022848
I0416 17:32:42.751801 22622 layer_factory.hpp:77] Creating layer conv4_bn
I0416 17:32:42.751804 22622 net.cpp:86] Creating Layer conv4_bn
I0416 17:32:42.751807 22622 net.cpp:408] conv4_bn <- conv4
I0416 17:32:42.751811 22622 net.cpp:369] conv4_bn -> conv4 (in-place)
I0416 17:32:42.751914 22622 net.cpp:124] Setting up conv4_bn
I0416 17:32:42.751919 22622 net.cpp:131] Top shape: 1 128 12 4 (6144)
I0416 17:32:42.751921 22622 net.cpp:139] Memory required for data: 3047424
I0416 17:32:42.751925 22622 layer_factory.hpp:77] Creating layer conv4_bn_scale
I0416 17:32:42.751929 22622 net.cpp:86] Creating Layer conv4_bn_scale
I0416 17:32:42.751930 22622 net.cpp:408] conv4_bn_scale <- conv4
I0416 17:32:42.751933 22622 net.cpp:369] conv4_bn_scale -> conv4 (in-place)
I0416 17:32:42.751976 22622 net.cpp:124] Setting up conv4_bn_scale
I0416 17:32:42.751981 22622 net.cpp:131] Top shape: 1 128 12 4 (6144)
I0416 17:32:42.751982 22622 net.cpp:139] Memory required for data: 3072000
I0416 17:32:42.751986 22622 layer_factory.hpp:77] Creating layer conv4_relu
I0416 17:32:42.751988 22622 net.cpp:86] Creating Layer conv4_relu
I0416 17:32:42.751991 22622 net.cpp:408] conv4_relu <- conv4
I0416 17:32:42.751993 22622 net.cpp:369] conv4_relu -> conv4 (in-place)
I0416 17:32:42.753341 22622 net.cpp:124] Setting up conv4_relu
I0416 17:32:42.753355 22622 net.cpp:131] Top shape: 1 128 12 4 (6144)
I0416 17:32:42.753356 22622 net.cpp:139] Memory required for data: 3096576
I0416 17:32:42.753360 22622 layer_factory.hpp:77] Creating layer pool4
I0416 17:32:42.753365 22622 net.cpp:86] Creating Layer pool4
I0416 17:32:42.753368 22622 net.cpp:408] pool4 <- conv4
I0416 17:32:42.753372 22622 net.cpp:382] pool4 -> pool4
I0416 17:32:42.753402 22622 net.cpp:124] Setting up pool4
I0416 17:32:42.753407 22622 net.cpp:131] Top shape: 1 128 6 2 (1536)
I0416 17:32:42.753408 22622 net.cpp:139] Memory required for data: 3102720
I0416 17:32:42.753410 22622 layer_factory.hpp:77] Creating layer conv5
I0416 17:32:42.753417 22622 net.cpp:86] Creating Layer conv5
I0416 17:32:42.753419 22622 net.cpp:408] conv5 <- pool4
I0416 17:32:42.753422 22622 net.cpp:382] conv5 -> conv5
I0416 17:32:42.756366 22622 net.cpp:124] Setting up conv5
I0416 17:32:42.756376 22622 net.cpp:131] Top shape: 1 128 6 2 (1536)
I0416 17:32:42.756377 22622 net.cpp:139] Memory required for data: 3108864
I0416 17:32:42.756382 22622 layer_factory.hpp:77] Creating layer conv5_bn
I0416 17:32:42.756386 22622 net.cpp:86] Creating Layer conv5_bn
I0416 17:32:42.756388 22622 net.cpp:408] conv5_bn <- conv5
I0416 17:32:42.756397 22622 net.cpp:369] conv5_bn -> conv5 (in-place)
I0416 17:32:42.756507 22622 net.cpp:124] Setting up conv5_bn
I0416 17:32:42.756512 22622 net.cpp:131] Top shape: 1 128 6 2 (1536)
I0416 17:32:42.756515 22622 net.cpp:139] Memory required for data: 3115008
I0416 17:32:42.756518 22622 layer_factory.hpp:77] Creating layer conv5_bn_scale
I0416 17:32:42.756523 22622 net.cpp:86] Creating Layer conv5_bn_scale
I0416 17:32:42.756525 22622 net.cpp:408] conv5_bn_scale <- conv5
I0416 17:32:42.756528 22622 net.cpp:369] conv5_bn_scale -> conv5 (in-place)
I0416 17:32:42.756574 22622 net.cpp:124] Setting up conv5_bn_scale
I0416 17:32:42.756578 22622 net.cpp:131] Top shape: 1 128 6 2 (1536)
I0416 17:32:42.756580 22622 net.cpp:139] Memory required for data: 3121152
I0416 17:32:42.756583 22622 layer_factory.hpp:77] Creating layer conv5_relu
I0416 17:32:42.756587 22622 net.cpp:86] Creating Layer conv5_relu
I0416 17:32:42.756589 22622 net.cpp:408] conv5_relu <- conv5
I0416 17:32:42.756592 22622 net.cpp:369] conv5_relu -> conv5 (in-place)
I0416 17:32:42.756906 22622 net.cpp:124] Setting up conv5_relu
I0416 17:32:42.756913 22622 net.cpp:131] Top shape: 1 128 6 2 (1536)
I0416 17:32:42.756916 22622 net.cpp:139] Memory required for data: 3127296
I0416 17:32:42.756917 22622 layer_factory.hpp:77] Creating layer pool5
I0416 17:32:42.756922 22622 net.cpp:86] Creating Layer pool5
I0416 17:32:42.756924 22622 net.cpp:408] pool5 <- conv5
I0416 17:32:42.756927 22622 net.cpp:382] pool5 -> pool5
I0416 17:32:42.757251 22622 net.cpp:124] Setting up pool5
I0416 17:32:42.757259 22622 net.cpp:131] Top shape: 1 128 1 1 (128)
I0416 17:32:42.757261 22622 net.cpp:139] Memory required for data: 3127808
I0416 17:32:42.757263 22622 layer_factory.hpp:77] Creating layer ft
I0416 17:32:42.757268 22622 net.cpp:86] Creating Layer ft
I0416 17:32:42.757272 22622 net.cpp:408] ft <- pool5
I0416 17:32:42.757274 22622 net.cpp:382] ft -> ft
I0416 17:32:42.757535 22622 net.cpp:124] Setting up ft
I0416 17:32:42.757539 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.757541 22622 net.cpp:139] Memory required for data: 3128320
I0416 17:32:42.757545 22622 layer_factory.hpp:77] Creating layer ft_bn
I0416 17:32:42.757548 22622 net.cpp:86] Creating Layer ft_bn
I0416 17:32:42.757550 22622 net.cpp:408] ft_bn <- ft
I0416 17:32:42.757553 22622 net.cpp:369] ft_bn -> ft (in-place)
I0416 17:32:42.757650 22622 net.cpp:124] Setting up ft_bn
I0416 17:32:42.757654 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.757656 22622 net.cpp:139] Memory required for data: 3128832
I0416 17:32:42.757663 22622 layer_factory.hpp:77] Creating layer ft_bn_scale
I0416 17:32:42.757668 22622 net.cpp:86] Creating Layer ft_bn_scale
I0416 17:32:42.757670 22622 net.cpp:408] ft_bn_scale <- ft
I0416 17:32:42.757673 22622 net.cpp:369] ft_bn_scale -> ft (in-place)
I0416 17:32:42.757716 22622 net.cpp:124] Setting up ft_bn_scale
I0416 17:32:42.757719 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.757721 22622 net.cpp:139] Memory required for data: 3129344
I0416 17:32:42.757725 22622 layer_factory.hpp:77] Creating layer ft_relu
I0416 17:32:42.757728 22622 net.cpp:86] Creating Layer ft_relu
I0416 17:32:42.757730 22622 net.cpp:408] ft_relu <- ft
I0416 17:32:42.757733 22622 net.cpp:369] ft_relu -> ft (in-place)
I0416 17:32:42.758046 22622 net.cpp:124] Setting up ft_relu
I0416 17:32:42.758054 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.758056 22622 net.cpp:139] Memory required for data: 3129856
I0416 17:32:42.758059 22622 layer_factory.hpp:77] Creating layer logits
I0416 17:32:42.758065 22622 net.cpp:86] Creating Layer logits
I0416 17:32:42.758067 22622 net.cpp:408] logits <- ft
I0416 17:32:42.758071 22622 net.cpp:382] logits -> logits
I0416 17:32:42.758133 22622 net.cpp:124] Setting up logits
I0416 17:32:42.758137 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.758139 22622 net.cpp:139] Memory required for data: 3129872
I0416 17:32:42.758143 22622 layer_factory.hpp:77] Creating layer prob
I0416 17:32:42.758149 22622 net.cpp:86] Creating Layer prob
I0416 17:32:42.758155 22622 net.cpp:408] prob <- logits
I0416 17:32:42.758158 22622 net.cpp:382] prob -> prob
I0416 17:32:42.758411 22622 net.cpp:124] Setting up prob
I0416 17:32:42.758417 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.758419 22622 net.cpp:139] Memory required for data: 3129888
I0416 17:32:42.758422 22622 net.cpp:202] prob does not need backward computation.
I0416 17:32:42.758424 22622 net.cpp:202] logits does not need backward computation.
I0416 17:32:42.758427 22622 net.cpp:202] ft_relu does not need backward computation.
I0416 17:32:42.758430 22622 net.cpp:202] ft_bn_scale does not need backward computation.
I0416 17:32:42.758431 22622 net.cpp:202] ft_bn does not need backward computation.
I0416 17:32:42.758435 22622 net.cpp:202] ft does not need backward computation.
I0416 17:32:42.758436 22622 net.cpp:202] pool5 does not need backward computation.
I0416 17:32:42.758438 22622 net.cpp:202] conv5_relu does not need backward computation.
I0416 17:32:42.758440 22622 net.cpp:202] conv5_bn_scale does not need backward computation.
I0416 17:32:42.758443 22622 net.cpp:202] conv5_bn does not need backward computation.
I0416 17:32:42.758445 22622 net.cpp:202] conv5 does not need backward computation.
I0416 17:32:42.758447 22622 net.cpp:202] pool4 does not need backward computation.
I0416 17:32:42.758450 22622 net.cpp:202] conv4_relu does not need backward computation.
I0416 17:32:42.758452 22622 net.cpp:202] conv4_bn_scale does not need backward computation.
I0416 17:32:42.758455 22622 net.cpp:202] conv4_bn does not need backward computation.
I0416 17:32:42.758456 22622 net.cpp:202] conv4 does not need backward computation.
I0416 17:32:42.758460 22622 net.cpp:202] pool3 does not need backward computation.
I0416 17:32:42.758461 22622 net.cpp:202] conv3_relu does not need backward computation.
I0416 17:32:42.758463 22622 net.cpp:202] conv3_bn_scale does not need backward computation.
I0416 17:32:42.758466 22622 net.cpp:202] conv3_bn does not need backward computation.
I0416 17:32:42.758468 22622 net.cpp:202] conv3 does not need backward computation.
I0416 17:32:42.758471 22622 net.cpp:202] pool2 does not need backward computation.
I0416 17:32:42.758473 22622 net.cpp:202] conv2_relu does not need backward computation.
I0416 17:32:42.758476 22622 net.cpp:202] conv2_bn_scale does not need backward computation.
I0416 17:32:42.758478 22622 net.cpp:202] conv2_bn does not need backward computation.
I0416 17:32:42.758481 22622 net.cpp:202] conv2 does not need backward computation.
I0416 17:32:42.758482 22622 net.cpp:202] pool1 does not need backward computation.
I0416 17:32:42.758486 22622 net.cpp:202] conv1_relu does not need backward computation.
I0416 17:32:42.758487 22622 net.cpp:202] conv1_bn_scale does not need backward computation.
I0416 17:32:42.758491 22622 net.cpp:202] conv1_bn does not need backward computation.
I0416 17:32:42.758492 22622 net.cpp:202] conv1 does not need backward computation.
I0416 17:32:42.758494 22622 net.cpp:202] permute does not need backward computation.
I0416 17:32:42.758497 22622 net.cpp:202] input does not need backward computation.
I0416 17:32:42.758499 22622 net.cpp:244] This network produces output prob
I0416 17:32:42.758509 22622 net.cpp:257] Network initialization done.
I0416 17:32:42.758947 22622 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/vertical/baidu_iter_250000.caffemodel
I0416 17:32:42.758952 22622 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0416 17:32:42.758955 22622 net.cpp:746] Ignoring source layer traffic_light
I0416 17:32:42.758957 22622 net.cpp:746] Ignoring source layer distort
I0416 17:32:42.759109 22622 net.cpp:746] Ignoring source layer ft_drop
I0416 17:32:42.759112 22622 net.cpp:746] Ignoring source layer softmaxloss
I0416 17:32:42.759210 22622 classify.cc:105] []Init Done
I0416 17:32:42.759215 22622 classify.cc:34] []Enter Classify init
I0416 17:32:42.759218 22622 classify.cc:37] []clear success
I0416 17:32:42.759224 22622 classify.cc:41] []1
I0416 17:32:42.759227 22622 classify.cc:42] []1
I0416 17:32:42.759229 22622 classify.cc:45] []net input blobs: data_org
I0416 17:32:42.759232 22622 classify.cc:48] []net output blobs: prob
I0416 17:32:42.759234 22622 classify.cc:56] []proto_file /apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/horizontal/deploy.prototxt
I0416 17:32:42.759238 22622 classify.cc:61] []model_root/apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/./
I0416 17:32:42.759240 22622 classify.cc:66] []create success
I0416 17:32:42.759243 22622 classify.cc:94] []input_reshape: 1, 32, 96, 3
I0416 17:32:42.759384 22622 common.cpp:178] Device id:                     0
I0416 17:32:42.759388 22622 common.cpp:179] Major revision number:         6
I0416 17:32:42.759390 22622 common.cpp:180] Minor revision number:         1
I0416 17:32:42.759392 22622 common.cpp:181] Name:                          GeForce GTX 1070 Ti
I0416 17:32:42.759394 22622 common.cpp:182] Total global memory:           8510701568
I0416 17:32:42.759397 22622 common.cpp:183] Total shared memory per block: 49152
I0416 17:32:42.759398 22622 common.cpp:184] Total registers per block:     65536
I0416 17:32:42.759400 22622 common.cpp:185] Warp size:                     32
I0416 17:32:42.759402 22622 common.cpp:186] Maximum memory pitch:          2147483647
I0416 17:32:42.759404 22622 common.cpp:187] Maximum threads per block:     1024
I0416 17:32:42.759407 22622 common.cpp:188] Maximum dimension of block:    1024, 1024, 64
I0416 17:32:42.759408 22622 common.cpp:191] Maximum dimension of grid:     2147483647, 65535, 65535
I0416 17:32:42.759410 22622 common.cpp:194] Clock rate:                    1683000
I0416 17:32:42.759413 22622 common.cpp:195] Total constant memory:         65536
I0416 17:32:42.759414 22622 common.cpp:196] Texture alignment:             512
I0416 17:32:42.759416 22622 common.cpp:197] Concurrent copy and execution: Yes
I0416 17:32:42.759418 22622 common.cpp:199] Number of multiprocessors:     19
I0416 17:32:42.759420 22622 common.cpp:200] Kernel execution timeout:      Yes
I0416 17:32:42.759922 22622 net.cpp:53] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data_org"
  input_param {
    shape {
      dim: 1
      dim: 32
      dim: 96
      dim: 3
    }
  }
}
layer {
  name: "permute"
  type: "Permute"
  bottom: "data_org"
  top: "data"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1_bn_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_bn_scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv2_relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv3_bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_bn_scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv3_relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_bn_scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv4_relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_bn_scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "conv5_relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_h: 2
    kernel_w: 6
    stride_h: 2
    stride_w: 6
    round_mode: FLOOR
  }
}
layer {
  name: "ft"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ft"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ft_bn"
  type: "BatchNorm"
  bottom: "ft"
  top: "ft"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "ft_bn_scale"
  type: "Scale"
  bottom: "ft"
  top: "ft"
  scale_param {
    axis: 1
    num_axes: 1
    bias_term: false
  }
}
layer {
  name: "ft_relu"
  type: "ReLU"
  bottom: "ft"
  top: "ft"
}
layer {
  name: "logits"
  type: "InnerProduct"
  bottom: "ft"
  top: "logits"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "logits"
  top: "prob"
}
I0416 17:32:42.759976 22622 layer_factory.hpp:77] Creating layer input
I0416 17:32:42.759981 22622 net.cpp:86] Creating Layer input
I0416 17:32:42.759984 22622 net.cpp:382] input -> data_org
I0416 17:32:42.760018 22622 net.cpp:124] Setting up input
I0416 17:32:42.760022 22622 net.cpp:131] Top shape: 1 32 96 3 (9216)
I0416 17:32:42.760025 22622 net.cpp:139] Memory required for data: 36864
I0416 17:32:42.760027 22622 layer_factory.hpp:77] Creating layer permute
I0416 17:32:42.760031 22622 net.cpp:86] Creating Layer permute
I0416 17:32:42.760035 22622 net.cpp:408] permute <- data_org
I0416 17:32:42.760037 22622 net.cpp:382] permute -> data
I0416 17:32:42.760094 22622 net.cpp:124] Setting up permute
I0416 17:32:42.760099 22622 net.cpp:131] Top shape: 1 3 32 96 (9216)
I0416 17:32:42.760102 22622 net.cpp:139] Memory required for data: 73728
I0416 17:32:42.760104 22622 layer_factory.hpp:77] Creating layer conv1
I0416 17:32:42.760110 22622 net.cpp:86] Creating Layer conv1
I0416 17:32:42.760139 22622 net.cpp:408] conv1 <- data
I0416 17:32:42.760143 22622 net.cpp:382] conv1 -> conv1
I0416 17:32:42.762290 22622 net.cpp:124] Setting up conv1
I0416 17:32:42.762303 22622 net.cpp:131] Top shape: 1 32 32 96 (98304)
I0416 17:32:42.762306 22622 net.cpp:139] Memory required for data: 466944
I0416 17:32:42.762313 22622 layer_factory.hpp:77] Creating layer conv1_bn
I0416 17:32:42.762318 22622 net.cpp:86] Creating Layer conv1_bn
I0416 17:32:42.762320 22622 net.cpp:408] conv1_bn <- conv1
I0416 17:32:42.762324 22622 net.cpp:369] conv1_bn -> conv1 (in-place)
I0416 17:32:42.762442 22622 net.cpp:124] Setting up conv1_bn
I0416 17:32:42.762446 22622 net.cpp:131] Top shape: 1 32 32 96 (98304)
I0416 17:32:42.762449 22622 net.cpp:139] Memory required for data: 860160
I0416 17:32:42.762455 22622 layer_factory.hpp:77] Creating layer conv1_bn_scale
I0416 17:32:42.762459 22622 net.cpp:86] Creating Layer conv1_bn_scale
I0416 17:32:42.762462 22622 net.cpp:408] conv1_bn_scale <- conv1
I0416 17:32:42.762465 22622 net.cpp:369] conv1_bn_scale -> conv1 (in-place)
I0416 17:32:42.762516 22622 net.cpp:124] Setting up conv1_bn_scale
I0416 17:32:42.762519 22622 net.cpp:131] Top shape: 1 32 32 96 (98304)
I0416 17:32:42.762521 22622 net.cpp:139] Memory required for data: 1253376
I0416 17:32:42.762524 22622 layer_factory.hpp:77] Creating layer conv1_relu
I0416 17:32:42.762528 22622 net.cpp:86] Creating Layer conv1_relu
I0416 17:32:42.762531 22622 net.cpp:408] conv1_relu <- conv1
I0416 17:32:42.762533 22622 net.cpp:369] conv1_relu -> conv1 (in-place)
I0416 17:32:42.762857 22622 net.cpp:124] Setting up conv1_relu
I0416 17:32:42.762864 22622 net.cpp:131] Top shape: 1 32 32 96 (98304)
I0416 17:32:42.762866 22622 net.cpp:139] Memory required for data: 1646592
I0416 17:32:42.762869 22622 layer_factory.hpp:77] Creating layer pool1
I0416 17:32:42.762873 22622 net.cpp:86] Creating Layer pool1
I0416 17:32:42.762876 22622 net.cpp:408] pool1 <- conv1
I0416 17:32:42.762879 22622 net.cpp:382] pool1 -> pool1
I0416 17:32:42.762903 22622 net.cpp:124] Setting up pool1
I0416 17:32:42.762907 22622 net.cpp:131] Top shape: 1 32 16 48 (24576)
I0416 17:32:42.762908 22622 net.cpp:139] Memory required for data: 1744896
I0416 17:32:42.762912 22622 layer_factory.hpp:77] Creating layer conv2
I0416 17:32:42.762917 22622 net.cpp:86] Creating Layer conv2
I0416 17:32:42.762918 22622 net.cpp:408] conv2 <- pool1
I0416 17:32:42.762923 22622 net.cpp:382] conv2 -> conv2
I0416 17:32:42.764245 22622 net.cpp:124] Setting up conv2
I0416 17:32:42.764255 22622 net.cpp:131] Top shape: 1 64 16 48 (49152)
I0416 17:32:42.764257 22622 net.cpp:139] Memory required for data: 1941504
I0416 17:32:42.764261 22622 layer_factory.hpp:77] Creating layer conv2_bn
I0416 17:32:42.764269 22622 net.cpp:86] Creating Layer conv2_bn
I0416 17:32:42.764272 22622 net.cpp:408] conv2_bn <- conv2
I0416 17:32:42.764276 22622 net.cpp:369] conv2_bn -> conv2 (in-place)
I0416 17:32:42.764379 22622 net.cpp:124] Setting up conv2_bn
I0416 17:32:42.764384 22622 net.cpp:131] Top shape: 1 64 16 48 (49152)
I0416 17:32:42.764385 22622 net.cpp:139] Memory required for data: 2138112
I0416 17:32:42.764390 22622 layer_factory.hpp:77] Creating layer conv2_bn_scale
I0416 17:32:42.764394 22622 net.cpp:86] Creating Layer conv2_bn_scale
I0416 17:32:42.764396 22622 net.cpp:408] conv2_bn_scale <- conv2
I0416 17:32:42.764400 22622 net.cpp:369] conv2_bn_scale -> conv2 (in-place)
I0416 17:32:42.764446 22622 net.cpp:124] Setting up conv2_bn_scale
I0416 17:32:42.764449 22622 net.cpp:131] Top shape: 1 64 16 48 (49152)
I0416 17:32:42.764451 22622 net.cpp:139] Memory required for data: 2334720
I0416 17:32:42.764454 22622 layer_factory.hpp:77] Creating layer conv2_relu
I0416 17:32:42.764458 22622 net.cpp:86] Creating Layer conv2_relu
I0416 17:32:42.764461 22622 net.cpp:408] conv2_relu <- conv2
I0416 17:32:42.764463 22622 net.cpp:369] conv2_relu -> conv2 (in-place)
I0416 17:32:42.764775 22622 net.cpp:124] Setting up conv2_relu
I0416 17:32:42.764781 22622 net.cpp:131] Top shape: 1 64 16 48 (49152)
I0416 17:32:42.764783 22622 net.cpp:139] Memory required for data: 2531328
I0416 17:32:42.764786 22622 layer_factory.hpp:77] Creating layer pool2
I0416 17:32:42.764789 22622 net.cpp:86] Creating Layer pool2
I0416 17:32:42.764792 22622 net.cpp:408] pool2 <- conv2
I0416 17:32:42.764796 22622 net.cpp:382] pool2 -> pool2
I0416 17:32:42.764818 22622 net.cpp:124] Setting up pool2
I0416 17:32:42.764822 22622 net.cpp:131] Top shape: 1 64 8 24 (12288)
I0416 17:32:42.764824 22622 net.cpp:139] Memory required for data: 2580480
I0416 17:32:42.764827 22622 layer_factory.hpp:77] Creating layer conv3
I0416 17:32:42.764832 22622 net.cpp:86] Creating Layer conv3
I0416 17:32:42.764833 22622 net.cpp:408] conv3 <- pool2
I0416 17:32:42.764837 22622 net.cpp:382] conv3 -> conv3
I0416 17:32:42.767275 22622 net.cpp:124] Setting up conv3
I0416 17:32:42.767285 22622 net.cpp:131] Top shape: 1 128 8 24 (24576)
I0416 17:32:42.767288 22622 net.cpp:139] Memory required for data: 2678784
I0416 17:32:42.767292 22622 layer_factory.hpp:77] Creating layer conv3_bn
I0416 17:32:42.767297 22622 net.cpp:86] Creating Layer conv3_bn
I0416 17:32:42.767299 22622 net.cpp:408] conv3_bn <- conv3
I0416 17:32:42.767302 22622 net.cpp:369] conv3_bn -> conv3 (in-place)
I0416 17:32:42.767408 22622 net.cpp:124] Setting up conv3_bn
I0416 17:32:42.767412 22622 net.cpp:131] Top shape: 1 128 8 24 (24576)
I0416 17:32:42.767416 22622 net.cpp:139] Memory required for data: 2777088
I0416 17:32:42.767421 22622 layer_factory.hpp:77] Creating layer conv3_bn_scale
I0416 17:32:42.767424 22622 net.cpp:86] Creating Layer conv3_bn_scale
I0416 17:32:42.767427 22622 net.cpp:408] conv3_bn_scale <- conv3
I0416 17:32:42.767431 22622 net.cpp:369] conv3_bn_scale -> conv3 (in-place)
I0416 17:32:42.767474 22622 net.cpp:124] Setting up conv3_bn_scale
I0416 17:32:42.767477 22622 net.cpp:131] Top shape: 1 128 8 24 (24576)
I0416 17:32:42.767480 22622 net.cpp:139] Memory required for data: 2875392
I0416 17:32:42.767483 22622 layer_factory.hpp:77] Creating layer conv3_relu
I0416 17:32:42.767486 22622 net.cpp:86] Creating Layer conv3_relu
I0416 17:32:42.767488 22622 net.cpp:408] conv3_relu <- conv3
I0416 17:32:42.767491 22622 net.cpp:369] conv3_relu -> conv3 (in-place)
I0416 17:32:42.767803 22622 net.cpp:124] Setting up conv3_relu
I0416 17:32:42.767812 22622 net.cpp:131] Top shape: 1 128 8 24 (24576)
I0416 17:32:42.767813 22622 net.cpp:139] Memory required for data: 2973696
I0416 17:32:42.767817 22622 layer_factory.hpp:77] Creating layer pool3
I0416 17:32:42.767822 22622 net.cpp:86] Creating Layer pool3
I0416 17:32:42.767823 22622 net.cpp:408] pool3 <- conv3
I0416 17:32:42.767827 22622 net.cpp:382] pool3 -> pool3
I0416 17:32:42.767850 22622 net.cpp:124] Setting up pool3
I0416 17:32:42.767854 22622 net.cpp:131] Top shape: 1 128 4 12 (6144)
I0416 17:32:42.767860 22622 net.cpp:139] Memory required for data: 2998272
I0416 17:32:42.767863 22622 layer_factory.hpp:77] Creating layer conv4
I0416 17:32:42.767868 22622 net.cpp:86] Creating Layer conv4
I0416 17:32:42.767870 22622 net.cpp:408] conv4 <- pool3
I0416 17:32:42.767874 22622 net.cpp:382] conv4 -> conv4
I0416 17:32:42.771854 22622 net.cpp:124] Setting up conv4
I0416 17:32:42.771872 22622 net.cpp:131] Top shape: 1 128 4 12 (6144)
I0416 17:32:42.771874 22622 net.cpp:139] Memory required for data: 3022848
I0416 17:32:42.771879 22622 layer_factory.hpp:77] Creating layer conv4_bn
I0416 17:32:42.771883 22622 net.cpp:86] Creating Layer conv4_bn
I0416 17:32:42.771886 22622 net.cpp:408] conv4_bn <- conv4
I0416 17:32:42.771891 22622 net.cpp:369] conv4_bn -> conv4 (in-place)
I0416 17:32:42.772006 22622 net.cpp:124] Setting up conv4_bn
I0416 17:32:42.772011 22622 net.cpp:131] Top shape: 1 128 4 12 (6144)
I0416 17:32:42.772012 22622 net.cpp:139] Memory required for data: 3047424
I0416 17:32:42.772017 22622 layer_factory.hpp:77] Creating layer conv4_bn_scale
I0416 17:32:42.772022 22622 net.cpp:86] Creating Layer conv4_bn_scale
I0416 17:32:42.772023 22622 net.cpp:408] conv4_bn_scale <- conv4
I0416 17:32:42.772027 22622 net.cpp:369] conv4_bn_scale -> conv4 (in-place)
I0416 17:32:42.772075 22622 net.cpp:124] Setting up conv4_bn_scale
I0416 17:32:42.772079 22622 net.cpp:131] Top shape: 1 128 4 12 (6144)
I0416 17:32:42.772081 22622 net.cpp:139] Memory required for data: 3072000
I0416 17:32:42.772085 22622 layer_factory.hpp:77] Creating layer conv4_relu
I0416 17:32:42.772089 22622 net.cpp:86] Creating Layer conv4_relu
I0416 17:32:42.772091 22622 net.cpp:408] conv4_relu <- conv4
I0416 17:32:42.772094 22622 net.cpp:369] conv4_relu -> conv4 (in-place)
I0416 17:32:42.772465 22622 net.cpp:124] Setting up conv4_relu
I0416 17:32:42.772473 22622 net.cpp:131] Top shape: 1 128 4 12 (6144)
I0416 17:32:42.772476 22622 net.cpp:139] Memory required for data: 3096576
I0416 17:32:42.772478 22622 layer_factory.hpp:77] Creating layer pool4
I0416 17:32:42.772483 22622 net.cpp:86] Creating Layer pool4
I0416 17:32:42.772485 22622 net.cpp:408] pool4 <- conv4
I0416 17:32:42.772490 22622 net.cpp:382] pool4 -> pool4
I0416 17:32:42.772516 22622 net.cpp:124] Setting up pool4
I0416 17:32:42.772519 22622 net.cpp:131] Top shape: 1 128 2 6 (1536)
I0416 17:32:42.772521 22622 net.cpp:139] Memory required for data: 3102720
I0416 17:32:42.772523 22622 layer_factory.hpp:77] Creating layer conv5
I0416 17:32:42.772531 22622 net.cpp:86] Creating Layer conv5
I0416 17:32:42.772532 22622 net.cpp:408] conv5 <- pool4
I0416 17:32:42.772536 22622 net.cpp:382] conv5 -> conv5
I0416 17:32:42.775651 22622 net.cpp:124] Setting up conv5
I0416 17:32:42.775660 22622 net.cpp:131] Top shape: 1 128 2 6 (1536)
I0416 17:32:42.775662 22622 net.cpp:139] Memory required for data: 3108864
I0416 17:32:42.775666 22622 layer_factory.hpp:77] Creating layer conv5_bn
I0416 17:32:42.775671 22622 net.cpp:86] Creating Layer conv5_bn
I0416 17:32:42.775673 22622 net.cpp:408] conv5_bn <- conv5
I0416 17:32:42.775677 22622 net.cpp:369] conv5_bn -> conv5 (in-place)
I0416 17:32:42.775785 22622 net.cpp:124] Setting up conv5_bn
I0416 17:32:42.775790 22622 net.cpp:131] Top shape: 1 128 2 6 (1536)
I0416 17:32:42.775792 22622 net.cpp:139] Memory required for data: 3115008
I0416 17:32:42.775796 22622 layer_factory.hpp:77] Creating layer conv5_bn_scale
I0416 17:32:42.775800 22622 net.cpp:86] Creating Layer conv5_bn_scale
I0416 17:32:42.775802 22622 net.cpp:408] conv5_bn_scale <- conv5
I0416 17:32:42.775806 22622 net.cpp:369] conv5_bn_scale -> conv5 (in-place)
I0416 17:32:42.775851 22622 net.cpp:124] Setting up conv5_bn_scale
I0416 17:32:42.775856 22622 net.cpp:131] Top shape: 1 128 2 6 (1536)
I0416 17:32:42.775857 22622 net.cpp:139] Memory required for data: 3121152
I0416 17:32:42.775861 22622 layer_factory.hpp:77] Creating layer conv5_relu
I0416 17:32:42.775864 22622 net.cpp:86] Creating Layer conv5_relu
I0416 17:32:42.775866 22622 net.cpp:408] conv5_relu <- conv5
I0416 17:32:42.775869 22622 net.cpp:369] conv5_relu -> conv5 (in-place)
I0416 17:32:42.776144 22622 net.cpp:124] Setting up conv5_relu
I0416 17:32:42.776150 22622 net.cpp:131] Top shape: 1 128 2 6 (1536)
I0416 17:32:42.776152 22622 net.cpp:139] Memory required for data: 3127296
I0416 17:32:42.776155 22622 layer_factory.hpp:77] Creating layer pool5
I0416 17:32:42.776158 22622 net.cpp:86] Creating Layer pool5
I0416 17:32:42.776161 22622 net.cpp:408] pool5 <- conv5
I0416 17:32:42.776165 22622 net.cpp:382] pool5 -> pool5
I0416 17:32:42.776523 22622 net.cpp:124] Setting up pool5
I0416 17:32:42.776530 22622 net.cpp:131] Top shape: 1 128 1 1 (128)
I0416 17:32:42.776533 22622 net.cpp:139] Memory required for data: 3127808
I0416 17:32:42.776535 22622 layer_factory.hpp:77] Creating layer ft
I0416 17:32:42.776540 22622 net.cpp:86] Creating Layer ft
I0416 17:32:42.776543 22622 net.cpp:408] ft <- pool5
I0416 17:32:42.776546 22622 net.cpp:382] ft -> ft
I0416 17:32:42.776806 22622 net.cpp:124] Setting up ft
I0416 17:32:42.776810 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.776813 22622 net.cpp:139] Memory required for data: 3128320
I0416 17:32:42.776816 22622 layer_factory.hpp:77] Creating layer ft_bn
I0416 17:32:42.776820 22622 net.cpp:86] Creating Layer ft_bn
I0416 17:32:42.776823 22622 net.cpp:408] ft_bn <- ft
I0416 17:32:42.776825 22622 net.cpp:369] ft_bn -> ft (in-place)
I0416 17:32:42.776926 22622 net.cpp:124] Setting up ft_bn
I0416 17:32:42.776929 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.776932 22622 net.cpp:139] Memory required for data: 3128832
I0416 17:32:42.776939 22622 layer_factory.hpp:77] Creating layer ft_bn_scale
I0416 17:32:42.776942 22622 net.cpp:86] Creating Layer ft_bn_scale
I0416 17:32:42.776944 22622 net.cpp:408] ft_bn_scale <- ft
I0416 17:32:42.776947 22622 net.cpp:369] ft_bn_scale -> ft (in-place)
I0416 17:32:42.776993 22622 net.cpp:124] Setting up ft_bn_scale
I0416 17:32:42.776996 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.776998 22622 net.cpp:139] Memory required for data: 3129344
I0416 17:32:42.777001 22622 layer_factory.hpp:77] Creating layer ft_relu
I0416 17:32:42.777005 22622 net.cpp:86] Creating Layer ft_relu
I0416 17:32:42.777007 22622 net.cpp:408] ft_relu <- ft
I0416 17:32:42.777010 22622 net.cpp:369] ft_relu -> ft (in-place)
I0416 17:32:42.777362 22622 net.cpp:124] Setting up ft_relu
I0416 17:32:42.777369 22622 net.cpp:131] Top shape: 1 128 (128)
I0416 17:32:42.777372 22622 net.cpp:139] Memory required for data: 3129856
I0416 17:32:42.777374 22622 layer_factory.hpp:77] Creating layer logits
I0416 17:32:42.777379 22622 net.cpp:86] Creating Layer logits
I0416 17:32:42.777381 22622 net.cpp:408] logits <- ft
I0416 17:32:42.777385 22622 net.cpp:382] logits -> logits
I0416 17:32:42.777451 22622 net.cpp:124] Setting up logits
I0416 17:32:42.777456 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.777457 22622 net.cpp:139] Memory required for data: 3129872
I0416 17:32:42.777462 22622 layer_factory.hpp:77] Creating layer prob
I0416 17:32:42.777467 22622 net.cpp:86] Creating Layer prob
I0416 17:32:42.777469 22622 net.cpp:408] prob <- logits
I0416 17:32:42.777472 22622 net.cpp:382] prob -> prob
I0416 17:32:42.778857 22622 net.cpp:124] Setting up prob
I0416 17:32:42.778868 22622 net.cpp:131] Top shape: 1 4 (4)
I0416 17:32:42.778870 22622 net.cpp:139] Memory required for data: 3129888
I0416 17:32:42.778873 22622 net.cpp:202] prob does not need backward computation.
I0416 17:32:42.778877 22622 net.cpp:202] logits does not need backward computation.
I0416 17:32:42.778879 22622 net.cpp:202] ft_relu does not need backward computation.
I0416 17:32:42.778882 22622 net.cpp:202] ft_bn_scale does not need backward computation.
I0416 17:32:42.778883 22622 net.cpp:202] ft_bn does not need backward computation.
I0416 17:32:42.778887 22622 net.cpp:202] ft does not need backward computation.
I0416 17:32:42.778888 22622 net.cpp:202] pool5 does not need backward computation.
I0416 17:32:42.778892 22622 net.cpp:202] conv5_relu does not need backward computation.
I0416 17:32:42.778893 22622 net.cpp:202] conv5_bn_scale does not need backward computation.
I0416 17:32:42.778899 22622 net.cpp:202] conv5_bn does not need backward computation.
I0416 17:32:42.778903 22622 net.cpp:202] conv5 does not need backward computation.
I0416 17:32:42.778904 22622 net.cpp:202] pool4 does not need backward computation.
I0416 17:32:42.778906 22622 net.cpp:202] conv4_relu does not need backward computation.
I0416 17:32:42.778909 22622 net.cpp:202] conv4_bn_scale does not need backward computation.
I0416 17:32:42.778911 22622 net.cpp:202] conv4_bn does not need backward computation.
I0416 17:32:42.778913 22622 net.cpp:202] conv4 does not need backward computation.
I0416 17:32:42.778916 22622 net.cpp:202] pool3 does not need backward computation.
I0416 17:32:42.778918 22622 net.cpp:202] conv3_relu does not need backward computation.
I0416 17:32:42.778921 22622 net.cpp:202] conv3_bn_scale does not need backward computation.
I0416 17:32:42.778923 22622 net.cpp:202] conv3_bn does not need backward computation.
I0416 17:32:42.778925 22622 net.cpp:202] conv3 does not need backward computation.
I0416 17:32:42.778928 22622 net.cpp:202] pool2 does not need backward computation.
I0416 17:32:42.778930 22622 net.cpp:202] conv2_relu does not need backward computation.
I0416 17:32:42.778932 22622 net.cpp:202] conv2_bn_scale does not need backward computation.
I0416 17:32:42.778934 22622 net.cpp:202] conv2_bn does not need backward computation.
I0416 17:32:42.778937 22622 net.cpp:202] conv2 does not need backward computation.
I0416 17:32:42.778939 22622 net.cpp:202] pool1 does not need backward computation.
I0416 17:32:42.778942 22622 net.cpp:202] conv1_relu does not need backward computation.
I0416 17:32:42.778944 22622 net.cpp:202] conv1_bn_scale does not need backward computation.
I0416 17:32:42.778946 22622 net.cpp:202] conv1_bn does not need backward computation.
I0416 17:32:42.778949 22622 net.cpp:202] conv1 does not need backward computation.
I0416 17:32:42.778951 22622 net.cpp:202] permute does not need backward computation.
I0416 17:32:42.778954 22622 net.cpp:202] input does not need backward computation.
I0416 17:32:42.778956 22622 net.cpp:244] This network produces output prob
I0416 17:32:42.778968 22622 net.cpp:257] Network initialization done.
I0416 17:32:42.779597 22622 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /apollo/modules/perception/production/data/perception/camera/models/traffic_light_recognition/horizontal/baidu_iter_200000.caffemodel
I0416 17:32:42.779600 22622 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0416 17:32:42.779603 22622 net.cpp:746] Ignoring source layer traffic_light
I0416 17:32:42.779605 22622 net.cpp:746] Ignoring source layer distort
I0416 17:32:42.779743 22622 net.cpp:746] Ignoring source layer ft_drop
I0416 17:32:42.779747 22622 net.cpp:746] Ignoring source layer softmaxloss
I0416 17:32:42.779842 22622 classify.cc:105] []Init Done
I0416 17:32:42.779855 22622 traffic_light_camera_perception.cc:80] []/apollo/modules/perception/production/data/perception/camera/models/traffic_light_tracker semantic.pt
I0416 17:32:42.780000 22622 traffic_light_camera_perception.cc:87] []tl pipeline init done
I0416 17:32:42.784749 22622 camera_app_traffic_light_camera_perception_test.cc:58] []Load image done
I0416 17:32:42.842998 22622 data_provider.cc:146] []Fill in GPU mode ...
I0416 17:32:42.843034 22622 data_provider.cc:186] []Done! (1)
I0416 17:32:42.843037 22622 camera_app_traffic_light_camera_perception_test.cc:86] []lights num 1
I0416 17:32:42.843044 22622 detection.cc:248] []detection input 1 lights
I0416 17:32:42.843055 22622 detection.cc:190] []reshape inputblob 1 270 270 3 (218700)
I0416 17:32:42.843058 22622 detection.cc:196] []get crop box success 919 493 270 270
I0416 17:32:42.843061 22622 data_provider.cc:241] []GetImage ...
I0416 17:32:42.843067 22622 data_provider.cc:268] []	cropping ...
I0416 17:32:42.843070 22622 data_provider.cc:271] []Done!
I0416 17:32:42.843072 22622 detection.cc:208] []get image data success 
I0416 17:32:42.869357 22622 detection.cc:224] []rt_net run success
I0416 17:32:42.869380 22622 detection.cc:301] []output blob size 3 9 1 1
I0416 17:32:42.869397 22622 detection.cc:360] []detect roi x 1045 600 17 52
I0416 17:32:42.869400 22622 detection.cc:360] []detect roi x 919 602 16 50
I0416 17:32:42.869403 22622 detection.cc:360] []detect roi x 965 619 26 19
I0416 17:32:42.869407 22622 detection.cc:275] []Dump output Done! Get box num:3
I0416 17:32:42.869410 22622 detection.cc:284] []start select
I0416 17:32:42.869416 22622 select.cc:84] []score 0.96986
I0416 17:32:42.869444 22622 select.cc:84] []score 0.586471
I0416 17:32:42.869449 22622 select.cc:84] []score 0.696152
I0416 17:32:42.869458 22622 select.cc:123] []hdmap_bboxes-0: projection_roi: [ 21 x 54 ] from ( 1043 , 601 ) detection_roi: [ 17 x 52 ] from ( 1045 , 600 )
I0416 17:32:42.869460 22622 detection.cc:286] []select success
I0416 17:32:42.869462 22622 detection.cc:288] []detection success
I0416 17:32:42.869467 22622 recognition.cc:62] []Recognize Use Vertical Model!
I0416 17:32:42.869473 22622 data_provider.cc:241] []GetImage ...
I0416 17:32:42.869477 22622 data_provider.cc:268] []	cropping ...
I0416 17:32:42.869482 22622 data_provider.cc:271] []Done!
I0416 17:32:42.869483 22622 classify.cc:128] []get img done
I0416 17:32:42.869510 22622 classify.cc:135] []resize gpu finish.
I0416 17:32:42.872084 22622 classify.cc:139] []infer finish.
I0416 17:32:42.872107 22622 classify.cc:161] []Light status recognized as Red
I0416 17:32:42.872109 22622 classify.cc:162] []Color Prob:
I0416 17:32:42.872117 22622 classify.cc:164] []2.31477e-05
I0416 17:32:42.872123 22622 classify.cc:164] []0.999884
I0416 17:32:42.872125 22622 classify.cc:164] []4.57642e-05
I0416 17:32:42.872128 22622 classify.cc:164] []4.68025e-05
I0416 17:32:42.872143 22622 traffic_light_camera_perception.cc:121] []TrafficLightsPerception perf_info. number_of_lights: 1 traffic_light_detect_time: 26 ms. traffic_light_recognize_time: 3 ms. traffic_light_track_time: 0 ms.
[       OK ] TrafficLightCameraPerceptionTest.normal (1839 ms)
[----------] 1 test from TrafficLightCameraPerceptionTest (1839 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (1839 ms total)
[  PASSED  ] 1 test.
==22622== Profiling application: ./camera_app_traffic_light_camera_perception_test
==22622== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   36.71%  3.7117ms       579  6.4100us     736ns  686.02us  [CUDA memcpy HtoD]
                   12.28%  1.2413ms      1308     949ns     672ns  2.4000us  [CUDA memset]
                    7.88%  796.36us         3  265.45us  133.44us  332.10us  maxwell_scudnn_128x128_relu_small_nn
                    6.99%  707.14us        10  70.714us     992ns  664.01us  [CUDA memcpy DtoH]
                    4.53%  457.58us        29  15.778us  12.672us  23.873us  maxwell_scudnn_winograd_128x128_ldg1_ldg4_tile148n_nt
                    3.11%  314.24us       175  1.7950us  1.2160us  7.1680us  void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)
                    2.21%  223.23us         2  111.62us  100.77us  122.47us  void cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)
                    1.93%  194.66us        92  2.1150us     896ns  27.648us  [CUDA memcpy DtoD]
                    1.64%  166.31us         5  33.261us  32.704us  34.368us  sgemm_32x32x32_NN
                    1.63%  164.90us        30  5.4960us  3.6480us  7.3280us  void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)
                    1.51%  152.51us         1  152.51us  152.51us  152.51us  void caffe::DFMBPSROIAlignForward<float>(int, float const *, caffe::DFMBPSROIAlignForward<float>, caffe::DFMBPSROIAlignForward<float>, caffe::DFMBPSROIAlignForward<float>, int, int, int, int, int, float const , float const , bool, caffe::DFMBPSROIAlignForward<float>, int, int, int, int, int, int, int, int, caffe::DFMBPSROIAlignForward<float>*, float const *)
                    1.41%  142.27us        36  3.9520us  1.1840us  33.760us  void axpy_kernel_val<float, float, int=0>(cublasAxpyParamsVal<float, float, float>)
                    1.40%  141.83us        46  3.0830us  1.3440us  19.168us  void op_generic_tensor_kernel<int=2, float, float, float, int=256, cudnnGenericOp_t=8, cudnnNanPropagation_t=1, cudnnDimOrder_t=0, int=1>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, float, dimArray, reducedDivisorArray, bool)
                    1.16%  116.99us         1  116.99us  116.99us  116.99us  void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)
                    1.15%  116.16us        37  3.1390us  1.9840us  10.880us  void caffe::ScaleBiasForward<float>(int, float const *, float const , float const , int, int, caffe::ScaleBiasForward<float>*)
                    1.04%  104.93us        13  8.0710us  2.4000us  24.448us  void op_generic_tensor_kernel<int=2, float, float, float, int=256, cudnnGenericOp_t=0, cudnnNanPropagation_t=0, cudnnDimOrder_t=0, int=0>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, float, dimArray, reducedDivisorArray, bool)
                    1.03%  104.35us        86  1.2130us     928ns  1.8560us  void copy_kernel<float, int=0>(cublasCopyParams<float>)
                    0.99%  99.904us         2  49.952us  49.920us  49.984us  void ForEachPixelNaive<unsigned char, int=3, PointwiseFunctor<unsigned char, int=3, unsigned char, int=3, SwapChannels<unsigned char, int=3, int=3>>>(Image<unsigned char, int=3>, NppiSize, unsigned char)
                    0.98%  99.394us        86  1.1550us     896ns  1.5680us  void scal_kernel_val<float, float, int=0>(cublasScalParamsVal<float, float>)
                    0.89%  89.601us        43  2.0830us  1.2480us  13.664us  void caffe::div_kernel<float>(int, float const *, float const , caffe::div_kernel<float>*)
                    0.75%  75.649us         1  75.649us  75.649us  75.649us  maxwell_sgemm_128x64_tn
                    0.72%  73.185us         2  36.592us  36.352us  36.833us  void ForEachPixelNaive<unsigned char, int=3, PointwiseFunctor<unsigned char, int=1, unsigned char, int=3, DupOperator<unsigned char, int=3>>>(Image<unsigned char, int=3>, NppiSize, unsigned char)
                    0.66%  66.273us         2  33.136us  32.929us  33.344us  void ForEachPixelByte<unsigned char, int=1, ColorToGrayFunctor<unsigned char, int=3>>(Pixel<unsigned char, int=1>*, int, int, int, int, int, int, unsigned char)
                    0.60%  60.897us         1  60.897us  60.897us  60.897us  void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)
                    0.58%  58.656us         2  29.328us  14.368us  44.288us  maxwell_scudnn_128x64_relu_interior_nn
                    0.58%  58.336us        43  1.3560us  1.1200us  1.6960us  void caffe::sqrt_kernel<float>(int, float const *, caffe::sqrt_kernel<float>*)
                    0.51%  51.617us         1  51.617us  51.617us  51.617us  maxwell_scudnn_128x32_relu_medium_nn
                    0.50%  51.040us         5  10.208us  9.5040us  11.168us  void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)
                    0.48%  48.576us        43  1.1290us     864ns  1.3440us  caffe::sync_conv_groups(void)
                    0.47%  47.968us        43  1.1150us     928ns  1.2480us  void caffe::add_scalar_kernel<float>(int, float, caffe::add_scalar_kernel<float>*)
                    0.47%  47.552us         3  15.850us  9.8240us  27.008us  maxwell_scudnn_128x32_relu_interior_nn
                    0.47%  47.200us         2  23.600us  3.8400us  43.360us  void caffe::PermuteKernel<float>(int, float*, bool, int const *, int const , int const , int, float)
                    0.38%  38.753us         1  38.753us  38.753us  38.753us  maxwell_scudnn_128x64_relu_small_nn
                    0.36%  36.448us         2  18.224us  15.872us  20.576us  sgemm_32x32x32_NT_vec
                    0.30%  30.784us         5  6.1560us  3.2960us  14.112us  void caffe::MaxPoolForward<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, int, caffe::MaxPoolForward<float>*, int*, float const *)
                    0.23%  23.072us         1  23.072us  23.072us  23.072us  maxwell_scudnn_128x32_relu_small_nn
                    0.21%  20.993us        12  1.7490us  1.1840us  2.2720us  cudnn::maxwell::gemm::computeOffsetsKernel(cudnn::maxwell::gemm::ComputeOffsetsParams)
                    0.20%  19.776us         2  9.8880us  3.3920us  16.384us  void apollo::perception::inference::resize_linear_kernel_mean<float>(unsigned char const *, float*, int, int, int, int, int, int, float, float, float, float*, float*, bool, float)
                    0.20%  19.744us         1  19.744us  19.744us  19.744us  maxwell_scudnn_128x128_relu_interior_nn
                    0.14%  14.528us         1  14.528us  14.528us  14.528us  maxwell_scudnn_winograd_128x128_ldg1_ldg4_tile148t_nt
                    0.14%  13.696us         6  2.2820us  1.2480us  4.4160us  void caffe::ScaleForward<float>(int, float const *, float const , int, int, caffe::ScaleForward<float>*)
                    0.11%  11.456us         2  5.7280us  5.6000us  5.8560us  void cudnn::detail::softmax_fw_kernel<int=2, float, float, int=256, int=1, int=1, int=0>(cudnnTensorStruct, float const *, cudnn::detail::softmax_fw_kernel<int=2, float, float, int=256, int=1, int=1, int=0>, cudnnTensorStruct*, int, float, cudnnTensorStruct*, int, int)
                    0.10%  9.9530us         1  9.9530us  9.9530us  9.9530us  void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=1, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=1, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)
                    0.09%  8.6720us         2  4.3360us  2.8800us  5.7920us  void caffe::compute_overlapped_by_idx_kernel<float>(int, float const *, int, caffe::compute_overlapped_by_idx_kernel<float>, int const *, int, caffe::compute_overlapped_by_idx_kernel<float>, bool*)
                    0.08%  7.6800us         2  3.8400us  2.8480us  4.8320us  void scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)
                    0.06%  5.6000us         2  2.8000us  2.0800us  3.5200us  void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=2, bool=0, cublasGemvParams<cublasGemvTensor<float const >, cublasGemvTensor<float>, float>>(float, float, float const )
                    0.06%  5.5690us         1  5.5690us  5.5690us  5.5690us  void cudnn::detail::softmax_fw_channel_4d_kernel<float, float, int=256, int=1>(cudnnTensorStruct, float const *, cudnn::detail::softmax_fw_channel_4d_kernel<float, float, int=256, int=1>, cudnnTensorStruct*, int, float, cudnnTensorStruct*, int, int)
                    0.05%  4.8320us         1  4.8320us  4.8320us  4.8320us  void caffe::rcnn_cmp_conf_bbox_kernel<float>(int, float, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, bool, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, bool, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, caffe::rcnn_cmp_conf_bbox_kernel<float>, bool, bool, int, caffe::rcnn_cmp_conf_bbox_kernel<float> const *, caffe::rcnn_cmp_conf_bbox_kernel<float> const , caffe::rcnn_cmp_conf_bbox_kernel<float> const , caffe::rcnn_cmp_conf_bbox_kernel<float> const , caffe::rcnn_cmp_conf_bbox_kernel<float>*, caffe::rcnn_cmp_conf_bbox_kernel<float> const *)
                    0.05%  4.6400us         1  4.6400us  4.6400us  4.6400us  void caffe::rpn_cmp_conf_bbox_kernel<float>(int, int, int, int, float, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, bool, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, bool, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, caffe::rpn_cmp_conf_bbox_kernel<float>, bool, caffe::rpn_cmp_conf_bbox_kernel<float> const *, caffe::rpn_cmp_conf_bbox_kernel<float> const , caffe::rpn_cmp_conf_bbox_kernel<float> const , caffe::rpn_cmp_conf_bbox_kernel<float>*, caffe::rpn_cmp_conf_bbox_kernel<float> const *)
                    0.03%  2.5600us         2  1.2800us  1.2800us  1.2800us  caffe::sync_deconv_groups(void)
      API calls:   54.75%  911.94ms      1848  493.47us     970ns  887.36ms  cudaStreamCreateWithFlags
                   23.99%  399.55ms      2916  137.02us     340ns  370.16ms  cudaFree
                   12.18%  202.84ms      2628  77.182us  2.0300us  176.65ms  cudaMallocHost
                    3.43%  57.199ms       788  72.587us  3.9600us  36.083ms  cudaLaunchKernel
                    1.34%  22.330ms      2859  7.8100us  3.1000us  708.59us  cudaFreeHost
                    1.24%  20.584ms      2400  8.5760us  1.6600us  395.16us  cudaMalloc
                    0.71%  11.756ms       681  17.263us  4.6700us  708.31us  cudaMemcpy
                    0.59%  9.8368ms       924  10.645us     970ns  1.0748ms  cudaStreamCreateWithPriority
                    0.36%  5.9155ms      2937  2.0140us  1.2600us  279.38us  cudaStreamDestroy
                    0.27%  4.5355ms       167  27.158us  1.9300us  1.1265ms  cudaStreamCreate
                    0.20%  3.3322ms      6484     513ns     400ns  4.8100us  cudaEventCreateWithFlags
                    0.17%  2.8055ms      6484     432ns     350ns  1.6000us  cudaEventDestroy
                    0.16%  2.7007ms       924  2.9220us  2.0600us  10.420us  cudaMemsetAsync
                    0.12%  1.9282ms      6946     277ns     240ns  5.7000us  cudaDeviceGetAttribute
                    0.12%  1.9248ms       384  5.0120us  2.1500us  14.770us  cudaMemset
                    0.11%  1.8817ms       231  8.1450us  4.3200us  17.720us  cudaHostAlloc
                    0.07%  1.1304ms       654  1.7280us     110ns  152.34us  cuDeviceGetAttribute
                    0.07%  1.1260ms         7  160.86us  141.63us  214.58us  cuDeviceTotalMem
                    0.04%  662.12us         5  132.42us  121.71us  150.45us  cudaGetDeviceProperties
                    0.03%  545.38us       466  1.1700us  1.0100us  19.210us  cudaDeviceSynchronize
                    0.02%  264.67us       533     496ns     290ns  17.910us  cudaGetDevice
                    0.01%  176.53us       165  1.0690us     730ns  2.6990us  cudaEventRecord
                    0.01%  158.58us         7  22.654us  12.620us  43.670us  cuDeviceGetName
                    0.01%  157.92us       231     683ns     570ns     920ns  cudaHostGetDevicePointer
                    0.01%  138.08us        59  2.3400us  2.0000us  3.3900us  cudaFuncGetAttributes
                    0.01%  111.53us       231     482ns     370ns  1.2100us  cudaDeviceGetStreamPriorityRange
                    0.01%  110.46us       832     132ns      90ns     760ns  cudaGetLastError
                    0.00%  38.580us       232     166ns     110ns     630ns  cudaGetDeviceCount
                    0.00%  35.830us        59     607ns     420ns  1.3800us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    0.00%  15.239us         6  2.5390us  1.2700us  4.6390us  cudaBindTexture
                    0.00%  13.050us        16     815ns     540ns  1.8300us  cudaEventCreate
                    0.00%  5.5100us         6     918ns     490ns  1.7900us  cuInit
                    0.00%  5.2200us         4  1.3050us     560ns  2.5500us  cudaSetDevice
                    0.00%  4.7700us         6     795ns     200ns  2.1100us  cuDriverGetVersion
                    0.00%  3.5600us         9     395ns     190ns     690ns  cuDeviceGetCount
                    0.00%  3.3200us         8     415ns     160ns     630ns  cuDeviceGet
                    0.00%  3.2200us         6     536ns     460ns     610ns  cudaUnbindTexture
                    0.00%  2.9290us         1  2.9290us  2.9290us  2.9290us  cuDeviceGetPCIBusId
                    0.00%  2.4700us        15     164ns     150ns     180ns  cudaPeekAtLastError
                    0.00%  2.0300us         7     290ns     180ns     370ns  cuDeviceGetUuid
